{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlEQ7lt9fv3p"
      },
      "source": [
        "# **INSTALLING DEPENDENCIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvlJyG0Cf0pw",
        "outputId": "114146ed-f71b-4776-d6a0-3e08ce25b9b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, requests, pyarrow, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 fsspec-2024.5.0 multiprocess-0.70.16 pyarrow-17.0.0 requests-2.32.3 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDeWJm6QzMZz",
        "outputId": "77f68f74-6a77-46a2-b955-821e44b6cd21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install lxml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBgJa_asf8Oj"
      },
      "source": [
        "# **IMPORTING ESSENTIAL LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xk3LXD1HgCyz"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple, Dict\n",
        "import numpy as np\n",
        "\n",
        "from datasets.utils.logging import disable_progress_bar\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose, Resize, Grayscale, RandomHorizontalFlip, RandomRotation\n",
        "from torchvision.datasets import CIFAR10, MNIST, FashionMNIST\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import copy\n",
        "import os\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import MDS  # Optional for visualization\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "from lxml import etree\n",
        "\n",
        "\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUonxDjFas7X"
      },
      "outputs": [],
      "source": [
        "!mkdir models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obINPA9F8VNX"
      },
      "source": [
        "# **LOG FILE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U65YnNYD8Xri"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "\n",
        "log_path = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S_\")\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
        "\n",
        "log_file = log_path + '.log'\n",
        "os.mkdir(log_path)\n",
        "open(log_file, 'a').close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvvwOLmqCmmo"
      },
      "source": [
        "# **PARSE .XML FILE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "o4chg7elCq81",
        "outputId": "411e36fd-1a7a-483e-ccf9-aff4aeb849ab"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9aac4867-f6ea-4b0a-b9b7-5a640d60227f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9aac4867-f6ea-4b0a-b9b7-5a640d60227f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving shards.xml to shards.xml\n"
          ]
        }
      ],
      "source": [
        "def parse_xml_assignments(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    node_assignments = {}\n",
        "    for node in root.findall('Node'):\n",
        "        node_id = int(node.get('id'))\n",
        "        shards = [(int(dp.get('classLabel')), int(dp.get('shard'))) for dp in node.findall('DataPair')]\n",
        "        node_assignments[node_id] = shards\n",
        "    return node_assignments\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znjBPF_DwjJE"
      },
      "source": [
        "# **DATA AUGMENTATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUExxYUKzY1V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset, TensorDataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def chunk(a, i, n):\n",
        "    a2 = chunkify(a, n)\n",
        "    return a2[i]\n",
        "\n",
        "def chunkify(a, n):\n",
        "    # splits list into even size list of lists\n",
        "    # [1,2,3,4] -> [1,2], [3,4]\n",
        "\n",
        "    k, m = divmod(len(a), n)\n",
        "    gen = (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n",
        "    return list(gen)\n",
        "\n",
        "def augment_dataset_with_rotation(dataset):\n",
        "  def rotate_90(image):\n",
        "    return transforms.functional.rotate(image, 90)\n",
        "  def rotate_180(image):\n",
        "    return transforms.functional.rotate(image, 180)\n",
        "  def rotate_270(image):\n",
        "    return transforms.functional.rotate(image, 270)\n",
        "  original_images = []\n",
        "  rotated_images = []\n",
        "  original_labels = []\n",
        "  rotated_labels = []\n",
        "\n",
        "  for img, label in dataset:\n",
        "    original_images.append(img)\n",
        "    rotated_images.append(rotate_180(img))\n",
        "    original_labels.append(label)\n",
        "    rotated_labels.append(label)\n",
        "\n",
        "  original_dataset = torch.utils.data.TensorDataset(torch.stack(original_images), torch.tensor(original_labels))\n",
        "  rotated_dataset = torch.utils.data.TensorDataset(torch.stack(rotated_images), torch.tensor(rotated_labels))\n",
        "  augmented_dataset = ConcatDataset([original_dataset, rotated_dataset])\n",
        "\n",
        "  show_images(original_dataset)\n",
        "  show_images(rotated_dataset)\n",
        "\n",
        "  return augmented_dataset\n",
        "\n",
        "def show_images(dataset, num_images=6):\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15,5))\n",
        "    for i in range(num_images):\n",
        "      img, label = dataset[i]\n",
        "      img = img.squeeze().numpy()\n",
        "      axes[i].imshow(img, cmap='gray')\n",
        "      axes[i].set_title(f'Label: {label}')\n",
        "      axes[i].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "class ClusteredDataset:\n",
        "  def __init__(self):\n",
        "\n",
        "    self.dataset = {}\n",
        "\n",
        "    self.transform = Compose([\n",
        "      Resize((224,224)),\n",
        "      ToTensor(),\n",
        "      Normalize((0.5,), (0.5,)),\n",
        "      ])\n",
        "\n",
        "    '''\n",
        "    self.transform = Compose([\n",
        "      ToTensor(),\n",
        "      Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "      ])\n",
        "      '''\n",
        "\n",
        "  def load_dataset(self, dataset: str, train):\n",
        "    if dataset == 'mnist':\n",
        "      if train:\n",
        "        train = MNIST(root= './data', train= True, download= True, transform= self.transform)\n",
        "\n",
        "        #dl_train = DataLoader(train)\n",
        "        X = train.data.unsqueeze(1).float() # (60000,28, 28)\n",
        "        Y = train.targets #(60000)\n",
        "        #X = X / 255.0\n",
        "      else:\n",
        "        test = MNIST(root= './data', train= False, download= True, transform= self.transform)\n",
        "        #dl_test = DataLoader(test)\n",
        "        X = test.data.unsqueeze(1).float() # (60000,28, 28)\n",
        "        print(\"S\", X.shape)\n",
        "        Y = test.targets #(60000)\n",
        "        #X = X / 255.0\n",
        "\n",
        "    if dataset == 'cifar10':\n",
        "      if train:\n",
        "        train = CIFAR10(root= './data', train= True, download= True, transform= self.transform)\n",
        "        dl_train = DataLoader(train)\n",
        "        X = dl_train.dataset.data # (60000,28, 28)\n",
        "        Y = dl_train.dataset.targets #(60000)\n",
        "        #X = X / 255.0\n",
        "      else:\n",
        "        test = CIFAR10(root= './data', train= False, download= True, transform= self.transform)\n",
        "        dl_test = DataLoader(test)\n",
        "        X = dl_test.dataset.data # (60000,28, 28)\n",
        "        Y = dl_test.dataset.targets #(60000)\n",
        "        #X = X / 255.0\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "  def setup_dataset(self, num_dataset, num_clients, num_data_per_client, num_clusters, random=True):\n",
        "    assert (num_clients // num_clusters) * num_data_per_client == num_dataset\n",
        "    data_indices = []\n",
        "    cluster_assignments = []\n",
        "    client_per_cluster = num_clients // num_clusters\n",
        "    for c_i in range(num_clusters):\n",
        "      if random:\n",
        "        ll = list(np.random.permutation(num_dataset))\n",
        "      else:\n",
        "\n",
        "        ll = list(range(num_dataset))\n",
        "\n",
        "      ll2 = chunkify(ll, client_per_cluster) # splits ll into m lists with size n\n",
        "      data_indices += ll2\n",
        "\n",
        "      cluster_assignments += [c_i for _ in range(client_per_cluster)]\n",
        "\n",
        "    data_indices = np.array(data_indices)\n",
        "    cluster_assignments = np.array(cluster_assignments)\n",
        "    assert data_indices.shape[0] == cluster_assignments.shape[0]\n",
        "    assert data_indices.shape[0] == num_clients\n",
        "\n",
        "\n",
        "    return data_indices, cluster_assignments\n",
        "\n",
        "  def rotate_data(self, num_dataset, num_clusters, m_i):\n",
        "\n",
        "\n",
        "    indices = self.dataset['data_indices'][m_i]\n",
        "    c_i = self.dataset['cluster_assign'][m_i]\n",
        "\n",
        "\n",
        "    X_batch = self.dataset['X'][indices]\n",
        "\n",
        "    Y_batch = self.dataset['Y'][indices]\n",
        "\n",
        "    #print(\"shape\", X_batch.shape, Y_batch.shape)\n",
        "\n",
        "\n",
        "    if num_clusters == 4:\n",
        "      k = c_i\n",
        "    if num_clusters == 2:\n",
        "      k = (c_i % 2) * 2\n",
        "    if num_clusters == 1:\n",
        "      k = 0\n",
        "\n",
        "    X_batch2 = torch.rot90(X_batch, k=int(k), dims = (1,2))\n",
        "    X_batch3 = X_batch2.reshape(-1,1, 28, 28)\n",
        "    print(\"after\", X_batch3.shape)\n",
        "\n",
        "\n",
        "    return X_batch3, Y_batch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def get_loaders(self, num_dataset, num_clients, num_data_per_client, num_clusters,train):\n",
        "    if train:\n",
        "      self.dataset['data_indices'], self.dataset['cluster_assign'] = self.setup_dataset(num_dataset, num_clients, num_data_per_client, num_clusters)\n",
        "      X, Y = self.load_dataset('mnist', train)\n",
        "      self.dataset['X'] = X\n",
        "      self.dataset['Y'] = Y\n",
        "    else:\n",
        "      self.dataset['data_indices'], self.dataset['cluster_assign'] = self.setup_dataset(num_dataset, num_clients, num_data_per_client, num_clusters)\n",
        "      X, Y = self.load_dataset('mnist', train)\n",
        "      self.dataset['X'] = X\n",
        "      self.dataset['Y'] = Y\n",
        "\n",
        "\n",
        "    loaders = []\n",
        "    for client in range(num_clients):\n",
        "      X_label, Y_label = self.rotate_data(num_dataset, num_clusters, client)\n",
        "      if isinstance(X_label, np.ndarray):\n",
        "        X_label = torch.tensor(X_label, dtype=torch.float32)\n",
        "      if isinstance(Y_label, np.ndarray):\n",
        "        Y_label = torch.tensor(Y_label, dtype=torch.long)\n",
        "      dataset = TensorDataset(X_label, Y_label)\n",
        "      data_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "      loaders.append(data_loader)\n",
        "    return loaders\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl9W__JNfETv"
      },
      "source": [
        "# **PREPARING THE CIFAR10 DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1WlZjdweX4v"
      },
      "outputs": [],
      "source": [
        "\n",
        "import random\n",
        "class Dataset:\n",
        "  def __init__(self):\n",
        "    self.num_classes = 10\n",
        "    self.num_shards_per_class = 4\n",
        "\n",
        "    self.transform = Compose([\n",
        "      ToTensor(),\n",
        "      Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "      ])\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    self.transform = Compose([\n",
        "      #Resize(224),\n",
        "      Grayscale(num_output_channels=3),\n",
        "      ToTensor(),\n",
        "      Normalize((0.1307,), (0.3081,)),\n",
        "      ])\n",
        "      \"\"\"\n",
        "\n",
        "  def load_CIFAR10_dataset(self):\n",
        "\n",
        "    ## For Alexnet model\n",
        "    \"\"\"\n",
        "    tr = Compose([Resize(224),\n",
        "                             ToTensor(),\n",
        "                             Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.25))])\n",
        "    \"\"\"\n",
        "    train = CIFAR10(root= './data', train= True, download= True, transform=self.transform)\n",
        "    test = CIFAR10(root= './data', train= False, download= True, transform=self.transform)\n",
        "    return train, test\n",
        "\n",
        "  def load_MNIST_dataset(self):\n",
        "    train = MNIST(root= './data', train= True, download= True, transform= self.transform)\n",
        "    test = MNIST(root= './data', train= False, download= True, transform= self.transform)\n",
        "    return train, test\n",
        "\n",
        "  def load_FashionMNIST_dataset(self):\n",
        "    train = FashionMNIST(root= './data', train= True, download= True, transform= self.transform)\n",
        "    test = FashionMNIST(root= './data', train= False, download= True, transform= self.transform)\n",
        "    return train, test\n",
        "\n",
        "  def load_shards_from_xml_file(self, xml_file, train, test, num_clients):\n",
        "    node_assignments = parse_xml_assignments(xml_file)\n",
        "    train_data_indices = {i: np.array([], dtype='int64') for i in range(num_clients)}\n",
        "    test_data_indices = {i: np.array([], dtype='int64') for i in range(num_clients)}\n",
        "    train_shards, _ = self.divide_class_into_shards(train, 10, 20)\n",
        "    test_shards, _ = self.divide_class_into_shards(test, 10, 20)\n",
        "    trainLoaders = []\n",
        "    testLoaders = []\n",
        "    for node in range(num_clients):\n",
        "      shard_ids = node_assignments[node]\n",
        "      indices_tr = [(shard_id[0] - 1) * 20 + shard_id[1] for shard_id in shard_ids]\n",
        "      indices_ts = [(shard_id[0] - 1) * 20 + random.randint(1,19) for shard_id in shard_ids]\n",
        "      train_indices = np.concatenate([train_shards[idx] for idx in indices_tr])\n",
        "      test_indices = np.concatenate([test_shards[idx] for idx in indices_ts])\n",
        "      train_loader = DataLoader(Subset(train, train_indices), batch_size=64, shuffle=True)\n",
        "      trainLoaders.append(train_loader)\n",
        "      test_loader = DataLoader(Subset(test, test_indices), batch_size=64, shuffle=True)\n",
        "      testLoaders.append(test_loader)\n",
        "\n",
        "    return trainLoaders, testLoaders\n",
        "\n",
        "\n",
        "    return 1\n",
        "\n",
        "  def divide_class_into_shards(self, dataset, num_classes: int, num_shards_per_class: int):\n",
        "    num_shards = num_classes * num_shards_per_class\n",
        "\n",
        "    num_imgs = int(len(dataset)/ num_shards_per_class / num_classes)\n",
        "\n",
        "    ## Create a list to store indices for each class\n",
        "    class_indices = [[] for _ in range(num_classes)]\n",
        "    labels = np.array(dataset.targets)\n",
        "\n",
        "\n",
        "    # Group the indices of each class\n",
        "    for idx, label in enumerate(labels):\n",
        "      class_indices[label].append(idx)\n",
        "\n",
        "\n",
        "    # Shuffle indices within each class\n",
        "\n",
        "    for i in range(num_classes):\n",
        "      np.random.shuffle(class_indices[i])\n",
        "\n",
        "    shards = []\n",
        "    for i in range(num_classes):\n",
        "      for j in range(num_shards_per_class):\n",
        "\n",
        "        shards.append(class_indices[i][j*num_imgs:(j+1)*num_imgs])\n",
        "    shards = np.array(shards, dtype='object')\n",
        "\n",
        "    return shards, num_shards\n",
        "  def noniid_split(self, dataset, num_classes: int, num_clients: int, num_shards_per_class: int):\n",
        "\n",
        "    shards, num_shards = self.divide_class_into_shards(dataset, num_classes, num_shards_per_class)\n",
        "    ## Ensure each client gets 2 shards from different classes\n",
        "    client_data_indices = {i: np.array([], dtype='int64') for i in range(num_clients)}\n",
        "    shards_per_client = 4\n",
        "    shards_assignments = np.zeros(num_shards, dtype=bool)\n",
        "    classes = []\n",
        "    for client in range(num_clients):\n",
        "      assigned_shards = []\n",
        "      classes_assigned = []\n",
        "\n",
        "      while len(assigned_shards) < shards_per_client:\n",
        "        shard_idx = np.random.choice(np.where(shards_assignments == False)[0])\n",
        "        class_idx = shard_idx // num_shards_per_class\n",
        "        if class_idx not in classes_assigned:\n",
        "          assigned_shards.append(shard_idx)\n",
        "          classes_assigned.append(class_idx)\n",
        "          shards_assignments[shard_idx] = True\n",
        "\n",
        "      classes.append(classes_assigned)\n",
        "      print(classes_assigned)\n",
        "\n",
        "      for shard in assigned_shards:\n",
        "        client_data_indices[client] = np.concatenate((client_data_indices[client], shards[shard]), axis=0)\n",
        "    return client_data_indices, classes\n",
        "\n",
        "\n",
        "  def partition_test_data_based_on_train(self, dataset, train_idx, num_classes: int, num_clients: int, num_shards_per_class: int):\n",
        "\n",
        "    shards, num_shards = self.divide_class_into_shards(dataset, num_classes, num_shards_per_class)\n",
        "    ## Ensure each client gets 2 shards from different classes\n",
        "    client_data_indices = {i: np.array([], dtype='int64') for i in range(num_clients)}\n",
        "    shards_per_client = 4\n",
        "    shards_assignments = np.zeros(num_shards, dtype=bool)\n",
        "    classes = []\n",
        "    for client in range(num_clients):\n",
        "      assigned_shards = []\n",
        "      classes_assigned = []\n",
        "\n",
        "      while len(assigned_shards) < shards_per_client:\n",
        "        class_idx = train_idx[client][len(assigned_shards)]\n",
        "        #shard_idx = np.random.choice(np.where(shards_assignments == False)[0])\n",
        "        shard_idx = class_idx * 20 + random.randint(1,19)\n",
        "        print(\"shard, class\", shard_idx, class_idx)\n",
        "        assigned_shards.append(shard_idx)\n",
        "        classes_assigned.append(class_idx)\n",
        "        #if class_idx not in classes_assigned:\n",
        "          #assigned_shards.append(shard_idx)\n",
        "          #classes_assigned.append(class_idx)\n",
        "          #shards_assignments[shard_idx] = True\n",
        "\n",
        "      classes.append(classes_assigned)\n",
        "      print(classes_assigned)\n",
        "\n",
        "      for shard in assigned_shards:\n",
        "        client_data_indices[client] = np.concatenate((client_data_indices[client], shards[shard]), axis=0)\n",
        "    return client_data_indices\n",
        "  def get_dataloaders(self, dataset, indices, batch_size):\n",
        "    loaders = []\n",
        "    for client_idx in indices:\n",
        "      subset = Subset(dataset, indices[client_idx])\n",
        "      loader = DataLoader(subset, batch_size=batch_size, shuffle= True)\n",
        "      loaders.append(loader)\n",
        "    return loaders\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y4re3AhcTUs"
      },
      "source": [
        "# **DATA DISTRIBUTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_-ElK9_cSdm",
        "outputId": "f23e8623-8490-4c59-ba6d-2c634c3ed35f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26421880/26421880 [00:03<00:00, 7998755.45it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 131692.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 2491420.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 6772985.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Insufficient data in label: Coat\n",
            "WARNING:root:Dumping used data for reuse\n",
            "WARNING:root:Insufficient data in label: Coat\n",
            "WARNING:root:Dumping used data for reuse\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import random\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import random\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose, Resize, Grayscale, RandomHorizontalFlip, RandomRotation\n",
        "from torchvision.datasets import CIFAR10, MNIST, FashionMNIST\n",
        "from torch.utils.data import DataLoader, ConcatDataset, TensorDataset\n",
        "\n",
        "def uniform(N, k):\n",
        "    \"\"\"Uniform distribution of 'N' items into 'k' groups.\"\"\"\n",
        "    dist = []\n",
        "    avg = N / k\n",
        "    # Make distribution\n",
        "    for i in range(k):\n",
        "        dist.append(int((i + 1) * avg) - int(i * avg))\n",
        "    # Return shuffled distribution\n",
        "    random.shuffle(dist)\n",
        "    return dist\n",
        "\n",
        "def normal(N, k):\n",
        "    \"\"\"Normal distribution of 'N' items into 'k' groups.\"\"\"\n",
        "    dist = []\n",
        "    # Make distribution\n",
        "    for i in range(k):\n",
        "        x = i - (k - 1) / 2\n",
        "        dist.append(int(N * (np.exp(-x) / (np.exp(-x) + 1)**2)))\n",
        "    # Add remainders\n",
        "    remainder = N - sum(dist)\n",
        "    dist = list(np.add(dist, uniform(remainder, k)))\n",
        "    # Return non-shuffled distribution\n",
        "    return dist\n",
        "\n",
        "\n",
        "class Generator():  # CHECKME\n",
        "    \"\"\"Generator for UNNAMED dataset.\"\"\"\n",
        "\n",
        "    # Extract UNNAMED data using torchvision datasets\n",
        "    def read(self, path):\n",
        "        self.trainset = FashionMNIST(\n",
        "            path, train=True, download=True, transform=transforms.Compose([\n",
        "                ToTensor(),\n",
        "                Normalize((0.5,), (0.5,)),\n",
        "      ]))\n",
        "        self.testset = FashionMNIST(\n",
        "            path, train=False, download= True, transform=transforms.Compose([\n",
        "                ToTensor(),\n",
        "                Normalize((0.5,), (0.5,)),\n",
        "      ]))\n",
        "        self.labels = list(self.trainset.classes)\n",
        "    def group(self):\n",
        "\n",
        "        # Create empty dict of labels\n",
        "      grouped_data = {label: [] for label in self.labels}  # pylint: disable=no-member\n",
        "\n",
        "        # Populate grouped data dict\n",
        "      for datapoint in self.trainset:\n",
        "          # pylint: disable=all\n",
        "\n",
        "          _, label = datapoint\n",
        "          label = self.labels[label]\n",
        "\n",
        "          grouped_data[label].append(datapoint)\n",
        "\n",
        "\n",
        "      return grouped_data\n",
        "\n",
        "    def group_test(self):\n",
        "        # Create empty dict of labels\n",
        "      grouped_data = {label: [] for label in self.labels}  # pylint: disable=no-member\n",
        "\n",
        "        # Populate grouped data dict\n",
        "      for datapoint in self.testset:\n",
        "        _, label = datapoint\n",
        "        label = self.labels[label]\n",
        "        grouped_data[label].append(datapoint)\n",
        "\n",
        "      return grouped_data\n",
        "'''\n",
        "class Generator(object):\n",
        "  def read(self, path):\n",
        "        # Read the dataset, set: trainset, testset, labels\n",
        "    raise NotImplementedError\n",
        "\n",
        "    # Group the data by label\n",
        "  def group(self):\n",
        "        # Create empty dict of labels\n",
        "    grouped_data = {label: [] for label in self.labels}  # pylint: disable=no-member\n",
        "\n",
        "        # Populate grouped data dict\n",
        "    for datapoint in self.trainset:  # pylint: disable=all\n",
        "        _, label = datapoint  # Extract label\n",
        "        label = self.labels[label]\n",
        "\n",
        "        grouped_data[label].append(datapoint)\n",
        "\n",
        "    self.trainset = grouped_data  # Overwrite trainset with grouped data\n",
        "\n",
        "    # Run data generation\n",
        "  def generate(self, path):\n",
        "    self.read(path)\n",
        "    self.trainset_size = len(self.trainset)  # Extract trainset size\n",
        "    self.group()\n",
        "\n",
        "    return self.trainset\n",
        "'''\n",
        "class Loader(object):\n",
        "  def __init__(self, generator):\n",
        "    self.trainset = generator.group()\n",
        "    self.testset = generator.group_test()\n",
        "    self.labels = generator.labels\n",
        "    self.trainset_size = 50000\n",
        "    self.used = {label: [] for label in self.labels}\n",
        "    self.used_test = {label: [] for label in self.labels}\n",
        "\n",
        "  def extract(self, label, n):\n",
        "    #print(label, n)\n",
        "    if len(self.trainset[label]) > n:\n",
        "\n",
        "        extracted = self.trainset[label][:n]  # Extract data\n",
        "        self.used[label].extend(extracted)  # Move data to used\n",
        "        del self.trainset[label][:n]  # Remove from trainset\n",
        "        return extracted\n",
        "    else:\n",
        "        logging.warning('Insufficient data in label: {}'.format(label))\n",
        "        logging.warning('Dumping used data for reuse')\n",
        "\n",
        "        # Unmark data as used\n",
        "        for label in self.labels:\n",
        "            self.trainset[label].extend(self.used[label])\n",
        "            self.used[label] = []\n",
        "\n",
        "        # Extract replenished data\n",
        "        return self.extract(label, n)\n",
        "\n",
        "  def extract_test(self, label, n):\n",
        "    #print(label, n)\n",
        "    if len(self.testset[label]) > n:\n",
        "      extracted = self.testset[label][:n]  # Extract data\n",
        "      self.used_test[label].extend(extracted)  # Move data to used\n",
        "      del self.testset[label][:n]  # Remove from trainset\n",
        "      return extracted\n",
        "    else:\n",
        "      logging.warning('Insufficient data in label: {}'.format(label))\n",
        "      logging.warning('Dumping used data for reuse')\n",
        "\n",
        "        # Unmark data as used\n",
        "      for label in self.labels:\n",
        "          self.testset[label].extend(self.used_test[label])\n",
        "          self.used_test[label] = []\n",
        "\n",
        "        # Extract replenished data\n",
        "      return self.extract_test(label, n)\n",
        "\n",
        "\n",
        "  def get_partition(self, partition_size):\n",
        "    # Get an partition uniform across all labels\n",
        "\n",
        "    # Use uniform distribution\n",
        "    dist = dists.uniform(partition_size, len(self.labels))\n",
        "\n",
        "    partition = []  # Extract data according to distribution\n",
        "    for i, label in enumerate(self.labels):\n",
        "        partition.extend(self.extract(label, dist[i]))\n",
        "\n",
        "    # Shuffle data partition\n",
        "    random.shuffle(partition)\n",
        "\n",
        "    return partition\n",
        "\n",
        "  def get_testset(self):\n",
        "    # Return the entire testset\n",
        "    return self.testset\n",
        "\n",
        "\n",
        "class BiasLoader(Loader):\n",
        "\n",
        "\n",
        "  def get_partition(self, partition_size, bias, pref):\n",
        "    #print(\"in partition\")\n",
        "    # Get a non-uniform partition with a preference bias\n",
        "\n",
        "    # Calculate sizes of majorty and minority portions\n",
        "    majority = int(partition_size[0] * bias)\n",
        "    minority = partition_size[0] - majority\n",
        "\n",
        "    majority_test = int(partition_size[1] * bias)\n",
        "    minority_test = partition_size[1] - majority_test\n",
        "\n",
        "    # Calculate number of minor labels\n",
        "    len_minor_labels = len(self.labels) - 1\n",
        "    secondary = False\n",
        "\n",
        "    if secondary:\n",
        "        # Distribute to random secondary label\n",
        "        dist = [0] * len_minor_labels\n",
        "        dist[random.randint(0, len_minor_labels - 1)] = minority\n",
        "    else:\n",
        "        # Distribute among all minority labels\n",
        "        dist = uniform(minority, len_minor_labels)\n",
        "        dist_test = uniform(minority_test, len_minor_labels)\n",
        "\n",
        "    # Add majority data to distribution\n",
        "    dist.insert(self.labels.index(pref), majority)\n",
        "    dist_test.insert(self.labels.index(pref), majority_test)\n",
        "    #print(\"done\")\n",
        "\n",
        "    partition = []  # Extract data according to distribution\n",
        "    partition_test = []\n",
        "    for i, label in enumerate(self.labels):\n",
        "        #print(dist[i], label)\n",
        "        partition.extend(self.extract(label, dist[i]))\n",
        "        partition_test.extend(self.extract_test(label, dist_test[i]))\n",
        "        #print(partition)\n",
        "\n",
        "    # Shuffle data partition\n",
        "    random.shuffle(partition)\n",
        "    random.shuffle(partition_test)\n",
        "\n",
        "    return partition, partition_test\n",
        "\n",
        "\n",
        "class ShardLoader(Loader):\n",
        "  def create_shards(self):\n",
        "    total = self.num_clients * self.data_per_client\n",
        "    shard_size = int(self.trainset_size / total)\n",
        "\n",
        "    data = []\n",
        "    for _, items in self.trainset.items():\n",
        "            data.extend(items)\n",
        "\n",
        "    shards = [data[(i * shard_size):((i + 1) * shard_size)] for i in range(total)]\n",
        "    random.shuffle(shards)\n",
        "    self.shards = shards\n",
        "    self.used = []\n",
        "\n",
        "    logging.info('Created {} shards of size {}'.format(len(shards), shard_size))\n",
        "  def extract_shard(self):\n",
        "    shard = self.shards[0]\n",
        "    self.used.append(shard)\n",
        "    del self.shards[0]\n",
        "    return shard\n",
        "  def get_partition(self):\n",
        "\n",
        "    partition = []\n",
        "    for i in range(self.shard_per_client):\n",
        "        partition.extend(self.extract_shard())\n",
        "    random.shuffle(partition)\n",
        "\n",
        "    return partition\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def make_loaders(IID, bias, loader_type, num_clients):\n",
        "  generator = Generator()\n",
        "  data_path = './data'\n",
        "  generator.read(data_path)\n",
        "  labels = generator.labels\n",
        "\n",
        "  loader = {\n",
        "        'basic': Loader(generator),\n",
        "        'bias': BiasLoader(generator),\n",
        "        'shard': ShardLoader(generator)\n",
        "        }\n",
        "  trainloaders = []\n",
        "  testloaders = []\n",
        "  if not IID:\n",
        "    dist = {\n",
        "             \"uniform\": uniform(num_clients, len(labels)),\n",
        "            \"normal\": normal(num_clients, len(labels))\n",
        "            }['uniform']\n",
        "    random.shuffle(dist)\n",
        "  for client_id in range(num_clients):\n",
        "    if not IID:\n",
        "      if bias:\n",
        "        #print(\"here\")\n",
        "        bias = 0.4\n",
        "        pref = random.choices(labels, dist)[0]\n",
        "      elif shard:\n",
        "        print(\"shard\")\n",
        "\n",
        "    if loader_type != 'shard':\n",
        "      partition_size = [6000, 1000]\n",
        "    if loader_type == 'bias':\n",
        "      data, data_test = loader['bias'].get_partition(partition_size, bias, pref)\n",
        "\n",
        "      data_loader = DataLoader(data, batch_size=32, shuffle=True)\n",
        "      data_loader_test = DataLoader(data_test, batch_size=32, shuffle=True)\n",
        "      trainloaders.append(data_loader)\n",
        "      testloaders.append(data_loader_test)\n",
        "  return trainloaders, testloaders\n",
        "\n",
        "trainloaders, testloaders = make_loaders(False, True, 'bias', 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7tHUhxsfccp"
      },
      "source": [
        "# **DEFINE THE NEURAL NETWORK MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDGCKLiDgSFE"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torchvision.models as models\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Net, self).__init__()\n",
        "        # Load a pre-trained ResNet18 model\n",
        "        self.resnet18 = models.resnet18(pretrained=False)\n",
        "\n",
        "        ## Required for MNIST dataset since it only has one channel insted of 3\n",
        "        #self.resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "        # Replace the fully connected layer to match the number of classes\n",
        "        self.resnet18.fc = nn.Linear(self.resnet18.fc.in_features, num_classes)\n",
        "        #self.resnet18.fc.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.01, training=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "      out = self.resnet18(x)\n",
        "      return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXuXbZDnpSpe"
      },
      "source": [
        "# **DEFINE THE GOOGLENET MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPZl67lVpXGS"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "import torchvision.models as models\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Net, self).__init__()\n",
        "        # Load a pre-trained ResNet18 model\n",
        "        self.googlenet = models.googlenet()\n",
        "\n",
        "        # Replace the fully connected layer to match the number of classes\n",
        "        self.googlenet.fc = nn.Linear(self.googlenet.fc.in_features, num_classes)\n",
        "        self.googlenet.aux1.fc2 = nn.Linear(self.googlenet.aux1.fc2.in_features, 10)\n",
        "        self.googlenet.aux2.fc2 = nn.Linear(self.googlenet.aux2.fc2.in_features, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.googlenet(x)\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saFjPXzUC9_N"
      },
      "source": [
        "# **MOBILENET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SefcxCmeDB9r"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torchvision.models.mobilenet import mobilenet_v2\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Net, self).__init__()\n",
        "        # Load a pre-trained ResNet18 model\n",
        "        self.mobilenet = mobilenet_v2()\n",
        "        #self.mobilenet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        self.mobilenet.classifier[1] = nn.Linear(self.mobilenet.classifier[1].in_features, out_features=10)\n",
        "\n",
        "        # Replace the fully connected layer to match the number of classes\n",
        "        #self.mobilenet.fc = nn.Linear(self.mobilenet.fc.in_features, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mobilenet(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3igX5eLvhG3_"
      },
      "source": [
        "# **ALEXNET MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "lamfU446hLNU",
        "outputId": "408356da-ddef-4805-a262-6d3daaef3e96"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport torchvision.models as models\\nclass Net(nn.Module):\\n    def __init__(self, num_classes=10):\\n        super(Net, self).__init__()\\n        # Load a pre-trained ResNet18 model\\n        self.alexnet = models.alexnet(pretrained=False)\\n        # Replace the fully connected layer to match the number of classes\\n        num_features = self.alexnet.classifier[6].in_features\\n        self.alexnet.classifier[6] = nn.Linear(num_features, num_classes)\\n\\n\\n    def forward(self, x):\\n        return self.alexnet(x)\\n'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "import torchvision.models as models\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Net, self).__init__()\n",
        "        # Load a pre-trained ResNet18 model\n",
        "        self.alexnet = models.alexnet(pretrained=False)\n",
        "        # Replace the fully connected layer to match the number of classes\n",
        "        num_features = self.alexnet.classifier[6].in_features\n",
        "        self.alexnet.classifier[6] = nn.Linear(num_features, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.alexnet(x)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT2-PAZz8Zjy"
      },
      "source": [
        "# **DEFINE THE CNN MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfyFE_N58dN2"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes=10) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt3gVCqfK8m9"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 120)\n",
        "        self.fc1_drop = nn.Dropout()\n",
        "        self.fc2 = nn.Linear(120, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1_drop(self.fc1(x)))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:] # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhckAY_kt__u"
      },
      "source": [
        "# **AGGREGATION METHODS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2NczQ73uKbh"
      },
      "outputs": [],
      "source": [
        "\n",
        "def compute_accuracy(model, dataloader, get_confusion_matrix=False, moon_model=False, device=\"cpu\"):\n",
        "\n",
        "    was_training = False\n",
        "    if model.training:\n",
        "        model.eval()\n",
        "        was_training = True\n",
        "\n",
        "    true_labels_list, pred_labels_list = np.array([]), np.array([])\n",
        "\n",
        "    if type(dataloader) == type([1]):\n",
        "        pass\n",
        "    else:\n",
        "        dataloader = [dataloader]\n",
        "\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for tmp in dataloader:\n",
        "            for batch_idx, (x, target) in enumerate(tmp):\n",
        "                x, target = x.to(device), target.to(device,dtype=torch.int64)\n",
        "                if moon_model:\n",
        "                    _, _, out = model(x)\n",
        "                else:\n",
        "                    out = model(x)\n",
        "                _, pred_label = torch.max(out.data, 1)\n",
        "\n",
        "                total += x.data.size()[0]\n",
        "                correct += (pred_label == target.data).sum().item()\n",
        "\n",
        "                if device == \"cpu\":\n",
        "                    pred_labels_list = np.append(pred_labels_list, pred_label.numpy())\n",
        "                    true_labels_list = np.append(true_labels_list, target.data.numpy())\n",
        "                else:\n",
        "                    pred_labels_list = np.append(pred_labels_list, pred_label.cpu().numpy())\n",
        "                    true_labels_list = np.append(true_labels_list, target.data.cpu().numpy())\n",
        "\n",
        "    if get_confusion_matrix:\n",
        "        conf_matrix = confusion_matrix(true_labels_list, pred_labels_list)\n",
        "\n",
        "    if was_training:\n",
        "        model.train()\n",
        "\n",
        "    if get_confusion_matrix:\n",
        "        return correct/float(total), conf_matrix\n",
        "\n",
        "    return correct/float(total)\n",
        "def train_net_fedprox(net_id, net, global_net, train_dataloader, test_dataloader, epochs, lr, args_optimizer, mu, device=\"cpu\"):\n",
        "    logger.info('Training network %s' % str(net_id))\n",
        "    logger.info('n_training: %d' % len(train_dataloader))\n",
        "    logger.info('n_test: %d' % len(test_dataloader))\n",
        "\n",
        "    train_acc = compute_accuracy(net, train_dataloader, device=device)\n",
        "    test_acc, conf_matrix = compute_accuracy(net, test_dataloader, get_confusion_matrix=True, device=device)\n",
        "\n",
        "    logger.info('>> Pre-Training Training accuracy: {}'.format(train_acc))\n",
        "    logger.info('>> Pre-Training Test accuracy: {}'.format(test_acc))\n",
        "\n",
        "\n",
        "    if args_optimizer == 'adam':\n",
        "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr, weight_decay=args.reg)\n",
        "    elif args_optimizer == 'amsgrad':\n",
        "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr, weight_decay=args.reg,\n",
        "                               amsgrad=True)\n",
        "    elif args_optimizer == 'sgd':\n",
        "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    cnt = 0\n",
        "    # mu = 0.001\n",
        "    global_weight_collector = list(global_net.to(device).parameters())\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss_collector = []\n",
        "        for batch_idx, (x, target) in enumerate(train_dataloader):\n",
        "            x, target = x.to(device), target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            x.requires_grad = True\n",
        "            target.requires_grad = False\n",
        "            target = target.long()\n",
        "\n",
        "            out = net(x)\n",
        "            loss = criterion(out, target)\n",
        "\n",
        "            #for fedprox\n",
        "            fed_prox_reg = 0.0\n",
        "            for param_index, param in enumerate(net.parameters()):\n",
        "                fed_prox_reg += ((mu / 2) * torch.norm((param - global_weight_collector[param_index]))**2)\n",
        "            loss += fed_prox_reg\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            cnt += 1\n",
        "            epoch_loss_collector.append(loss.item())\n",
        "\n",
        "        epoch_loss = sum(epoch_loss_collector) / len(epoch_loss_collector)\n",
        "        logger.info('Epoch: %d Loss: %f' % (epoch, epoch_loss))\n",
        "\n",
        "        # if epoch % 10 == 0:\n",
        "        #     train_acc = compute_accuracy(net, train_dataloader, device=device)\n",
        "        #     test_acc, conf_matrix = compute_accuracy(net, test_dataloader, get_confusion_matrix=True, device=device)\n",
        "        #\n",
        "        #     logger.info('>> Training accuracy: %f' % train_acc)\n",
        "        #     logger.info('>> Test accuracy: %f' % test_acc)\n",
        "\n",
        "    train_acc = compute_accuracy(net, train_dataloader, device=device)\n",
        "    test_acc, conf_matrix = compute_accuracy(net, test_dataloader, get_confusion_matrix=True, device=device)\n",
        "\n",
        "    logger.info('>> Training accuracy: %f' % train_acc)\n",
        "    logger.info('>> Test accuracy: %f' % test_acc)\n",
        "\n",
        "    net.to('cpu')\n",
        "    logger.info(' ** Training complete **')\n",
        "    return train_acc, test_acc\n",
        "\n",
        "\n",
        "def train_net_scaffold(net_id, net, global_model, c_local, c_global, train_dataloader, test_dataloader, epochs, lr, args_optimizer, device=\"cpu\"):\n",
        "    logger.info('Training network %s' % str(net_id))\n",
        "\n",
        "    train_acc = compute_accuracy(net, train_dataloader, device=device)\n",
        "    test_acc, conf_matrix = compute_accuracy(net, test_dataloader, get_confusion_matrix=True, device=device)\n",
        "\n",
        "    logger.info('>> Pre-Training Training accuracy: {}'.format(train_acc))\n",
        "    logger.info('>> Pre-Training Test accuracy: {}'.format(test_acc))\n",
        "\n",
        "    if args_optimizer == 'adam':\n",
        "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr, weight_decay=args.reg)\n",
        "    elif args_optimizer == 'amsgrad':\n",
        "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr, weight_decay=args.reg,\n",
        "                               amsgrad=True)\n",
        "    elif args_optimizer == 'sgd':\n",
        "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    cnt = 0\n",
        "    if type(train_dataloader) == type([1]):\n",
        "        pass\n",
        "    else:\n",
        "        train_dataloader = [train_dataloader]\n",
        "\n",
        "    #writer = SummaryWriter()\n",
        "    '''\n",
        "    c_local.to(device)\n",
        "    c_global.to(device)\n",
        "    global_model.to(device)\n",
        "\n",
        "    c_global_para = c_global.state_dict()\n",
        "    c_local_para = c_local.state_dict()\n",
        "    '''\n",
        "    c_global_para = c_global\n",
        "    c_local_para = c_local\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss_collector = []\n",
        "        for tmp in train_dataloader:\n",
        "            for batch_idx, (x, target) in enumerate(tmp):\n",
        "                x, target = x.to(device), target.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                x.requires_grad = True\n",
        "                target.requires_grad = False\n",
        "                target = target.long()\n",
        "\n",
        "                out = net(x)\n",
        "                loss = criterion(out, target)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                net_para = net.state_dict()\n",
        "                for key in net_para:\n",
        "                    net_para[key] = net_para[key] - lr * (c_global_para[key] - c_local_para[key])\n",
        "                net.load_state_dict(net_para)\n",
        "\n",
        "                cnt += 1\n",
        "                epoch_loss_collector.append(loss.item())\n",
        "\n",
        "\n",
        "        epoch_loss = sum(epoch_loss_collector) / len(epoch_loss_collector)\n",
        "        logger.info('Epoch: %d Loss: %f' % (epoch, epoch_loss))\n",
        "\n",
        "    #c_new_para = c_local.state_dict()\n",
        "    c_new_para = c_local\n",
        "\n",
        "    #c_delta_para = copy.deepcopy(c_local.state_dict())\n",
        "    c_delta_para = copy.deepcopy(c_local)\n",
        "    global_model_para = global_model.state_dict()\n",
        "    net_para = net.state_dict()\n",
        "    for key in net_para:\n",
        "        c_new_para[key] = c_new_para[key] - c_global_para[key] + (global_model_para[key] - net_para[key]) / (cnt * lr)\n",
        "        c_delta_para[key] = c_new_para[key] - c_local_para[key]\n",
        "    #c_local.load_state_dict(c_new_para)\n",
        "    c_local = c_new_para\n",
        "\n",
        "\n",
        "    train_acc = compute_accuracy(net, train_dataloader, device=device)\n",
        "    test_acc, conf_matrix = compute_accuracy(net, test_dataloader, get_confusion_matrix=True, device=device)\n",
        "\n",
        "    logger.info('>> Training accuracy: %f' % train_acc)\n",
        "    logger.info('>> Test accuracy: %f' % test_acc)\n",
        "\n",
        "    net.to('cpu')\n",
        "    logger.info(' ** Training complete **')\n",
        "    return train_acc, test_acc, c_delta_para\n",
        "\n",
        "def train_net_fednova(net_id, net, global_model, train_dataloader, test_dataloader, epochs, lr, args_optimizer, device=\"cpu\"):\n",
        "    logger.info('Training network %s' % str(net_id))\n",
        "\n",
        "    train_acc = compute_accuracy(net, train_dataloader, device=device)\n",
        "    test_acc, conf_matrix = compute_accuracy(net, test_dataloader, get_confusion_matrix=True, device=device)\n",
        "\n",
        "    logger.info('>> Pre-Training Training accuracy: {}'.format(train_acc))\n",
        "    logger.info('>> Pre-Training Test accuracy: {}'.format(test_acc))\n",
        "\n",
        "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=lr, momentum=args.rho, weight_decay=args.reg)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    if type(train_dataloader) == type([1]):\n",
        "        pass\n",
        "    else:\n",
        "        train_dataloader = [train_dataloader]\n",
        "\n",
        "    #writer = SummaryWriter()\n",
        "\n",
        "\n",
        "    tau = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss_collector = []\n",
        "        for tmp in train_dataloader:\n",
        "            for batch_idx, (x, target) in enumerate(tmp):\n",
        "                x, target = x.to(device), target.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                x.requires_grad = True\n",
        "                target.requires_grad = False\n",
        "                target = target.long()\n",
        "\n",
        "                out = net(x)\n",
        "                loss = criterion(out, target)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                tau = tau + 1\n",
        "\n",
        "                epoch_loss_collector.append(loss.item())\n",
        "\n",
        "\n",
        "        epoch_loss = sum(epoch_loss_collector) / len(epoch_loss_collector)\n",
        "        logger.info('Epoch: %d Loss: %f' % (epoch, epoch_loss))\n",
        "\n",
        "    global_model.to(device)\n",
        "    a_i = (tau - args.rho * (1 - pow(args.rho, tau)) / (1 - args.rho)) / (1 - args.rho)\n",
        "    global_model.to(device)\n",
        "    global_model_para = global_model.state_dict()\n",
        "    net_para = net.state_dict()\n",
        "    norm_grad = copy.deepcopy(global_model.state_dict())\n",
        "    for key in norm_grad:\n",
        "        #norm_grad[key] = (global_model_para[key] - net_para[key]) / a_i\n",
        "        norm_grad[key] = torch.true_divide(global_model_para[key]-net_para[key], a_i)\n",
        "    train_acc = compute_accuracy(net, train_dataloader, device=device)\n",
        "    test_acc, conf_matrix = compute_accuracy(net, test_dataloader, get_confusion_matrix=True, device=device)\n",
        "\n",
        "    logger.info('>> Training accuracy: %f' % train_acc)\n",
        "    logger.info('>> Test accuracy: %f' % test_acc)\n",
        "\n",
        "    net.to('cpu')\n",
        "    logger.info(' ** Training complete **')\n",
        "    return train_acc, test_acc, a_i, norm_grad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12CnxUOYgfPd"
      },
      "source": [
        "# **CLIENT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B10HX4UEgkUA"
      },
      "outputs": [],
      "source": [
        "\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "from torch.optim.lr_scheduler import CyclicLR, ReduceLROnPlateau\n",
        "\n",
        "def calculate_accuracy(loader, model):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            images, labels = data\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "\n",
        "def train(net, node_id, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    #scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
        "\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            \"\"\"\n",
        "            if isinstance(outputs, tuple):\n",
        "              outputs, aux1, aux2 = outputs\n",
        "              loss = criterion(outputs, labels) + 0.3 * criterion(aux1, labels) + 0.3 * criterion(aux2, labels)\n",
        "            else:\n",
        "              loss = criterion(outputs, labels)\n",
        "            \"\"\"\n",
        "            ## no logits\n",
        "            ## For googlenet model\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            ## outputs.data\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "    loss /= len(trainloader.dataset)\n",
        "    acc = correct / total\n",
        "\n",
        "\n",
        "    model_path = f'models/node_{node_id}.pth'\n",
        "    torch.save(net.state_dict(), model_path)\n",
        "\n",
        "    return acc,loss\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            ## For googlenet model\n",
        "            \"\"\"\n",
        "            if isinstance(outputs, tuple):\n",
        "              outputs, _, _ = outputs\n",
        "            \"\"\"\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    #print(f\" test loss {loss}, accuracy {accuracy}\")\n",
        "    return  accuracy,loss\n",
        "\n",
        "\n",
        "class Client():\n",
        "    def __init__(self, net, node_id, trainloader,testloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.node_id = node_id\n",
        "        self.train_acc, self.test_acc= 0.0, 0.0\n",
        "        self.global_net = Net()\n",
        "\n",
        "\n",
        "    # def train_test(self):\n",
        "    #     self.train_acc,_=\n",
        "    #     self.test_acc\n",
        "\n",
        "    def set_bias(self, pref, bias):\n",
        "      self.bias = bias\n",
        "      self.pref = pref\n",
        "    def set_shard(self, shard):\n",
        "      self.shard = shard\n",
        "\n",
        "    def get_global_net(self):\n",
        "      return self.global_net\n",
        "\n",
        "    def setting_parameters(self,  parameters: List[np.ndarray]):\n",
        "        params_dict = zip(self.net.state_dict().items(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        self.net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "    def getting_parameters(self) -> List[np.ndarray]:\n",
        "        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n",
        "\n",
        "\n",
        "\n",
        "    #def get_parameters(self):\n",
        "        #return getting_parameters()\n",
        "\n",
        "    def fit(self, parameters):\n",
        "        self.setting_parameters(parameters)\n",
        "        train(self.net, self.node_id, self.trainloader, epochs=1)\n",
        "        return self.getting_parameters(), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters):\n",
        "        self.setting_parameters(parameters)\n",
        "        loss, accuracy = test(self.net, self.testloader)\n",
        "        return float(loss), len(self.testloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "    def Train_test_and_return_acc(self):\n",
        "        self.train_acc,_=train(self.net, self.node_id, self.trainloader, 1)\n",
        "        self.test_acc,_=test(self.net, self.testloader)\n",
        "        return self.train_acc, self.test_acc\n",
        "\n",
        "    def train_and_test_fedprox(self, global_net):\n",
        "      self.train_acc, self.test_acc = train_net_fedprox(self.node_id, self.net, global_net, self.trainloader, self.testloader, epochs=1, lr=0.01, args_optimizer='sgd', mu=0.001, device=\"cpu\")\n",
        "      return self.train_acc, self.test_acc\n",
        "\n",
        "    def train_and_test_scaffold(self, global_net, c_local, c_global):\n",
        "      self.train_acc, self.test_acc, c = train_net_scaffold(self.node_id, self.net, global_net, c_local, c_global, self.trainloader, self.testloader, epochs=1, lr=0.01, args_optimizer='sgd', device=\"cpu\")\n",
        "      return self.train_acc, self.test_acc, c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--NsOYGKgznP"
      },
      "source": [
        "# **DEFINE THE SERVER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EK9Mn9Iwg_be"
      },
      "outputs": [],
      "source": [
        "\n",
        "def divide_nested_list(nested_list, divisor):\n",
        "    for i in range(len(nested_list)):\n",
        "        if isinstance(nested_list[i], list):\n",
        "            divide_nested_list(nested_list[i], divisor)\n",
        "        else:\n",
        "            nested_list[i] /= divisor\n",
        "    return nested_list\n",
        "\n",
        "def zero_nested_list(nested_list):\n",
        "    for i in range(len(nested_list)):\n",
        "        if isinstance(nested_list[i], list):\n",
        "            zero_nested_list(nested_list[i])\n",
        "        else:\n",
        "            nested_list[i] = 0\n",
        "    return nested_list\n",
        "\n",
        "\n",
        "\n",
        "class Server:\n",
        "    def __init__(self):\n",
        "        self.models = []\n",
        "\n",
        "    def append_model(self, model: nn.Module):\n",
        "        if not isinstance(model, nn.Module):\n",
        "            raise TypeError(\"Only instances of nn.Module can be appended\")\n",
        "        self.models.append(model)\n",
        "\n",
        "    def aggregate(self):\n",
        "        if not self.models:\n",
        "            raise ValueError(\"No models added to the server.\")\n",
        "        print(\"model numbers:\", len(self.models))\n",
        "        # Initialize a model with the same architecture to store the average weights\n",
        "        #avg_model = Net(num_classes=10)\n",
        "        avg_model = Net()\n",
        "\n",
        "        # Iterate over each parameter in the average model\n",
        "        with torch.no_grad():\n",
        "            for param_name, avg_param in avg_model.named_parameters():\n",
        "                # Sum the corresponding parameters from all models\n",
        "                temp = torch.zeros_like(avg_param)\n",
        "                for model in self.models:\n",
        "                    model_param = dict(model.named_parameters())[param_name]\n",
        "                    temp += model_param.data\n",
        "                # Divide by the number of models to get the average\n",
        "                avg_param.copy_(temp / len(self.models))\n",
        "\n",
        "        return avg_model\n",
        "\n",
        "    def aggregate_prox(self, global_model):\n",
        "      if not self.models:\n",
        "            raise ValueError(\"No models added to the server.\")\n",
        "      print(\"model numbers:\", len(self.models))\n",
        "        # Initialize a model with the same architecture to store the average weights\n",
        "\n",
        "\n",
        "      global_state_dict = global_model.state_dict()\n",
        "      new_global_params = {key: torch.zeros_like(param) for key, param in global_state_dict.items()}\n",
        "      for client_model in self.models:\n",
        "        client_state_dict = client_model.state_dict()\n",
        "        for key in global_state_dict.keys():\n",
        "          new_global_params[key] += client_state_dict[key]\n",
        "\n",
        "      for key in global_state_dict.keys():\n",
        "        new_global_params[key] /= len(self.models)\n",
        "\n",
        "      global_model.load_state_dict(new_global_params)\n",
        "\n",
        "      return global_model\n",
        "\n",
        "    def aggregate_scaffold(self, global_model, client_controls, c):\n",
        "      new_global_weights = {}\n",
        "      new_global_controls = {}\n",
        "      for key in global_model.state_dict().keys():\n",
        "\n",
        "        print(self.models[0].state_dict())\n",
        "\n",
        "        for i in range(len(self.models)):\n",
        "          params = self.models[i].state_dict()\n",
        "          new_global_weights[key] = sum(params[key])\n",
        "          new_global_controls[key] = sum(params[key])\n",
        "        new_global_weights[key] / len(self.models)\n",
        "        new_global_controls[key] / len(self.models)\n",
        "\n",
        "      print(\"done\")\n",
        "      global_model.load_state_dict(new_global_weights)\n",
        "      print(\"global is fine\")\n",
        "      c.load_state_dict(new_global_controls)\n",
        "      print(\"c is fine\")\n",
        "      return global_model, c\n",
        "\n",
        "    def aggregate_nova(self):\n",
        "      return 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Rk9G9pqhIzI"
      },
      "source": [
        "# **CLUSTERING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji3fh24rJMAi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "from lxml import etree\n",
        "class Cosine_Clustering:\n",
        "\n",
        "    def __init__(self, num_nodes, clusteringRound):\n",
        "\n",
        "        self.round_number=clusteringRound\n",
        "        self.num_nodes=num_nodes\n",
        "    def load_model_weights(self,model_path):\n",
        "        return torch.load(model_path, map_location=torch.device('cpu'))\n",
        "\n",
        "    def compute_weight_difference(self,model_weights_prev, model_weights_curr):\n",
        "        weight_diff = {}\n",
        "\n",
        "        for key in model_weights_curr.keys():\n",
        "\n",
        "            if 'weight' in key:\n",
        "                # Focus only on the weight parameters, excluding biases\n",
        "                weight_diff[key] = model_weights_curr[key] - model_weights_prev[key]\n",
        "        return weight_diff\n",
        "\n",
        "\n",
        "    def normalize_distance(self,distances,num_nodes):\n",
        "        min1=np.min(np.ma.masked_equal(distances, 0))\n",
        "        max1=np.max(np.ma.masked_equal(distances, 0))\n",
        "        print(\"min , max\", min1, max1)\n",
        "\n",
        "        normal_distances=np.zeros((num_nodes, num_nodes))\n",
        "\n",
        "        for i in range (num_nodes):\n",
        "            normal_distances[i][i]=0\n",
        "            for j in range (i+1,num_nodes):\n",
        "                normal_distances[i][j]=normal_distances[j][i]=(distances[i][j]-min1)/(max1-min1)\n",
        "                print(normal_distances)\n",
        "            #print(\"after:\",item, distances[item])\n",
        "        return normal_distances\n",
        "\n",
        "    def cosine_similarity(self,weights_diff1, weights_diff2):\n",
        "        dot_product = 0.0\n",
        "        norm1 = 0.0\n",
        "        norm2 = 0.0\n",
        "        for key in weights_diff1.keys():\n",
        "            dot_product += (weights_diff1[key] * weights_diff2[key]).sum().item()\n",
        "            norm1 += (weights_diff1[key] ** 2).sum().item()\n",
        "            norm2 += (weights_diff2[key] ** 2).sum().item()\n",
        "        if norm1 == 0 or norm2 == 0:  # Avoid division by zero\n",
        "            return 0\n",
        "        return dot_product / (np.sqrt(norm1) * np.sqrt(norm2))\n",
        "\n",
        "    def calculate_cosine_similarities(self, round_number, num_nodes):\n",
        "        weight_diffs = []\n",
        "        similarities = {}\n",
        "\n",
        "        # Load and compute weight differences for each node between rounds r-1 and r\n",
        "        for node_id in range(num_nodes):\n",
        "            model_path_prev= f\"models/node_{node_id}_round_{self.round_number-1}.pth\"\n",
        "            model_path_curr = f\"models/node_{node_id}_round_{self.round_number}.pth\"\n",
        "            model_weights_prev = self.load_model_weights(model_path_prev)\n",
        "            model_weights_curr = self.load_model_weights(model_path_curr)\n",
        "            weight_diffs.append(self.compute_weight_difference(model_weights_prev, model_weights_curr))\n",
        "\n",
        "        # Calculate cosine similarities between weight differences of all pairs of nodes\n",
        "        distances=np.zeros((num_nodes, num_nodes))\n",
        "        # Calculate Euclidean distances between model weights of all pairs of nodes\n",
        "        for i in range(num_nodes):\n",
        "            distances[i][i]=0\n",
        "            for j in range(i+1,num_nodes):\n",
        "                sim = self.cosine_similarity(weight_diffs[i], weight_diffs[j])\n",
        "                distances[i][j] = abs(sim)\n",
        "                print(f\"Cosine similarity between Node {i} and Node {j} for Round {round_number}: {sim}\")\n",
        "        return distances,weight_diffs\n",
        "\n",
        "    # Example usage\n",
        "\n",
        "\n",
        "    def Clustering(self):\n",
        "        import numpy as np\n",
        "        from sklearn.cluster import DBSCAN\n",
        "        from sklearn.manifold import MDS  # Optional for visualization\n",
        "        import matplotlib.pyplot as plt  # Optional for visualization\n",
        "          # Adjust path to your models directory\n",
        "          # Calculate for round 2 (and it uses round 1 for previous weights)\n",
        "        distances,weight_diffs=self.calculate_cosine_similarities(self.round_number, self.num_nodes)\n",
        "        #print(\"bofore normal\", distances)\n",
        "        normal_distances=self.normalize_distance(distances,self.num_nodes)\n",
        "        print(\"after norml\",normal_distances)\n",
        "\n",
        "        # Assuming 'normal_distances' is your precomputed 10x10 symmetric distance matrix\n",
        "        # For demonstration, creating a random symmetric distance matrix\n",
        "        normal_distances = (normal_distances + normal_distances.T) / 2\n",
        "        np.fill_diagonal(normal_distances, 0)\n",
        "\n",
        "        # Run DBSCAN\n",
        "        dbscan = DBSCAN(eps=0.1, min_samples=1, metric=\"precomputed\")\n",
        "        clusters = dbscan.fit_predict(normal_distances)\n",
        "\n",
        "        # Find the maximum cluster label from the assigned labels\n",
        "        max_label = max(clusters)\n",
        "\n",
        "        # Assign unique positive labels to noise points (initially labeled as -1)\n",
        "        noise_indices = clusters == -1\n",
        "        unique_noise_labels = np.arange(max_label + 1, max_label + 1 + np.sum(noise_indices))\n",
        "        clusters[noise_indices] = unique_noise_labels\n",
        "\n",
        "        # Create XML document using lxml\n",
        "        root = etree.Element(\"Clusters\")\n",
        "        for cluster_id in np.unique(clusters):\n",
        "            cluster_element = etree.SubElement(root, \"Cluster\", id=str(cluster_id))\n",
        "            members = np.where(clusters == cluster_id)[0]\n",
        "            for member in members:\n",
        "                etree.SubElement(cluster_element, \"Node\", id=str(member))\n",
        "\n",
        "        # Convert to XML tree and pretty print to a file\n",
        "        tree = etree.ElementTree(root)\n",
        "        tree.write(\"clusters_cosine.xml\", pretty_print=True, xml_declaration=True, encoding='UTF-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXonqs9dhN0k"
      },
      "outputs": [],
      "source": [
        "#import pandas as pd\n",
        "\n",
        "from scipy import spatial\n",
        "def find_num_cluster(clusters):\n",
        "  num_cluster = []\n",
        "  for item in clusters:\n",
        "    if item not in num_cluster:\n",
        "      num_cluster.append(item)\n",
        "  return len(num_cluster)\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "\n",
        "class Clustering():\n",
        "    def __init__(self, clients,trainLoaders,percentage,Cluster_number):\n",
        "        #self.models=models\n",
        "        self.clients=clients\n",
        "        self.num_nodes=len(clients)\n",
        "        self. percentage=percentage\n",
        "        self.Mask_Number=0\n",
        "        self.maskIds=[]\n",
        "        self.grads = []\n",
        "        #self.sensitivity_values=[self.calculate_sensitivity(models[i],trainLoaders[i]) for i in range (len(models))]\n",
        "        self.load_and_claculate_sensitivity(trainLoaders)\n",
        "\n",
        "        #df = pd.read_csv(\"clients.csv\")\n",
        "        #self.maskIds=[self.get_maskIds(self.sensitivity_values[i]) for i in range (self.num_nodes)]\n",
        "        #= df[\"mask_IDs\"]\n",
        "        #print(\"Mask IDs:\",self.maskIds)\n",
        "        self.Cluster_number=Cluster_number\n",
        "\n",
        "        self.distances=self.calculate_distance()\n",
        "        #print(\"Mask_Number:\",self.Mask_Number)\n",
        "        #print(\"dist:\",self.distances)\n",
        "        self.Clusters=self.Make_Clusters()\n",
        "\n",
        "\n",
        "    def assign_save_ids_to_weights(self, model):\n",
        "        weight_id_map = {}\n",
        "        weight_id = 0\n",
        "        for name, parameter in model.named_parameters():\n",
        "            if 'bias' not in name and parameter.requires_grad:  # Exclude biases\n",
        "                weight_id_map[name] = {}\n",
        "                num_weights = parameter.numel()\n",
        "                for i in range(num_weights):\n",
        "                    weight_id_map[name][i] = weight_id\n",
        "                    weight_id += 1\n",
        "        filename=\"weight_to_id.csv\"\n",
        "        if not os.path.exists(filename):\n",
        "            with open(filename, 'w', newline='') as csvfile:\n",
        "                writer = csv.writer(csvfile)\n",
        "                writer.writerow(['Layer', 'Weight Index', 'Weight ID'])\n",
        "                for layer_name, indices in weight_id_map.items():\n",
        "                    for index, weight_id in indices.items():\n",
        "                        writer.writerow([layer_name, index, weight_id])\n",
        "        return weight_id_map\n",
        "\n",
        "    def load_and_claculate_sensitivity(self, trainLoaders):\n",
        "        for cid in self.clients:\n",
        "            model = load_torch_model(cid)\n",
        "            sensitivity_value = self.calculate_sensitivity(model, trainLoaders[int(cid)])\n",
        "            gradients = [weight for weight in sensitivity_value.values()]\n",
        "\n",
        "            #gradients = [grad for grad in gradients if grad <= 0.004]\n",
        "            #print(\"max grad\", max(gradients))\n",
        "            #skew, kurtosis = visualize_gradients_and_stats(gradients)\n",
        "            #plot_gradient_spectrum(gradients)\n",
        "            weight_id_map = self.assign_save_ids_to_weights(load_torch_model(0))\n",
        "            mask_ID, weights = self.get_maskIds(sensitivity_value, weight_id_map)\n",
        "            #print(\"mask_id\", mask_ID)\n",
        "            self.maskIds.append(mask_ID)\n",
        "            self.grads.append(weights)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def calculate_sensitivity(self, model, dataloader):\n",
        "    # Ensure the model is in training mode to enable gradient computation\n",
        "        model.train()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Initialize a dictionary to store the sum of gradients for each parameter\n",
        "        gradient_sums = {}\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'bias' not in name:  # Skip bias parameters\n",
        "                gradient_sums[name] = 0.0\n",
        "                param.requires_grad_(True)\n",
        "\n",
        "        # Iterate over the DataLoader\n",
        "        for inputs, labels in dataloader:\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            ## For googlenet model\n",
        "            \"\"\"\n",
        "            if isinstance(outputs, tuple):\n",
        "              outputs, aux1, aux2 = outputs\n",
        "            \"\"\"\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            model.zero_grad()  # Reset gradients to zero before backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            sensitivities = {}\n",
        "\n",
        "            # Accumulate the sum of absolute gradients for each parameter\n",
        "            for name, parameter in model.named_parameters():\n",
        "\n",
        "                if 'bias' not in name and parameter.requires_grad:  # Exclude biases\n",
        "\n",
        "\n",
        "                    #print(\"param\", parameter)\n",
        "                    #print(\"grad\", parameter.grad)\n",
        "                    ## For googlenet model\n",
        "                    \"\"\"\n",
        "                    if parameter.grad is not None:\n",
        "                      grads = parameter.grad.abs().view(-1).cpu().numpy()\n",
        "                    \"\"\"\n",
        "                    grads = parameter.grad.abs().view(-1).cpu().numpy()\n",
        "                    #grads = parameter.abs().view(-1).cpu().detach().numpy()\n",
        "                    for i, grad in enumerate(grads):\n",
        "                        sensitivities[(name, i)] = grad\n",
        "\n",
        "            return sensitivities\n",
        "\n",
        "    def get_maskIds(self,sensitivity_values_node, weight_id_map):\n",
        "        num_weights = len(sensitivity_values_node)\n",
        "        top_k = int(np.ceil(self.percentage * num_weights / 100))\n",
        "        self.Mask_Number=top_k\n",
        "        sorted_weights = sorted(sensitivity_values_node.items(),\n",
        "                                key=lambda item: item[1], reverse=True)[:top_k]\n",
        "        weights = [weight for (layer, index), weight in sensitivity_values_node.items()]\n",
        "\n",
        "        top_weight_ids = [weight_id_map[layer][index] for (layer, index), _ in sorted_weights]\n",
        "        return top_weight_ids, weights\n",
        "\n",
        "\n",
        "    def normalize_distance(self, distances):\n",
        "        min1 = np.min(np.ma.masked_equal(distances, 0))\n",
        "        max1 = np.max(np.ma.masked_equal(distances, 0))\n",
        "        #print(\"min,max:\",min1,max1)\n",
        "        normal_distances = np.zeros((self.num_nodes, self.num_nodes))\n",
        "\n",
        "        for i in range(self.num_nodes):\n",
        "            normal_distances[i][i] = 0\n",
        "            for j in range(i+1, self.num_nodes):\n",
        "                normal_distances[i][j] = normal_distances[j][i] = (distances[i][j]-min1)/(max1-min1)\n",
        "\n",
        "        return normal_distances\n",
        "\n",
        "    def normalize(self, distances, sensitive):\n",
        "        normal_distances = np.zeros((self.num_nodes, self.num_nodes))\n",
        "        for i in range(self.num_nodes):\n",
        "            normal_distances[i][i] = 0\n",
        "            for j in range(i+1, self.num_nodes):\n",
        "                normal_distances[i][j] = normal_distances[j][i] = distances[i][j]/len(sensitive)\n",
        "\n",
        "        return normal_distances\n",
        "\n",
        "    def calculate_common_ids(self, index1, index2):\n",
        "        arr1=self.maskIds[index1]\n",
        "        arr2=self.maskIds[index2]\n",
        "        sarr1=set(arr1)\n",
        "        sarr2=set(arr2)\n",
        "        inter=sarr1.intersection(sarr2)\n",
        "        similarity1=len(inter)\n",
        "        #print(\"similarity for----------------\",sarr1,sarr2,inter,similarity1)\n",
        "        return similarity1\n",
        "\n",
        "    def cosine_similarity(self,index1, index2):\n",
        "        dot_product = 0.0\n",
        "        norm1 = 0.0\n",
        "        norm2 = 0.0\n",
        "        arr1=self.maskIds[index1]\n",
        "        arr2=self.maskIds[index2]\n",
        "        for i  in range(len(self.maskIds)):\n",
        "            dot_product += (arr1[i] * arr2[i]).sum().item()\n",
        "            norm1 += (arr1[i] ** 2).sum().item()\n",
        "            norm2 += (arr2[i] ** 2).sum().item()\n",
        "        if norm1 == 0 or norm2 == 0:  # Avoid division by zero\n",
        "            return 0\n",
        "        return dot_product / (np.sqrt(norm1) * np.sqrt(norm2))\n",
        "\n",
        "    def calculate_distance(self, ):\n",
        "        similarity_matrix = np.zeros((self.num_nodes, self.num_nodes))\n",
        "\n",
        "        for i in range(self.num_nodes):\n",
        "            for j in range(i + 1, self.num_nodes):\n",
        "                similarity = self.calculate_common_ids(i,j)\n",
        "                #arr1=self.grads[i]\n",
        "                #arr2=self.grads[j]\n",
        "\n",
        "                #similarity = 1 - spatial.distance.cosine(arr1, arr2)\n",
        "                similarity_matrix[i, j] = similarity\n",
        "                similarity_matrix[j, i] = similarity\n",
        "                #print(f'similarity{i},{j} is {similarity_matrix[i, j]}')\n",
        "            similarity_matrix[i, i] = self.Mask_Number\n",
        "\n",
        "        #print(\"similarity:\",similarity_matrix)\n",
        "        max_distances =  - similarity_matrix\n",
        "        distances = self.Mask_Number-similarity_matrix\n",
        "        #print(\"before normalized:\",distances)\n",
        "        #normal_distances = self.normalize_distance(distances)\n",
        "        return distances\n",
        "\n",
        "    def index_to_value(self,groups):\n",
        "        value_groups=[]\n",
        "        for group in groups:\n",
        "          list1=[]\n",
        "          for index in group:\n",
        "              list1.append(self.clients[index])\n",
        "          value_groups.append(list1)\n",
        "        return value_groups\n",
        "\n",
        "    def Make_Clusters(self):\n",
        "        normal_distances = (self.distances + self.distances.T) / 2\n",
        "        #print(f'normal distances:{normal_distances}')\n",
        "        np.fill_diagonal(normal_distances, 0)\n",
        "        print(self.normalize(normal_distances, self.maskIds[0]))\n",
        "\n",
        "        #kmeans = KMeans(n_clusters=self.Cluster_number)\n",
        "        affinity_propagation = AffinityPropagation(affinity='precomputed')\n",
        "        #clusters = kmeans.fit_predict(normal_distances)\n",
        "        normal_distances = -normal_distances\n",
        "        clusters = affinity_propagation.fit_predict(normal_distances)\n",
        "        print(f'cluster results:{clusters}')\n",
        "        # Find the maximum cluster label from the assigned labels\n",
        "        max_label = max(clusters)\n",
        "\n",
        "        # Assign unique positive labels to noise points (initially labeled as -1)\n",
        "        noise_indices = clusters == -1\n",
        "        unique_noise_labels = np.arange(max_label + 1, max_label + 1 + np.sum(noise_indices))\n",
        "        clusters[noise_indices] = unique_noise_labels\n",
        "        cluster_list = [np.where(clusters == cluster_id)[0].tolist() for cluster_id in range(find_num_cluster(clusters))]\n",
        "        #print(\"clusters with location:\",cluster_list)\n",
        "        #print(\"clusters with clients:\", self.index_to_value(cluster_list))\n",
        "        cluster_list=self.index_to_value(cluster_list)\n",
        "        return cluster_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBHOk3RcheAo"
      },
      "source": [
        "# **FL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s_crcUnhg4C"
      },
      "outputs": [],
      "source": [
        "class FL():\n",
        "\n",
        "    def __init__(self, clients,client_initial_models,round_number, trainloaders, testloaders,  Sensitivity_percentage):\n",
        "        self.clients=clients\n",
        "        self.num_clients=len(clients)\n",
        "        self.client_initial_models=client_initial_models\n",
        "        self.Sensitivity_percentage =Sensitivity_percentage\n",
        "        self.trainloaders=trainloaders\n",
        "        self.testloaders=testloaders\n",
        "        self.round_number=round_number\n",
        "        self.global_model=None\n",
        "        self.clustering_result=None\n",
        "        self.client_obj_list=[]\n",
        "        self.accuracies = {}\n",
        "        self.training()\n",
        "\n",
        "\n",
        "    def training(self):\n",
        "      #print(\"-----------FL class->training\")\n",
        "      #print(\"len clients\", len(self.clients))\n",
        "      #print(\"len models\", len(self.client_initial_models))\n",
        "      for cid in self.clients:\n",
        "        print(\"cid is:\", cid)\n",
        "        #print(\"trainloader\", len(self.trainloaders))\n",
        "        client=Client(self.client_initial_models[self.clients.index(int(cid))],cid, self.trainloaders[int(cid)], self.testloaders[int(cid)])\n",
        "        self.client_obj_list.append(client)\n",
        "\n",
        "\n",
        "\n",
        "      global_model = Net()\n",
        "\n",
        "      os.makedirs('models', exist_ok=True)\n",
        "      #c = {key: torch.zeros_like(val) for key, val in global_model.state_dict().items()}\n",
        "      #client_controls = [{key: torch.zeros_like(val) for key, val in global_model.state_dict().items()} for _ in range(len(self.clients))]\n",
        "\n",
        "      start_time = datetime.now()\n",
        "      for r in range(self.round_number):\n",
        "          print(f\"\\nRound {r+1}/{self.round_number}\")\n",
        "          server=Server()\n",
        "          global_accuracy=0\n",
        "\n",
        "          index=0\n",
        "          for cid in self.clients:\n",
        "                #self.client_obj_list[cid].net=copy.deepcopy(global_model)\n",
        "                #self.client_obj_list[cid]=client\n",
        "\n",
        "\n",
        "                #client.setting_parameters(global_model)\n",
        "              train_acc,test_acc=self.client_obj_list[self.clients.index(cid)].Train_test_and_return_acc()\n",
        "              #train_acc, test_acc = self.client_obj_list[self.clients.index(cid)].train_and_test_fedprox(global_model)\n",
        "              #train_acc, test_acc, c = self.client_obj_list[self.clients.index(cid)].train_and_test_scaffold(global_model, client_controls[cid], c)\n",
        "              print(f'node {cid}: train_acc: {train_acc}, test_acc:{test_acc}')\n",
        "              with open(log_file, 'a') as f:\n",
        "                f.write(f\"\\nNode {cid} - Round {r+1}: Train Accuracy: {train_acc}%, Test Accuracy: {test_acc}%\")\n",
        "              global_accuracy += test_acc\n",
        "              self.accuracies[r+1] = global_accuracy\n",
        "              server.append_model(self.client_obj_list[self.clients.index(cid)].net)\n",
        "\n",
        "\n",
        "\n",
        "          global_model= server.aggregate()\n",
        "\n",
        "          #global_model = server.aggregate_prox(global_model)\n",
        "          end_time = datetime.now()\n",
        "          execution_time = end_time - start_time\n",
        "          print(\"time\", execution_time)\n",
        "          with open(log_file, 'a') as f:\n",
        "            f.write(f\"\\n Exe FL Round Time: {execution_time}\")\n",
        "          #global_model, c = server.aggregate_scaffold(global_model, client_controls, c)\n",
        "          print(\"global acc:\",global_accuracy/self. num_clients)\n",
        "          with open(log_file, 'a') as f:\n",
        "            f.write(f\"\\nGlobal Model of {self.num_clients}- Round {r+1}: Test Accuracy is: {global_accuracy/self.num_clients}%\")\n",
        "          for cid in self.clients:\n",
        "              self.client_obj_list[self.clients.index(cid)].net=copy.deepcopy(global_model)\n",
        "\n",
        "        #filtered_c =  [sublist for sublist in c if sublist]\n",
        "      self.global_model=global_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OXgbb0Xio0d"
      },
      "source": [
        "# **VISUALIZE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_kl09xPir4-"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Visualizer():\n",
        "    def __init__(self, trainloaders):\n",
        "        self.trainloaders = trainloaders\n",
        "\n",
        "    def count_classes(self):\n",
        "        # Initialize a list to store class counts for each DataLoader\n",
        "        class_counts = []\n",
        "        # CIFAR-10 has 10 classes, indexed 0-9\n",
        "        for loader in self.trainloaders:\n",
        "            # Initialize counts for this DataLoader\n",
        "            counts = np.zeros(10, dtype=int)\n",
        "            # Iterate through all batches in the DataLoader\n",
        "            for _, labels in loader:\n",
        "                # Count occurrences of each class in this batch and add to counts\n",
        "                for label in labels:\n",
        "                    counts[label] += 1\n",
        "            class_counts.append(counts)\n",
        "        return class_counts\n",
        "\n",
        "    def plot_class_distribution(self):\n",
        "        class_counts=self.count_classes()\n",
        "        num_classes = 10\n",
        "        labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "        labels.reverse()\n",
        "        num_nodes = len(class_counts)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(9, 5))\n",
        "        width = 0.35  # the width of the bars\n",
        "\n",
        "        # Create an array with the positions of each bar along the x-axis\n",
        "        x = np.arange(num_classes)\n",
        "\n",
        "        # Plot data\n",
        "        for i in range(num_nodes):\n",
        "            # Compute the bottom positions for the stacked bars\n",
        "            bottom = np.sum(class_counts[:i], axis=0) if i > 0 else np.zeros(num_classes)\n",
        "            ax.bar(x, class_counts[i], width, bottom=bottom, label=f'Client {i+1}')\n",
        "\n",
        "        ax.set_xlabel('Classes')\n",
        "        ax.set_ylabel('Number of Samples')\n",
        "        ax.set_title('Distribution of CIFAR-10 Classes Across Different Nodes')\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(labels)\n",
        "        ax.legend(title=\"Node\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    # Example usage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0WVVz4uiyhN"
      },
      "source": [
        "# **LOAD TORCH**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC55t6aNi0uj"
      },
      "outputs": [],
      "source": [
        "def load_torch_model(node_id):\n",
        "  model_path = f'models/node_{node_id}.pth'\n",
        "  model = torch.load(model_path)\n",
        "  return model\n",
        "\n",
        "def save_torch_model(model, node_id):\n",
        "  model_path = f'models/node_{node_id}.pth'\n",
        "  torch.save(model, model_path)\n",
        "\n",
        "def save_model_param(model, node_id, round_number):\n",
        "  model_path = f'models/node_{node_id}_round_{round_number}.pth'\n",
        "  torch.save(model.state_dict(),model_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UiEMscJAVtp"
      },
      "source": [
        "**LOAD** **DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONxVf6P4AUpa"
      },
      "outputs": [],
      "source": [
        "def load_and_prepare_data():\n",
        "\n",
        "    #c = ClusteredDataset()\n",
        "    #trainloaders = c.get_loaders(60000, 600, 200, 2, train=True)\n",
        "    #testloaders = c.get_loaders(10000, 200, 100, 2, train=False)\n",
        "    #trainloaders, testloaders = get_loaders(10)\n",
        "    #print(len(trainloaders) , len(testloaders))\n",
        "    dataset = Dataset()\n",
        "    train_data, test_data = dataset.load_CIFAR10_dataset()\n",
        "    #train_data, test_data = dataset.load_MNIST_dataset()\n",
        "    #train_data, test_data = dataset.load_FashionMNIST_dataset()\n",
        "\n",
        "    #print(\"data\", len(train_data), len(test_data))\n",
        "    #train_indices , train_idx = dataset.noniid_split(train_data, num_classes, num_clients, num_shards_per_class)\n",
        "    #test_indices = dataset.partition_test_data_based_on_train(test_data, train_idx, num_classes, num_clients, num_shards_per_class)\n",
        "\n",
        "    #trainloaders = dataset.get_dataloaders(train_data, train_indices, 32)\n",
        "    #testloaders = dataset.get_dataloaders(test_data, test_indices, 32)\n",
        "    trainloaders, testloaders = dataset.load_shards_from_xml_file(\"shards.xml\", train_data,test_data, 10)\n",
        "    print(\"final \", len(trainloaders), len(testloaders))\n",
        "    '''\n",
        "    for node_id in range(num_clients):\n",
        "\n",
        "        data_path = f'./data/train_node_{node_id}_data.pth'\n",
        "        torch.save(trainloaders[node_id], data_path)\n",
        "\n",
        "        data_path = f'./data/test_node_{node_id}_data.pth'\n",
        "        torch.save(testloaders[node_id], data_path)\n",
        "    '''\n",
        "\n",
        "    print(\"done saving\")\n",
        "    return trainloaders, testloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z2kK3foAfRg"
      },
      "source": [
        "\n",
        "\n",
        "**PARAMETERS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On2FNEI-AeZw"
      },
      "outputs": [],
      "source": [
        "num_shards_per_class = 20\n",
        "num_clients = 10\n",
        "num_classes=10\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "Clustering_method=\"Mask\"# Weight, Mask\n",
        "Clustering_period = 5\n",
        "cluster_number=3\n",
        "Round_Epochs = 3\n",
        "#Node_numbers = 50\n",
        "FL_rounds = 10\n",
        "Sensitivity_percentage = 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5L0J8nHOuB5"
      },
      "source": [
        "**LOAD** **DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ynR25wDOs0h",
        "outputId": "1a910c90-71df-4db4-d091-895e6ef18910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:18<00:00, 9256911.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "final  10 10\n",
            "done saving\n"
          ]
        }
      ],
      "source": [
        "trainloaders,testloaders=load_and_prepare_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "cJQC2Bl2BOxT",
        "outputId": "036fb8f2-6b53-4cb2-8228-1dae907a2857"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "Visualizer(trainloaders).plot_class_distribution()\n",
        "Visualizer(testloaders).plot_class_distribution()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2Va_TnLISwp"
      },
      "source": [
        "# **PLOT GRADIENTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CHrBgYSBhxep",
        "outputId": "9b03d708-f924-4b68-c775-c933b7a58bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "---------Clustering step 0\n",
            "-------------in initial genertaio\n",
            "cluster [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "clientIDs [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "len_client_models(should be 10): 0\n",
            " ---in making new FL----cluster models len: 10 cluster IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "cid is: 0\n",
            "cid is: 1\n",
            "cid is: 2\n",
            "cid is: 3\n",
            "cid is: 4\n",
            "cid is: 5\n",
            "cid is: 6\n",
            "cid is: 7\n",
            "cid is: 8\n",
            "cid is: 9\n",
            "\n",
            "Round 1/10\n",
            "node 0: train_acc: 0.65, test_acc:0.44\n",
            "node 1: train_acc: 0.595, test_acc:0.6\n",
            "node 2: train_acc: 0.637, test_acc:0.42\n",
            "node 3: train_acc: 0.599, test_acc:0.56\n",
            "node 4: train_acc: 0.463, test_acc:0.53\n",
            "node 5: train_acc: 0.472, test_acc:0.38\n",
            "node 6: train_acc: 0.504, test_acc:0.51\n",
            "node 7: train_acc: 0.545, test_acc:0.435\n",
            "node 8: train_acc: 0.67, test_acc:0.575\n",
            "node 9: train_acc: 0.56, test_acc:0.435\n",
            "model numbers: 10\n",
            "time 0:00:44.343245\n",
            "global acc: 0.4884999999999999\n",
            "\n",
            "Round 2/10\n",
            "node 0: train_acc: 0.647, test_acc:0.265\n",
            "node 1: train_acc: 0.622, test_acc:0.5\n",
            "node 2: train_acc: 0.611, test_acc:0.25\n",
            "node 3: train_acc: 0.606, test_acc:0.345\n",
            "node 4: train_acc: 0.494, test_acc:0.25\n",
            "node 5: train_acc: 0.498, test_acc:0.25\n",
            "node 6: train_acc: 0.536, test_acc:0.5\n",
            "node 7: train_acc: 0.554, test_acc:0.44\n",
            "node 8: train_acc: 0.611, test_acc:0.655\n",
            "node 9: train_acc: 0.537, test_acc:0.365\n",
            "model numbers: 10\n",
            "time 0:01:28.289957\n",
            "global acc: 0.382\n",
            "\n",
            "Round 3/10\n",
            "node 0: train_acc: 0.732, test_acc:0.25\n",
            "node 1: train_acc: 0.631, test_acc:0.5\n",
            "node 2: train_acc: 0.675, test_acc:0.25\n",
            "node 3: train_acc: 0.658, test_acc:0.5\n",
            "node 4: train_acc: 0.491, test_acc:0.25\n",
            "node 5: train_acc: 0.525, test_acc:0.25\n",
            "node 6: train_acc: 0.494, test_acc:0.5\n",
            "node 7: train_acc: 0.521, test_acc:0.39\n",
            "node 8: train_acc: 0.691, test_acc:0.585\n",
            "time 0:02:08.719559\n",
            "global acc: 0.381\n",
            "\n",
            "Round 4/10\n",
            "node 0: train_acc: 0.72, test_acc:0.28\n",
            "node 1: train_acc: 0.657, test_acc:0.5\n",
            "node 2: train_acc: 0.621, test_acc:0.25\n",
            "node 3: train_acc: 0.66, test_acc:0.345\n",
            "node 4: train_acc: 0.534, test_acc:0.25\n",
            "node 5: train_acc: 0.539, test_acc:0.265\n",
            "node 6: train_acc: 0.512, test_acc:0.5\n",
            "node 7: train_acc: 0.594, test_acc:0.25\n",
            "node 8: train_acc: 0.678, test_acc:0.585\n",
            "node 9: train_acc: 0.568, test_acc:0.27\n",
            "model numbers: 10\n",
            "time 0:02:48.477557\n",
            "global acc: 0.34950000000000003\n",
            "\n",
            "Round 5/10\n",
            "node 0: train_acc: 0.751, test_acc:0.41\n",
            "node 1: train_acc: 0.68, test_acc:0.5\n",
            "node 2: train_acc: 0.74, test_acc:0.31\n",
            "node 3: train_acc: 0.703, test_acc:0.29\n",
            "node 4: train_acc: 0.524, test_acc:0.26\n",
            "node 5: train_acc: 0.538, test_acc:0.27\n",
            "node 6: train_acc: 0.553, test_acc:0.5\n",
            "node 7: train_acc: 0.593, test_acc:0.4\n",
            "node 8: train_acc: 0.737, test_acc:0.66\n",
            "node 9: train_acc: 0.62, test_acc:0.31\n",
            "model numbers: 10\n",
            "time 0:03:28.848313\n",
            "global acc: 0.391\n",
            "\n",
            "Round 6/10\n",
            "node 0: train_acc: 0.758, test_acc:0.405\n",
            "node 1: train_acc: 0.738, test_acc:0.505\n",
            "node 2: train_acc: 0.708, test_acc:0.395\n",
            "node 3: train_acc: 0.686, test_acc:0.34\n",
            "node 4: train_acc: 0.5, test_acc:0.25\n",
            "node 5: train_acc: 0.555, test_acc:0.255\n",
            "node 6: train_acc: 0.562, test_acc:0.505\n",
            "node 7: train_acc: 0.611, test_acc:0.425\n",
            "node 8: train_acc: 0.72, test_acc:0.655\n",
            "node 9: train_acc: 0.627, test_acc:0.475\n",
            "model numbers: 10\n",
            "time 0:04:09.553225\n",
            "global acc: 0.421\n",
            "\n",
            "Round 7/10\n",
            "node 0: train_acc: 0.782, test_acc:0.255\n",
            "node 1: train_acc: 0.749, test_acc:0.61\n",
            "node 2: train_acc: 0.749, test_acc:0.265\n",
            "node 3: train_acc: 0.73, test_acc:0.56\n",
            "node 4: train_acc: 0.549, test_acc:0.255\n",
            "node 5: train_acc: 0.537, test_acc:0.255\n",
            "node 6: train_acc: 0.551, test_acc:0.525\n",
            "node 7: train_acc: 0.597, test_acc:0.405\n",
            "node 8: train_acc: 0.777, test_acc:0.735\n",
            "node 9: train_acc: 0.646, test_acc:0.45\n",
            "model numbers: 10\n",
            "time 0:04:49.414296\n",
            "global acc: 0.43149999999999994\n",
            "\n",
            "Round 8/10\n",
            "node 0: train_acc: 0.783, test_acc:0.275\n",
            "node 1: train_acc: 0.729, test_acc:0.545\n",
            "node 2: train_acc: 0.77, test_acc:0.285\n",
            "node 3: train_acc: 0.694, test_acc:0.575\n",
            "node 4: train_acc: 0.55, test_acc:0.265\n",
            "node 5: train_acc: 0.575, test_acc:0.28\n",
            "node 6: train_acc: 0.606, test_acc:0.5\n",
            "node 7: train_acc: 0.666, test_acc:0.32\n",
            "node 8: train_acc: 0.775, test_acc:0.755\n",
            "node 9: train_acc: 0.654, test_acc:0.345\n",
            "model numbers: 10\n",
            "time 0:05:29.199181\n",
            "global acc: 0.4145\n",
            "\n",
            "Round 9/10\n",
            "node 0: train_acc: 0.808, test_acc:0.405\n",
            "node 1: train_acc: 0.754, test_acc:0.5\n",
            "node 2: train_acc: 0.745, test_acc:0.265\n",
            "node 3: train_acc: 0.784, test_acc:0.565\n",
            "node 4: train_acc: 0.555, test_acc:0.265\n",
            "node 5: train_acc: 0.551, test_acc:0.265\n",
            "node 6: train_acc: 0.599, test_acc:0.505\n",
            "node 7: train_acc: 0.67, test_acc:0.525\n",
            "node 8: train_acc: 0.75, test_acc:0.645\n",
            "node 9: train_acc: 0.654, test_acc:0.34\n",
            "model numbers: 10\n",
            "time 0:06:12.636634\n",
            "global acc: 0.42800000000000005\n",
            "\n",
            "Round 10/10\n",
            "node 0: train_acc: 0.804, test_acc:0.25\n",
            "node 1: train_acc: 0.771, test_acc:0.5\n",
            "node 2: train_acc: 0.775, test_acc:0.27\n",
            "node 3: train_acc: 0.773, test_acc:0.515\n",
            "node 4: train_acc: 0.576, test_acc:0.265\n",
            "node 5: train_acc: 0.558, test_acc:0.355\n",
            "node 6: train_acc: 0.576, test_acc:0.525\n",
            "node 7: train_acc: 0.684, test_acc:0.58\n",
            "node 8: train_acc: 0.798, test_acc:0.725\n",
            "node 9: train_acc: 0.718, test_acc:0.52\n",
            "model numbers: 10\n",
            "time 0:06:52.453276\n",
            "global acc: 0.45050000000000007\n",
            "----------------------Info befire clustering-------------\n",
            "model_len: 10\n",
            "Client IDS: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[[0.         0.2967243  0.25029704 0.30331203 0.41034138 0.39488532\n",
            "  0.40057476 0.3877375  0.3905433  0.38441187]\n",
            " [0.2967243  0.         0.28943422 0.32468569 0.40630357 0.39940359\n",
            "  0.40553144 0.38543094 0.38590514 0.38618876]\n",
            " [0.25029704 0.28943422 0.         0.30566958 0.4108129  0.39762223\n",
            "  0.40220223 0.3886671  0.3883119  0.38456039]\n",
            " [0.30331203 0.32468569 0.30566958 0.         0.4025297  0.39080545\n",
            "  0.39898397 0.38712999 0.38951439 0.38629613]\n",
            " [0.41034138 0.40630357 0.4108129  0.4025297  0.         0.30144209\n",
            "  0.32331589 0.41548774 0.40692897 0.425045  ]\n",
            " [0.39488532 0.39940359 0.39762223 0.39080545 0.30144209 0.\n",
            "  0.30987828 0.41440067 0.40669187 0.42111455]\n",
            " [0.40057476 0.40553144 0.40220223 0.39898397 0.32331589 0.30987828\n",
            "  0.         0.41029665 0.40178888 0.41700695]\n",
            " [0.3877375  0.38543094 0.3886671  0.38712999 0.41548774 0.41440067\n",
            "  0.41029665 0.         0.30662602 0.26627741]\n",
            " [0.3905433  0.38590514 0.3883119  0.38951439 0.40692897 0.40669187\n",
            "  0.40178888 0.30662602 0.         0.30965282]\n",
            " [0.38441187 0.38618876 0.38456039 0.38629613 0.425045   0.42111455\n",
            "  0.41700695 0.26627741 0.30965282 0.        ]]\n",
            "cluster results:[0 0 0 0 1 1 1 2 2 2]\n",
            "new clustering: [[0, 1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
            "\n",
            "\n",
            "---------Clustering step 1\n",
            "-------------in initial genertaio\n",
            "cluster [0, 1, 2, 3]\n",
            "clientIDs [0, 1, 2, 3]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 4 cluster IDs: [0, 1, 2, 3]\n",
            "cid is: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cid is: 1\n",
            "cid is: 2\n",
            "cid is: 3\n",
            "\n",
            "Round 1/10\n",
            "node 0: train_acc: 0.803, test_acc:0.255\n",
            "node 1: train_acc: 0.787, test_acc:0.565\n",
            "node 2: train_acc: 0.803, test_acc:0.285\n",
            "node 3: train_acc: 0.769, test_acc:0.55\n",
            "model numbers: 4\n",
            "time 0:00:17.980290\n",
            "global acc: 0.41375\n",
            "\n",
            "Round 2/10\n",
            "node 0: train_acc: 0.809, test_acc:0.345\n",
            "node 1: train_acc: 0.798, test_acc:0.525\n",
            "node 2: train_acc: 0.772, test_acc:0.54\n",
            "node 3: train_acc: 0.797, test_acc:0.54\n",
            "model numbers: 4\n",
            "time 0:00:35.438760\n",
            "global acc: 0.48750000000000004\n",
            "\n",
            "Round 3/10\n",
            "node 0: train_acc: 0.811, test_acc:0.4\n",
            "node 1: train_acc: 0.816, test_acc:0.5\n",
            "node 2: train_acc: 0.792, test_acc:0.33\n",
            "node 3: train_acc: 0.797, test_acc:0.63\n",
            "model numbers: 4\n",
            "time 0:00:52.541384\n",
            "global acc: 0.46499999999999997\n",
            "\n",
            "Round 4/10\n",
            "node 0: train_acc: 0.836, test_acc:0.535\n",
            "node 1: train_acc: 0.836, test_acc:0.545\n",
            "node 2: train_acc: 0.832, test_acc:0.525\n",
            "node 3: train_acc: 0.837, test_acc:0.55\n",
            "model numbers: 4\n",
            "time 0:01:09.750937\n",
            "global acc: 0.5387500000000001\n",
            "\n",
            "Round 5/10\n",
            "node 0: train_acc: 0.853, test_acc:0.495\n",
            "node 1: train_acc: 0.826, test_acc:0.6\n",
            "node 2: train_acc: 0.841, test_acc:0.445\n",
            "node 3: train_acc: 0.842, test_acc:0.635\n",
            "model numbers: 4\n",
            "time 0:01:26.768340\n",
            "global acc: 0.54375\n",
            "\n",
            "Round 6/10\n",
            "node 0: train_acc: 0.855, test_acc:0.435\n",
            "node 1: train_acc: 0.843, test_acc:0.535\n",
            "node 2: train_acc: 0.849, test_acc:0.515\n",
            "node 3: train_acc: 0.85, test_acc:0.52\n",
            "model numbers: 4\n",
            "time 0:01:43.933757\n",
            "global acc: 0.50125\n",
            "\n",
            "Round 7/10\n",
            "node 0: train_acc: 0.887, test_acc:0.525\n",
            "node 1: train_acc: 0.853, test_acc:0.65\n",
            "node 2: train_acc: 0.846, test_acc:0.605\n",
            "node 3: train_acc: 0.849, test_acc:0.615\n",
            "model numbers: 4\n",
            "time 0:02:01.241602\n",
            "global acc: 0.59875\n",
            "\n",
            "Round 8/10\n",
            "node 0: train_acc: 0.868, test_acc:0.54\n",
            "node 1: train_acc: 0.862, test_acc:0.65\n",
            "node 2: train_acc: 0.879, test_acc:0.45\n",
            "node 3: train_acc: 0.859, test_acc:0.615\n",
            "model numbers: 4\n",
            "time 0:02:19.174717\n",
            "global acc: 0.56375\n",
            "\n",
            "Round 9/10\n",
            "node 0: train_acc: 0.885, test_acc:0.52\n",
            "node 1: train_acc: 0.862, test_acc:0.68\n",
            "node 2: train_acc: 0.884, test_acc:0.53\n",
            "node 3: train_acc: 0.861, test_acc:0.71\n",
            "model numbers: 4\n",
            "time 0:02:36.462663\n",
            "global acc: 0.6100000000000001\n",
            "\n",
            "Round 10/10\n",
            "node 0: train_acc: 0.891, test_acc:0.56\n",
            "node 1: train_acc: 0.894, test_acc:0.635\n",
            "node 2: train_acc: 0.876, test_acc:0.515\n",
            "node 3: train_acc: 0.859, test_acc:0.645\n",
            "model numbers: 4\n",
            "time 0:02:53.181434\n",
            "global acc: 0.58875\n",
            "-------------in initial genertaio\n",
            "cluster [4, 5, 6]\n",
            "clientIDs [0, 1, 2, 3, 4, 5, 6]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 3 cluster IDs: [0, 1, 2, 3, 4, 5, 6]\n",
            "cid is: 4\n",
            "cid is: 5\n",
            "cid is: 6\n",
            "\n",
            "Round 1/10\n",
            "node 4: train_acc: 0.568, test_acc:0.28\n",
            "node 5: train_acc: 0.531, test_acc:0.37\n",
            "node 6: train_acc: 0.596, test_acc:0.515\n",
            "model numbers: 3\n",
            "time 0:00:12.794139\n",
            "global acc: 0.38833333333333336\n",
            "\n",
            "Round 2/10\n",
            "node 4: train_acc: 0.603, test_acc:0.28\n",
            "node 5: train_acc: 0.606, test_acc:0.49\n",
            "node 6: train_acc: 0.594, test_acc:0.55\n",
            "model numbers: 3\n",
            "time 0:00:25.611519\n",
            "global acc: 0.44\n",
            "\n",
            "Round 3/10\n",
            "node 4: train_acc: 0.587, test_acc:0.31\n",
            "node 5: train_acc: 0.648, test_acc:0.44\n",
            "node 6: train_acc: 0.645, test_acc:0.57\n",
            "model numbers: 3\n",
            "time 0:00:38.775996\n",
            "global acc: 0.43999999999999995\n",
            "\n",
            "Round 4/10\n",
            "node 4: train_acc: 0.642, test_acc:0.42\n",
            "node 5: train_acc: 0.625, test_acc:0.37\n",
            "node 6: train_acc: 0.651, test_acc:0.55\n",
            "model numbers: 3\n",
            "time 0:00:51.044644\n",
            "global acc: 0.4466666666666667\n",
            "\n",
            "Round 5/10\n",
            "node 4: train_acc: 0.654, test_acc:0.455\n",
            "node 5: train_acc: 0.658, test_acc:0.51\n",
            "node 6: train_acc: 0.667, test_acc:0.535\n",
            "model numbers: 3\n",
            "time 0:01:04.788061\n",
            "global acc: 0.5\n",
            "\n",
            "Round 6/10\n",
            "node 4: train_acc: 0.669, test_acc:0.395\n",
            "node 5: train_acc: 0.674, test_acc:0.565\n",
            "node 6: train_acc: 0.687, test_acc:0.59\n",
            "model numbers: 3\n",
            "time 0:01:17.683450\n",
            "global acc: 0.5166666666666666\n",
            "\n",
            "Round 7/10\n",
            "node 4: train_acc: 0.671, test_acc:0.57\n",
            "node 5: train_acc: 0.654, test_acc:0.57\n",
            "node 6: train_acc: 0.704, test_acc:0.615\n",
            "model numbers: 3\n",
            "time 0:01:31.405424\n",
            "global acc: 0.585\n",
            "\n",
            "Round 8/10\n",
            "node 4: train_acc: 0.668, test_acc:0.595\n",
            "node 5: train_acc: 0.694, test_acc:0.42\n",
            "node 6: train_acc: 0.707, test_acc:0.635\n",
            "model numbers: 3\n",
            "time 0:01:44.109961\n",
            "global acc: 0.5499999999999999\n",
            "\n",
            "Round 9/10\n",
            "node 4: train_acc: 0.696, test_acc:0.53\n",
            "node 5: train_acc: 0.711, test_acc:0.53\n",
            "node 6: train_acc: 0.696, test_acc:0.625\n",
            "model numbers: 3\n",
            "time 0:01:58.000833\n",
            "global acc: 0.5616666666666666\n",
            "\n",
            "Round 10/10\n",
            "node 4: train_acc: 0.711, test_acc:0.55\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-1b4739e6579a>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" ---in making new FL----cluster models len:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_initial_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"cluster IDs:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_IDs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#print(\"lencluster\", len(cluster_initial_models))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcluster_initial_models\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFL_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSensitivity_percentage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mFL_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m#plot_accuracy(f.accuracies, str(cluster))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-0c22fe661ac3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, clients, client_initial_models, round_number, trainloaders, testloaders, Sensitivity_percentage)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_obj_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-0c22fe661ac3>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;31m#client.setting_parameters(global_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m               \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_obj_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain_test_and_return_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m               \u001b[0;31m#train_acc, test_acc = self.client_obj_list[self.clients.index(cid)].train_and_test_fedprox(global_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m               \u001b[0;31m#train_acc, test_acc, c = self.client_obj_list[self.clients.index(cid)].train_and_test_scaffold(global_model, client_controls[cid], c)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-568f90480298>\u001b[0m in \u001b[0;36mTrain_test_and_return_acc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mTrain_test_and_return_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-568f90480298>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, node_id, trainloader, epochs)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m## For googlenet model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# Metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#--------------------------------\n",
        "import copy\n",
        "\n",
        "clusters=[]\n",
        "\n",
        "initial = [i for i in range(num_clients)]\n",
        "clusters.append(initial)\n",
        "\n",
        "#client_IDs=[6,4,2,1,3]\n",
        "def generate_initial_models(step,cluster,client_IDs,client_Models):\n",
        "    print(\"-------------in initial genertaio\")\n",
        "    print(\"cluster\", cluster)\n",
        "    print(\"clientIDs\", client_IDs)\n",
        "    print(\"len_client_models(should be 10):\",len(client_Models))\n",
        "    list1=[]\n",
        "    if step==0:\n",
        "        for member in range(len(cluster)):\n",
        "            list1.append(Net())\n",
        "    else:\n",
        "        for index in cluster:\n",
        "            list1.append(client_Models[client_IDs.index(index)])\n",
        "    return list1\n",
        "\n",
        "\n",
        "\n",
        "## ---------------main\n",
        "client_Models=[]\n",
        "client_copy_models = []\n",
        "\n",
        "for step in range(Clustering_period):\n",
        "    client_copy_models=copy.deepcopy(client_Models)\n",
        "    client_Models=[]\n",
        "    print(\"\\n\\n---------Clustering step\", step)\n",
        "    FL_list=[]\n",
        "    client_IDs=[]\n",
        "    for cluster in clusters:\n",
        "        for Id in cluster:\n",
        "            client_IDs.append(Id)\n",
        "\n",
        "\n",
        "        cluster_initial_models=generate_initial_models(step,cluster,client_IDs,client_copy_models)\n",
        "        print(\" ---in making new FL----cluster models len:\", len(cluster_initial_models),\"cluster IDs:\", client_IDs)\n",
        "        #print(\"lencluster\", len(cluster_initial_models))\n",
        "        f = FL(cluster,cluster_initial_models,FL_rounds, trainloaders, testloaders, Sensitivity_percentage)\n",
        "        FL_list.append(f)\n",
        "        #plot_accuracy(f.accuracies, str(cluster))\n",
        "\n",
        "\n",
        "\n",
        "        for member in f.client_obj_list:\n",
        "            client_Models.append(member.net)\n",
        "\n",
        "        ## Save pytorch models for each client\n",
        "        for cid in client_IDs:\n",
        "          save_torch_model(client_Models[client_IDs.index(cid)], cid)\n",
        "          save_model_param(client_Models[client_IDs.index(cid)], cid, step)\n",
        "\n",
        "    print(\"----------------------Info befire clustering-------------\")\n",
        "    print(\"model_len:\", len(client_Models))\n",
        "    print(\"Client IDS:\",client_IDs )\n",
        "\n",
        "    start_cluster_time = datetime.now()\n",
        "    clusters = Clustering(client_IDs, trainloaders, Sensitivity_percentage, cluster_number).Clusters\n",
        "    end_cluster_time = datetime.now()\n",
        "    exe_cluster_time = end_cluster_time - start_cluster_time\n",
        "    with open(log_file, 'a') as f:\n",
        "        f.write(f\"\\n Exe Cluster Time: {exe_cluster_time}\")\n",
        "\n",
        "    print(\"new clustering:\",clusters)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUu16MP9yjo_",
        "outputId": "fc6fccd0-6f6a-4d51-8457-32ef6f1a4c49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "---------Clustering step 0\n",
            "-------------in initial genertaio\n",
            "cluster [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "clientIDs [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "len_client_models(should be 10): 0\n",
            " ---in making new FL----cluster models len: 10 cluster IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "cid is: 0\n",
            "cid is: 1\n",
            "cid is: 2\n",
            "cid is: 3\n",
            "cid is: 4\n",
            "cid is: 5\n",
            "cid is: 6\n",
            "cid is: 7\n",
            "cid is: 8\n",
            "cid is: 9\n",
            "\n",
            "Round 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-e53d7605a93b>:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "node 0: train_acc: 0.8377777777777777, test_acc:0.9693333333333334\n",
            "node 1: train_acc: 0.7711428571428571, test_acc:0.9691780821917808\n",
            "node 2: train_acc: 0.7805714285714286, test_acc:1.0\n",
            "node 3: train_acc: 0.9341333333333334, test_acc:0.9992\n",
            "node 4: train_acc: 0.8682222222222222, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9146666666666666, test_acc:0.9976\n",
            "node 6: train_acc: 0.651375, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.8463333333333334, test_acc:1.0\n",
            "node 8: train_acc: 0.675, test_acc:0.947\n",
            "node 9: train_acc: 0.9298666666666666, test_acc:0.9992\n",
            "model numbers: 10\n",
            "time 0:00:36.128480\n",
            "global acc: 0.9630365629078502\n",
            "\n",
            "Round 2/10\n",
            "node 0: train_acc: 0.6635555555555556, test_acc:0.6666666666666666\n",
            "node 1: train_acc: 0.4165714285714286, test_acc:0.4280821917808219\n",
            "node 2: train_acc: 0.7791428571428571, test_acc:1.0\n",
            "node 3: train_acc: 0.19866666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.3293333333333333, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.7049333333333333, test_acc:0.9928\n",
            "node 6: train_acc: 0.22975, test_acc:0.24981245311327832\n",
            "node 7: train_acc: 0.835, test_acc:0.998\n",
            "node 8: train_acc: 0.0, test_acc:0.0\n",
            "node 9: train_acc: 0.19746666666666668, test_acc:0.1992\n",
            "model numbers: 10\n",
            "time 0:01:11.548240\n",
            "global acc: 0.5067894644894101\n",
            "\n",
            "Round 3/10\n",
            "node 0: train_acc: 0.6611111111111111, test_acc:0.6666666666666666\n",
            "node 1: train_acc: 0.8711428571428571, test_acc:0.9657534246575342\n",
            "node 2: train_acc: 0.9234285714285714, test_acc:0.9982847341337907\n",
            "node 3: train_acc: 0.1984, test_acc:0.2\n",
            "node 4: train_acc: 0.32866666666666666, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9582666666666667, test_acc:0.996\n",
            "node 6: train_acc: 0.237125, test_acc:0.24981245311327832\n",
            "node 7: train_acc: 0.9833333333333333, test_acc:0.998\n",
            "node 8: train_acc: 0.0, test_acc:0.0\n",
            "node 9: train_acc: 0.1996, test_acc:0.1992\n",
            "model numbers: 10\n",
            "time 0:01:47.221797\n",
            "global acc: 0.5607050611904604\n",
            "\n",
            "Round 4/10\n",
            "node 0: train_acc: 0.6617777777777778, test_acc:0.6666666666666666\n",
            "node 1: train_acc: 0.9422857142857143, test_acc:0.9708904109589042\n",
            "node 2: train_acc: 0.9871428571428571, test_acc:1.0\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.3328888888888889, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9593333333333334, test_acc:0.9968\n",
            "node 6: train_acc: 0.247125, test_acc:0.2490622655663916\n",
            "node 7: train_acc: 0.9933333333333333, test_acc:0.998\n",
            "node 8: train_acc: 0.0, test_acc:0.0\n",
            "node 9: train_acc: 0.19906666666666667, test_acc:0.1992\n",
            "model numbers: 10\n",
            "time 0:02:23.061883\n",
            "global acc: 0.5613952676525297\n",
            "\n",
            "Round 5/10\n",
            "node 0: train_acc: 0.6626666666666666, test_acc:0.6666666666666666\n",
            "node 1: train_acc: 0.9037142857142857, test_acc:0.9657534246575342\n",
            "node 2: train_acc: 0.8414285714285714, test_acc:1.0\n",
            "node 3: train_acc: 0.2, test_acc:0.2\n",
            "node 4: train_acc: 0.3322222222222222, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9702666666666667, test_acc:0.996\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "node 7: train_acc: 0.9973333333333333, test_acc:0.998\n",
            "node 8: train_acc: 0.0, test_acc:0.0\n",
            "node 9: train_acc: 0.1992, test_acc:0.2\n",
            "model numbers: 10\n",
            "time 0:02:59.530754\n",
            "global acc: 0.5359753424657535\n",
            "\n",
            "Round 6/10\n",
            "node 0: train_acc: 0.6656666666666666, test_acc:0.6666666666666666\n",
            "node 1: train_acc: 0.9342857142857143, test_acc:0.9726027397260274\n",
            "node 2: train_acc: 0.9802857142857143, test_acc:1.0\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.33266666666666667, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9562666666666667, test_acc:0.996\n",
            "node 6: train_acc: 0.236375, test_acc:0.24606151537884471\n",
            "node 7: train_acc: 0.9903333333333333, test_acc:1.0\n",
            "node 8: train_acc: 0.0055, test_acc:0.499\n",
            "node 9: train_acc: 0.19813333333333333, test_acc:0.1992\n",
            "model numbers: 10\n",
            "time 0:03:35.996582\n",
            "global acc: 0.6112864255104873\n",
            "\n",
            "Round 7/10\n",
            "node 0: train_acc: 0.8414444444444444, test_acc:0.95\n",
            "node 1: train_acc: 0.9257142857142857, test_acc:0.9691780821917808\n",
            "node 2: train_acc: 0.9597142857142857, test_acc:0.9982847341337907\n",
            "node 3: train_acc: 0.1996, test_acc:0.2\n",
            "node 4: train_acc: 0.3313333333333333, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9612, test_acc:0.996\n",
            "node 6: train_acc: 0.238, test_acc:0.24681170292573143\n",
            "node 7: train_acc: 0.998, test_acc:1.0\n",
            "node 8: train_acc: 0.31033333333333335, test_acc:0.46\n",
            "node 9: train_acc: 0.19946666666666665, test_acc:0.2\n",
            "model numbers: 10\n",
            "time 0:04:12.033550\n",
            "global acc: 0.6353607852584636\n",
            "\n",
            "Round 8/10\n",
            "node 0: train_acc: 0.9035555555555556, test_acc:0.9506666666666667\n",
            "node 1: train_acc: 0.9488571428571428, test_acc:0.976027397260274\n",
            "node 2: train_acc: 0.9831428571428571, test_acc:1.0\n",
            "node 3: train_acc: 0.19946666666666665, test_acc:0.2\n",
            "node 4: train_acc: 0.33155555555555555, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9649333333333333, test_acc:0.9952\n",
            "node 6: train_acc: 0.227, test_acc:0.24756189047261815\n",
            "node 7: train_acc: 0.996, test_acc:0.998\n",
            "node 8: train_acc: 0.44083333333333335, test_acc:0.47\n",
            "node 9: train_acc: 0.19853333333333334, test_acc:0.1992\n",
            "model numbers: 10\n",
            "time 0:04:48.015444\n",
            "global acc: 0.6369989287732893\n",
            "\n",
            "Round 9/10\n",
            "node 0: train_acc: 0.9081111111111111, test_acc:0.9313333333333333\n",
            "node 1: train_acc: 0.9411428571428572, test_acc:0.9657534246575342\n",
            "node 2: train_acc: 0.9774285714285714, test_acc:1.0\n",
            "node 3: train_acc: 0.2, test_acc:0.2\n",
            "node 4: train_acc: 0.3328888888888889, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9428, test_acc:0.996\n",
            "node 6: train_acc: 0.233375, test_acc:0.23930982745686422\n",
            "node 7: train_acc: 0.999, test_acc:1.0\n",
            "node 8: train_acc: 0.44633333333333336, test_acc:0.476\n",
            "node 9: train_acc: 0.5076, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:05:23.208154\n",
            "global acc: 0.7140129918781066\n",
            "\n",
            "Round 10/10\n",
            "node 0: train_acc: 0.9152222222222223, test_acc:0.952\n",
            "node 1: train_acc: 0.9385714285714286, test_acc:0.9674657534246576\n",
            "node 2: train_acc: 0.9811428571428571, test_acc:1.0\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.33266666666666667, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9236, test_acc:0.9944\n",
            "node 6: train_acc: 0.237125, test_acc:0.24681170292573143\n",
            "node 7: train_acc: 0.9973333333333333, test_acc:1.0\n",
            "node 8: train_acc: 0.43766666666666665, test_acc:0.473\n",
            "node 9: train_acc: 0.9065333333333333, test_acc:0.9968\n",
            "model numbers: 10\n",
            "time 0:05:58.679456\n",
            "global acc: 0.7163810789683722\n",
            "----------------------Info befire clustering-------------\n",
            "model_len: 10\n",
            "Client IDS: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "new clustering: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
            "\n",
            "\n",
            "---------Clustering step 1\n",
            "-------------in initial genertaio\n",
            "cluster [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "clientIDs [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 10 cluster IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "cid is: 0\n",
            "cid is: 1\n",
            "cid is: 2\n",
            "cid is: 3\n",
            "cid is: 4\n",
            "cid is: 5\n",
            "cid is: 6\n",
            "cid is: 7\n",
            "cid is: 8\n",
            "cid is: 9\n",
            "\n",
            "Round 1/10\n",
            "node 0: train_acc: 0.9361111111111111, test_acc:0.96\n",
            "node 1: train_acc: 0.9497142857142857, test_acc:0.9708904109589042\n",
            "node 2: train_acc: 0.9811428571428571, test_acc:0.9982847341337907\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.3317777777777778, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9509333333333333, test_acc:0.9984\n",
            "node 6: train_acc: 0.237, test_acc:0.24756189047261815\n",
            "node 7: train_acc: 0.9996666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.4385, test_acc:0.462\n",
            "node 9: train_acc: 0.8685333333333334, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:00:35.957992\n",
            "global acc: 0.7168870368898647\n",
            "\n",
            "Round 2/10\n",
            "node 0: train_acc: 0.9436666666666667, test_acc:0.958\n",
            "node 1: train_acc: 0.9522857142857143, test_acc:0.976027397260274\n",
            "node 2: train_acc: 0.9857142857142858, test_acc:1.0\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.33244444444444443, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9468, test_acc:0.996\n",
            "node 6: train_acc: 0.49025, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.9986666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.44783333333333336, test_acc:0.461\n",
            "node 9: train_acc: 0.9252, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:01:12.067462\n",
            "global acc: 0.767294827748033\n",
            "\n",
            "Round 3/10\n",
            "node 0: train_acc: 0.9445555555555556, test_acc:0.9513333333333334\n",
            "node 1: train_acc: 0.9502857142857143, test_acc:0.9811643835616438\n",
            "node 2: train_acc: 0.982, test_acc:0.9982847341337907\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.33155555555555555, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9604, test_acc:0.996\n",
            "node 6: train_acc: 0.238375, test_acc:0.24306076519129782\n",
            "node 7: train_acc: 0.995, test_acc:1.0\n",
            "node 8: train_acc: 0.44333333333333336, test_acc:0.462\n",
            "node 9: train_acc: 0.9189333333333334, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:01:47.325005\n",
            "global acc: 0.7163576549553399\n",
            "\n",
            "Round 4/10\n",
            "node 0: train_acc: 0.9391111111111111, test_acc:0.9586666666666667\n",
            "node 1: train_acc: 0.9451428571428572, test_acc:0.9811643835616438\n",
            "node 2: train_acc: 0.9791428571428571, test_acc:1.0\n",
            "node 3: train_acc: 0.19946666666666665, test_acc:0.2\n",
            "node 4: train_acc: 0.332, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9626666666666667, test_acc:0.9976\n",
            "node 6: train_acc: 0.23825, test_acc:0.24756189047261815\n",
            "node 7: train_acc: 0.9986666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.44133333333333336, test_acc:0.469\n",
            "node 9: train_acc: 0.9250666666666667, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:02:23.290424\n",
            "global acc: 0.7185726274034263\n",
            "\n",
            "Round 5/10\n",
            "node 0: train_acc: 0.9482222222222222, test_acc:0.9566666666666667\n",
            "node 1: train_acc: 0.9468571428571428, test_acc:0.9743150684931506\n",
            "node 2: train_acc: 0.9834285714285714, test_acc:1.0\n",
            "node 3: train_acc: 0.1996, test_acc:0.2\n",
            "node 4: train_acc: 0.3328888888888889, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9602666666666667, test_acc:0.996\n",
            "node 6: train_acc: 0.3435, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.998, test_acc:1.0\n",
            "node 8: train_acc: 0.448, test_acc:0.462\n",
            "node 9: train_acc: 0.9041333333333333, test_acc:0.9968\n",
            "model numbers: 10\n",
            "time 0:02:59.270286\n",
            "global acc: 0.7669302615379874\n",
            "\n",
            "Round 6/10\n",
            "node 0: train_acc: 0.9442222222222222, test_acc:0.9546666666666667\n",
            "node 1: train_acc: 0.9568571428571429, test_acc:0.976027397260274\n",
            "node 2: train_acc: 0.9868571428571429, test_acc:0.9982847341337907\n",
            "node 3: train_acc: 0.19973333333333335, test_acc:0.2\n",
            "node 4: train_acc: 0.33266666666666667, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9748, test_acc:0.9976\n",
            "node 6: train_acc: 0.567625, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.9943333333333333, test_acc:1.0\n",
            "node 8: train_acc: 0.44633333333333336, test_acc:0.474\n",
            "node 9: train_acc: 0.9270666666666667, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:03:34.131011\n",
            "global acc: 0.7682499678280788\n",
            "\n",
            "Round 7/10\n",
            "node 0: train_acc: 0.9507777777777778, test_acc:0.9613333333333334\n",
            "node 1: train_acc: 0.9508571428571428, test_acc:0.9743150684931506\n",
            "node 2: train_acc: 0.9865714285714285, test_acc:1.0\n",
            "node 3: train_acc: 0.19973333333333335, test_acc:0.2\n",
            "node 4: train_acc: 0.3322222222222222, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9174666666666667, test_acc:0.9968\n",
            "node 6: train_acc: 0.308375, test_acc:0.7516879219804952\n",
            "node 7: train_acc: 0.9946666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.4543333333333333, test_acc:0.463\n",
            "node 9: train_acc: 0.9244, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:04:09.922488\n",
            "global acc: 0.7678869657140314\n",
            "\n",
            "Round 8/10\n",
            "node 0: train_acc: 0.9472222222222222, test_acc:0.962\n",
            "node 1: train_acc: 0.9534285714285714, test_acc:0.9777397260273972\n",
            "node 2: train_acc: 0.9822857142857143, test_acc:1.0\n",
            "node 3: train_acc: 0.19973333333333335, test_acc:0.2\n",
            "node 4: train_acc: 0.3322222222222222, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9706666666666667, test_acc:0.9984\n",
            "node 6: train_acc: 0.65325, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.9963333333333333, test_acc:1.0\n",
            "node 8: train_acc: 0.4435, test_acc:0.474\n",
            "node 9: train_acc: 0.9254666666666667, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:04:45.820719\n",
            "global acc: 0.7694060606247454\n",
            "\n",
            "Round 9/10\n",
            "node 0: train_acc: 0.951, test_acc:0.9593333333333334\n",
            "node 1: train_acc: 0.9565714285714285, test_acc:0.9811643835616438\n",
            "node 2: train_acc: 0.9871428571428571, test_acc:0.9965694682675815\n",
            "node 3: train_acc: 0.19946666666666665, test_acc:0.2\n",
            "node 4: train_acc: 0.332, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9714666666666667, test_acc:0.9984\n",
            "node 6: train_acc: 0.686125, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.9966666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.45316666666666666, test_acc:0.471\n",
            "node 9: train_acc: 0.9444, test_acc:0.9992\n",
            "model numbers: 10\n",
            "time 0:05:20.473675\n",
            "global acc: 0.7689188065382615\n",
            "\n",
            "Round 10/10\n",
            "node 0: train_acc: 0.9497777777777778, test_acc:0.9566666666666667\n",
            "node 1: train_acc: 0.948, test_acc:0.976027397260274\n",
            "node 2: train_acc: 0.9837142857142858, test_acc:1.0\n",
            "node 3: train_acc: 0.19973333333333335, test_acc:0.2\n",
            "node 4: train_acc: 0.33266666666666667, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9616, test_acc:0.9984\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "node 7: train_acc: 0.9946666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.44916666666666666, test_acc:0.464\n",
            "node 9: train_acc: 0.9234666666666667, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:05:56.482205\n",
            "global acc: 0.6926827397260275\n",
            "----------------------Info befire clustering-------------\n",
            "model_len: 10\n",
            "Client IDS: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "new clustering: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
            "\n",
            "\n",
            "---------Clustering step 2\n",
            "-------------in initial genertaio\n",
            "cluster [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "clientIDs [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 10 cluster IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "cid is: 0\n",
            "cid is: 1\n",
            "cid is: 2\n",
            "cid is: 3\n",
            "cid is: 4\n",
            "cid is: 5\n",
            "cid is: 6\n",
            "cid is: 7\n",
            "cid is: 8\n",
            "cid is: 9\n",
            "\n",
            "Round 1/10\n",
            "node 0: train_acc: 0.9525555555555556, test_acc:0.9613333333333334\n",
            "node 1: train_acc: 0.914, test_acc:0.9777397260273972\n",
            "node 2: train_acc: 0.8574285714285714, test_acc:1.0\n",
            "node 3: train_acc: 0.2, test_acc:0.2\n",
            "node 4: train_acc: 0.33244444444444443, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9636, test_acc:0.996\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "node 7: train_acc: 0.9976666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.4488333333333333, test_acc:0.471\n",
            "node 9: train_acc: 0.9474666666666667, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:00:35.428752\n",
            "global acc: 0.6937806392694064\n",
            "\n",
            "Round 2/10\n",
            "node 0: train_acc: 0.954, test_acc:0.948\n",
            "node 1: train_acc: 0.9537142857142857, test_acc:0.9811643835616438\n",
            "node 2: train_acc: 0.9857142857142858, test_acc:1.0\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.33311111111111114, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.976, test_acc:0.9936\n",
            "node 6: train_acc: 0.51875, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.9946666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.44783333333333336, test_acc:0.476\n",
            "node 9: train_acc: 0.938, test_acc:0.9992\n",
            "model numbers: 10\n",
            "time 0:01:10.399452\n",
            "global acc: 0.76814852637817\n",
            "\n",
            "Round 3/10\n",
            "node 0: train_acc: 0.9448888888888889, test_acc:0.9613333333333334\n",
            "node 1: train_acc: 0.956, test_acc:0.9794520547945206\n",
            "node 2: train_acc: 0.9891428571428571, test_acc:1.0\n",
            "node 3: train_acc: 0.19973333333333335, test_acc:0.2\n",
            "node 4: train_acc: 0.33311111111111114, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9672, test_acc:0.9976\n",
            "node 6: train_acc: 0.622, test_acc:0.6406601650412603\n",
            "node 7: train_acc: 0.9953333333333333, test_acc:1.0\n",
            "node 8: train_acc: 0.44633333333333336, test_acc:0.471\n",
            "node 9: train_acc: 0.9501333333333334, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:01:45.310062\n",
            "global acc: 0.7581778886502448\n",
            "\n",
            "Round 4/10\n",
            "node 0: train_acc: 0.9565555555555556, test_acc:0.9653333333333334\n",
            "node 1: train_acc: 0.9568571428571429, test_acc:0.9743150684931506\n",
            "node 2: train_acc: 0.9877142857142858, test_acc:1.0\n",
            "node 3: train_acc: 0.19946666666666665, test_acc:0.2\n",
            "node 4: train_acc: 0.33266666666666667, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9684, test_acc:0.9968\n",
            "node 6: train_acc: 0.64025, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.9986666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.45266666666666666, test_acc:0.469\n",
            "node 9: train_acc: 0.9618666666666666, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:02:20.765052\n",
            "global acc: 0.768736928204654\n",
            "\n",
            "Round 5/10\n",
            "node 0: train_acc: 0.9424444444444444, test_acc:0.966\n",
            "node 1: train_acc: 0.95, test_acc:0.9777397260273972\n",
            "node 2: train_acc: 0.9845714285714285, test_acc:0.9965694682675815\n",
            "node 3: train_acc: 0.19933333333333333, test_acc:0.2\n",
            "node 4: train_acc: 0.332, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.966, test_acc:0.9984\n",
            "node 6: train_acc: 0.48125, test_acc:0.7509377344336085\n",
            "node 7: train_acc: 0.9946666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.44383333333333336, test_acc:0.461\n",
            "node 9: train_acc: 0.9321333333333334, test_acc:1.0\n",
            "model numbers: 10\n",
            "time 0:02:56.719538\n",
            "global acc: 0.7683980262061921\n",
            "\n",
            "Round 6/10\n",
            "node 0: train_acc: 0.9547777777777777, test_acc:0.964\n",
            "node 1: train_acc: 0.9611428571428572, test_acc:0.9777397260273972\n",
            "node 2: train_acc: 0.9917142857142857, test_acc:1.0\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.33266666666666667, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9756, test_acc:0.9976\n",
            "node 6: train_acc: 0.69375, test_acc:0.722430607651913\n",
            "node 7: train_acc: 0.994, test_acc:1.0\n",
            "node 8: train_acc: 0.45016666666666666, test_acc:0.477\n",
            "node 9: train_acc: 0.9506666666666667, test_acc:0.9976\n",
            "model numbers: 10\n",
            "time 0:03:31.281473\n",
            "global acc: 0.7669703667012644\n",
            "\n",
            "Round 7/10\n",
            "node 0: train_acc: 0.9456666666666667, test_acc:0.9666666666666667\n",
            "node 1: train_acc: 0.9511428571428572, test_acc:0.9811643835616438\n",
            "node 2: train_acc: 0.986, test_acc:1.0\n",
            "node 3: train_acc: 0.19973333333333335, test_acc:0.2\n",
            "node 4: train_acc: 0.33266666666666667, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.97, test_acc:0.9968\n",
            "node 6: train_acc: 0.57225, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.9946666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.4555, test_acc:0.472\n",
            "node 9: train_acc: 0.9558666666666666, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:04:07.032300\n",
            "global acc: 0.7698551930448365\n",
            "\n",
            "Round 8/10\n",
            "node 0: train_acc: 0.954, test_acc:0.9573333333333334\n",
            "node 1: train_acc: 0.9562857142857143, test_acc:0.9777397260273972\n",
            "node 2: train_acc: 0.994, test_acc:1.0\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.33244444444444443, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9576, test_acc:0.9984\n",
            "node 6: train_acc: 0.6385, test_acc:0.7111777944486122\n",
            "node 7: train_acc: 0.9953333333333333, test_acc:1.0\n",
            "node 8: train_acc: 0.459, test_acc:0.468\n",
            "node 9: train_acc: 0.9608, test_acc:1.0\n",
            "model numbers: 10\n",
            "time 0:04:42.921333\n",
            "global acc: 0.7645984187142676\n",
            "\n",
            "Round 9/10\n",
            "node 0: train_acc: 0.9551111111111111, test_acc:0.966\n",
            "node 1: train_acc: 0.9642857142857143, test_acc:0.9417808219178082\n",
            "node 2: train_acc: 0.9917142857142857, test_acc:1.0\n",
            "node 3: train_acc: 0.19973333333333335, test_acc:0.2\n",
            "node 4: train_acc: 0.3322222222222222, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9685333333333334, test_acc:0.9984\n",
            "node 6: train_acc: 0.66725, test_acc:0.7659414853713429\n",
            "node 7: train_acc: 0.994, test_acc:1.0\n",
            "node 8: train_acc: 0.4638333333333333, test_acc:0.487\n",
            "node 9: train_acc: 0.9294666666666667, test_acc:0.996\n",
            "model numbers: 10\n",
            "time 0:05:18.137265\n",
            "global acc: 0.7688455640622485\n",
            "\n",
            "Round 10/10\n",
            "node 0: train_acc: 0.9535555555555556, test_acc:0.9666666666666667\n",
            "node 1: train_acc: 0.956, test_acc:0.9811643835616438\n",
            "node 2: train_acc: 0.9905714285714285, test_acc:1.0\n",
            "node 3: train_acc: 0.1996, test_acc:0.2\n",
            "node 4: train_acc: 0.332, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9632, test_acc:0.9984\n",
            "node 6: train_acc: 0.644125, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.997, test_acc:1.0\n",
            "node 8: train_acc: 0.458, test_acc:0.481\n",
            "node 9: train_acc: 0.9356, test_acc:0.9976\n",
            "model numbers: 10\n",
            "time 0:05:53.881321\n",
            "global acc: 0.7708351930448366\n",
            "----------------------Info befire clustering-------------\n",
            "model_len: 10\n",
            "Client IDS: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "new clustering: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
            "\n",
            "\n",
            "---------Clustering step 3\n",
            "-------------in initial genertaio\n",
            "cluster [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "clientIDs [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 10 cluster IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "cid is: 0\n",
            "cid is: 1\n",
            "cid is: 2\n",
            "cid is: 3\n",
            "cid is: 4\n",
            "cid is: 5\n",
            "cid is: 6\n",
            "cid is: 7\n",
            "cid is: 8\n",
            "cid is: 9\n",
            "\n",
            "Round 1/10\n",
            "node 0: train_acc: 0.951, test_acc:0.968\n",
            "node 1: train_acc: 0.9611428571428572, test_acc:0.9726027397260274\n",
            "node 2: train_acc: 0.9954285714285714, test_acc:1.0\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.3328888888888889, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9697333333333333, test_acc:0.9992\n",
            "node 6: train_acc: 0.630875, test_acc:0.7524381095273819\n",
            "node 7: train_acc: 0.9943333333333333, test_acc:1.0\n",
            "node 8: train_acc: 0.4563333333333333, test_acc:0.47\n",
            "node 9: train_acc: 0.9665333333333334, test_acc:0.9968\n",
            "model numbers: 10\n",
            "time 0:00:36.051518\n",
            "global acc: 0.7692374182586742\n",
            "\n",
            "Round 2/10\n",
            "node 0: train_acc: 0.9528888888888889, test_acc:0.9666666666666667\n",
            "node 1: train_acc: 0.9648571428571429, test_acc:0.9794520547945206\n",
            "node 2: train_acc: 0.9934285714285714, test_acc:1.0\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.33311111111111114, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9758666666666667, test_acc:0.9984\n",
            "node 6: train_acc: 0.646625, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.9973333333333333, test_acc:1.0\n",
            "node 8: train_acc: 0.45566666666666666, test_acc:0.468\n",
            "node 9: train_acc: 0.9590666666666666, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:01:11.179075\n",
            "global acc: 0.7694439601681242\n",
            "\n",
            "Round 3/10\n",
            "node 0: train_acc: 0.9524444444444444, test_acc:0.9593333333333334\n",
            "node 1: train_acc: 0.9591428571428572, test_acc:0.9794520547945206\n",
            "node 2: train_acc: 0.99, test_acc:1.0\n",
            "node 3: train_acc: 0.1996, test_acc:0.2\n",
            "node 4: train_acc: 0.33244444444444443, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9729333333333333, test_acc:0.9984\n",
            "node 6: train_acc: 0.690125, test_acc:0.7494373593398349\n",
            "node 7: train_acc: 0.9956666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.4618333333333333, test_acc:0.481\n",
            "node 9: train_acc: 0.9641333333333333, test_acc:0.9992\n",
            "model numbers: 10\n",
            "time 0:01:46.364001\n",
            "global acc: 0.7700156080801023\n",
            "\n",
            "Round 4/10\n",
            "node 0: train_acc: 0.959, test_acc:0.9686666666666667\n",
            "node 1: train_acc: 0.9628571428571429, test_acc:0.9811643835616438\n",
            "node 2: train_acc: 0.996, test_acc:1.0\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.3353333333333333, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9749333333333333, test_acc:0.9992\n",
            "node 6: train_acc: 0.31425, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.9973333333333333, test_acc:1.0\n",
            "node 8: train_acc: 0.48183333333333334, test_acc:0.949\n",
            "node 9: train_acc: 0.9665333333333334, test_acc:0.9968\n",
            "model numbers: 10\n",
            "time 0:02:22.296907\n",
            "global acc: 0.8178351930448367\n",
            "\n",
            "Round 5/10\n",
            "node 0: train_acc: 0.9556666666666667, test_acc:0.9653333333333334\n",
            "node 1: train_acc: 0.9462857142857143, test_acc:0.9743150684931506\n",
            "node 2: train_acc: 0.9857142857142858, test_acc:0.9948542024013722\n",
            "node 3: train_acc: 0.19973333333333335, test_acc:0.2\n",
            "node 4: train_acc: 0.352, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9766666666666667, test_acc:0.9992\n",
            "node 6: train_acc: 0.7045, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.9963333333333333, test_acc:1.0\n",
            "node 8: train_acc: 0.5353333333333333, test_acc:0.95\n",
            "node 9: train_acc: 0.9541333333333334, test_acc:1.0\n",
            "model numbers: 10\n",
            "time 0:02:57.572218\n",
            "global acc: 0.8832556817781245\n",
            "\n",
            "Round 6/10\n",
            "node 0: train_acc: 0.9527777777777777, test_acc:0.9673333333333334\n",
            "node 1: train_acc: 0.9588571428571429, test_acc:0.9777397260273972\n",
            "node 2: train_acc: 0.9931428571428571, test_acc:0.9948542024013722\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.896, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9762666666666666, test_acc:0.9968\n",
            "node 6: train_acc: 0.641875, test_acc:0.6901725431357839\n",
            "node 7: train_acc: 0.9973333333333333, test_acc:1.0\n",
            "node 8: train_acc: 0.8546666666666667, test_acc:0.955\n",
            "node 9: train_acc: 0.9552, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:03:32.980795\n",
            "global acc: 0.8778966471564553\n",
            "\n",
            "Round 7/10\n",
            "node 0: train_acc: 0.9505555555555556, test_acc:0.9646666666666667\n",
            "node 1: train_acc: 0.9522857142857143, test_acc:0.9743150684931506\n",
            "node 2: train_acc: 0.9925714285714285, test_acc:1.0\n",
            "node 3: train_acc: 0.2, test_acc:0.2\n",
            "node 4: train_acc: 0.9742222222222222, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9690666666666666, test_acc:0.9992\n",
            "node 6: train_acc: 0.666875, test_acc:0.7629407351837959\n",
            "node 7: train_acc: 0.9946666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.9133333333333333, test_acc:0.953\n",
            "node 9: train_acc: 0.9541333333333334, test_acc:0.9992\n",
            "model numbers: 10\n",
            "time 0:04:08.945008\n",
            "global acc: 0.885198913701028\n",
            "\n",
            "Round 8/10\n",
            "node 0: train_acc: 0.9466666666666667, test_acc:0.966\n",
            "node 1: train_acc: 0.9528571428571428, test_acc:0.9743150684931506\n",
            "node 2: train_acc: 0.9882857142857143, test_acc:1.0\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.9535555555555556, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9692, test_acc:0.9992\n",
            "node 6: train_acc: 0.695625, test_acc:0.7164291072768192\n",
            "node 7: train_acc: 0.9983333333333333, test_acc:1.0\n",
            "node 8: train_acc: 0.9183333333333333, test_acc:0.954\n",
            "node 9: train_acc: 0.9618666666666666, test_acc:0.9976\n",
            "model numbers: 10\n",
            "time 0:04:45.245402\n",
            "global acc: 0.8806210842436636\n",
            "\n",
            "Round 9/10\n",
            "node 0: train_acc: 0.9521111111111111, test_acc:0.9586666666666667\n",
            "node 1: train_acc: 0.9425714285714286, test_acc:0.9811643835616438\n",
            "node 2: train_acc: 0.9882857142857143, test_acc:1.0\n",
            "node 3: train_acc: 0.19973333333333335, test_acc:0.2\n",
            "node 4: train_acc: 0.9755555555555555, test_acc:1.0\n",
            "node 5: train_acc: 0.9712, test_acc:0.996\n",
            "node 6: train_acc: 0.6455, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.9913333333333333, test_acc:1.0\n",
            "node 8: train_acc: 0.9186666666666666, test_acc:0.954\n",
            "node 9: train_acc: 0.9648, test_acc:0.9992\n",
            "model numbers: 10\n",
            "time 0:05:20.721374\n",
            "global acc: 0.8839218597115032\n",
            "\n",
            "Round 10/10\n",
            "node 0: train_acc: 0.9487777777777778, test_acc:0.9473333333333334\n",
            "node 1: train_acc: 0.9397142857142857, test_acc:0.9794520547945206\n",
            "node 2: train_acc: 0.9811428571428571, test_acc:0.9965694682675815\n",
            "node 3: train_acc: 0.1996, test_acc:0.2\n",
            "node 4: train_acc: 0.9793333333333333, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.974, test_acc:0.9968\n",
            "node 6: train_acc: 0.666, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.995, test_acc:1.0\n",
            "node 8: train_acc: 0.9088333333333334, test_acc:0.957\n",
            "node 9: train_acc: 0.9612, test_acc:1.0\n",
            "model numbers: 10\n",
            "time 0:05:57.364653\n",
            "global acc: 0.8826009069948825\n",
            "----------------------Info befire clustering-------------\n",
            "model_len: 10\n",
            "Client IDS: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "new clustering: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
            "\n",
            "\n",
            "---------Clustering step 4\n",
            "-------------in initial genertaio\n",
            "cluster [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "clientIDs [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 10 cluster IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "cid is: 0\n",
            "cid is: 1\n",
            "cid is: 2\n",
            "cid is: 3\n",
            "cid is: 4\n",
            "cid is: 5\n",
            "cid is: 6\n",
            "cid is: 7\n",
            "cid is: 8\n",
            "cid is: 9\n",
            "\n",
            "Round 1/10\n",
            "node 0: train_acc: 0.9537777777777777, test_acc:0.9613333333333334\n",
            "node 1: train_acc: 0.9445714285714286, test_acc:0.976027397260274\n",
            "node 2: train_acc: 0.9908571428571429, test_acc:0.9965694682675815\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.9651111111111111, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9733333333333334, test_acc:0.9992\n",
            "node 6: train_acc: 0.70475, test_acc:0.6504126031507877\n",
            "node 7: train_acc: 0.995, test_acc:1.0\n",
            "node 8: train_acc: 0.9091666666666667, test_acc:0.953\n",
            "node 9: train_acc: 0.966, test_acc:0.996\n",
            "model numbers: 10\n",
            "time 0:00:36.021368\n",
            "global acc: 0.8731209468678645\n",
            "\n",
            "Round 2/10\n",
            "node 0: train_acc: 0.9586666666666667, test_acc:0.9673333333333334\n",
            "node 1: train_acc: 0.9397142857142857, test_acc:0.9794520547945206\n",
            "node 2: train_acc: 0.9891428571428571, test_acc:1.0\n",
            "node 3: train_acc: 0.19973333333333335, test_acc:0.2\n",
            "node 4: train_acc: 0.9142222222222223, test_acc:1.0\n",
            "node 5: train_acc: 0.9657333333333333, test_acc:0.9992\n",
            "node 6: train_acc: 0.00075, test_acc:0.0\n",
            "node 7: train_acc: 0.9956666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.9066666666666666, test_acc:0.954\n",
            "node 9: train_acc: 0.9302666666666667, test_acc:0.9984\n",
            "model numbers: 10\n",
            "time 0:01:11.448055\n",
            "global acc: 0.8098385388127853\n",
            "\n",
            "Round 3/10\n",
            "node 0: train_acc: 0.9618888888888889, test_acc:0.9626666666666667\n",
            "node 1: train_acc: 0.8345714285714285, test_acc:0.9743150684931506\n",
            "node 2: train_acc: 0.9331428571428572, test_acc:1.0\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.9888888888888889, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9732, test_acc:0.9968\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "node 7: train_acc: 0.995, test_acc:1.0\n",
            "node 8: train_acc: 0.9265, test_acc:0.955\n",
            "node 9: train_acc: 0.9473333333333334, test_acc:0.9976\n",
            "model numbers: 10\n",
            "time 0:01:46.945860\n",
            "global acc: 0.8085048401826483\n",
            "\n",
            "Round 4/10\n",
            "node 0: train_acc: 0.955, test_acc:0.968\n",
            "node 1: train_acc: 0.9508571428571428, test_acc:0.9743150684931506\n",
            "node 2: train_acc: 0.9931428571428571, test_acc:1.0\n",
            "node 3: train_acc: 0.1996, test_acc:0.2\n",
            "node 4: train_acc: 0.9644444444444444, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9676, test_acc:0.9992\n",
            "node 6: train_acc: 0.464625, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.992, test_acc:1.0\n",
            "node 8: train_acc: 0.9125, test_acc:0.955\n",
            "node 9: train_acc: 0.9604, test_acc:0.9992\n",
            "model numbers: 10\n",
            "time 0:02:23.181710\n",
            "global acc: 0.8844569282046539\n",
            "\n",
            "Round 5/10\n",
            "node 0: train_acc: 0.9587777777777777, test_acc:0.9666666666666667\n",
            "node 1: train_acc: 0.9411428571428572, test_acc:0.9794520547945206\n",
            "node 2: train_acc: 0.9834285714285714, test_acc:1.0\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.9853333333333333, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9764, test_acc:0.9984\n",
            "node 6: train_acc: 0.696625, test_acc:0.7516879219804952\n",
            "node 7: train_acc: 0.9946666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.9248333333333333, test_acc:0.957\n",
            "node 9: train_acc: 0.9674666666666667, test_acc:0.9968\n",
            "model numbers: 10\n",
            "time 0:02:59.039930\n",
            "global acc: 0.8848673310108349\n",
            "\n",
            "Round 6/10\n",
            "node 0: train_acc: 0.9572222222222222, test_acc:0.9673333333333334\n",
            "node 1: train_acc: 0.9505714285714286, test_acc:0.9691780821917808\n",
            "node 2: train_acc: 0.9911428571428571, test_acc:1.0\n",
            "node 3: train_acc: 0.19946666666666665, test_acc:0.2\n",
            "node 4: train_acc: 0.9366666666666666, test_acc:1.0\n",
            "node 5: train_acc: 0.978, test_acc:0.9968\n",
            "node 6: train_acc: 0.58275, test_acc:0.7824456114028507\n",
            "node 7: train_acc: 0.995, test_acc:1.0\n",
            "node 8: train_acc: 0.8953333333333333, test_acc:0.954\n",
            "node 9: train_acc: 0.9565333333333333, test_acc:0.996\n",
            "model numbers: 10\n",
            "time 0:03:34.239947\n",
            "global acc: 0.8865757026927966\n",
            "\n",
            "Round 7/10\n",
            "node 0: train_acc: 0.9572222222222222, test_acc:0.9666666666666667\n",
            "node 1: train_acc: 0.9522857142857143, test_acc:0.9811643835616438\n",
            "node 2: train_acc: 0.9888571428571429, test_acc:1.0\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.974, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9722666666666666, test_acc:0.9984\n",
            "node 6: train_acc: 0.713, test_acc:0.7516879219804952\n",
            "node 7: train_acc: 0.9963333333333333, test_acc:1.0\n",
            "node 8: train_acc: 0.9201666666666667, test_acc:0.955\n",
            "node 9: train_acc: 0.9688, test_acc:0.9976\n",
            "model numbers: 10\n",
            "time 0:04:10.497259\n",
            "global acc: 0.8849185638875472\n",
            "\n",
            "Round 8/10\n",
            "node 0: train_acc: 0.9555555555555556, test_acc:0.968\n",
            "node 1: train_acc: 0.9474285714285714, test_acc:0.9726027397260274\n",
            "node 2: train_acc: 0.9862857142857143, test_acc:0.9931389365351629\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.9668888888888889, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9737333333333333, test_acc:0.9992\n",
            "node 6: train_acc: 0.608, test_acc:0.7381845461365342\n",
            "node 7: train_acc: 0.997, test_acc:1.0\n",
            "node 8: train_acc: 0.8891666666666667, test_acc:0.956\n",
            "node 9: train_acc: 0.9713333333333334, test_acc:1.0\n",
            "model numbers: 10\n",
            "time 0:04:47.033950\n",
            "global acc: 0.882579288906439\n",
            "\n",
            "Round 9/10\n",
            "node 0: train_acc: 0.9553333333333334, test_acc:0.9673333333333334\n",
            "node 1: train_acc: 0.9462857142857143, test_acc:0.9811643835616438\n",
            "node 2: train_acc: 0.9851428571428571, test_acc:1.0\n",
            "node 3: train_acc: 0.19986666666666666, test_acc:0.2\n",
            "node 4: train_acc: 0.9666666666666667, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9754666666666667, test_acc:0.9992\n",
            "node 6: train_acc: 0.70975, test_acc:0.7591897974493623\n",
            "node 7: train_acc: 0.998, test_acc:1.0\n",
            "node 8: train_acc: 0.9071666666666667, test_acc:0.955\n",
            "node 9: train_acc: 0.9710666666666666, test_acc:0.9992\n",
            "model numbers: 10\n",
            "time 0:05:22.345510\n",
            "global acc: 0.8859754181011006\n",
            "\n",
            "Round 10/10\n",
            "node 0: train_acc: 0.9608888888888889, test_acc:0.9673333333333334\n",
            "node 1: train_acc: 0.9382857142857143, test_acc:0.9743150684931506\n",
            "node 2: train_acc: 0.9851428571428571, test_acc:0.9982847341337907\n",
            "node 3: train_acc: 0.19973333333333335, test_acc:0.2\n",
            "node 4: train_acc: 0.964, test_acc:1.0\n",
            "node 5: train_acc: 0.9738666666666667, test_acc:0.9992\n",
            "node 6: train_acc: 0.1995, test_acc:0.4463615903975994\n",
            "node 7: train_acc: 0.9976666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.923, test_acc:0.951\n",
            "node 9: train_acc: 0.98, test_acc:1.0\n",
            "model numbers: 10\n",
            "time 0:05:58.622623\n",
            "global acc: 0.8536494726357875\n",
            "----------------------Info befire clustering-------------\n",
            "model_len: 10\n",
            "Client IDS: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "new clustering: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n"
          ]
        }
      ],
      "source": [
        "#--------------------------------\n",
        "import copy\n",
        "\n",
        "clusters=[]\n",
        "\n",
        "initial = [i for i in range(num_clients)]\n",
        "clusters.append(initial)\n",
        "\n",
        "#client_IDs=[6,4,2,1,3]\n",
        "def generate_initial_models(step,cluster,client_IDs,client_Models):\n",
        "    print(\"-------------in initial genertaio\")\n",
        "    print(\"cluster\", cluster)\n",
        "    print(\"clientIDs\", client_IDs)\n",
        "    print(\"len_client_models(should be 10):\",len(client_Models))\n",
        "    list1=[]\n",
        "    if step==0:\n",
        "        for member in range(len(cluster)):\n",
        "            list1.append(Net())\n",
        "    else:\n",
        "        for index in cluster:\n",
        "            list1.append(client_Models[client_IDs.index(index)])\n",
        "    return list1\n",
        "\n",
        "\n",
        "\n",
        "## ---------------main\n",
        "client_Models=[]\n",
        "client_copy_models = []\n",
        "\n",
        "for step in range(Clustering_period):\n",
        "    client_copy_models=copy.deepcopy(client_Models)\n",
        "    client_Models=[]\n",
        "    print(\"\\n\\n---------Clustering step\", step)\n",
        "    FL_list=[]\n",
        "    client_IDs=[]\n",
        "    for cluster in clusters:\n",
        "        for Id in cluster:\n",
        "            client_IDs.append(Id)\n",
        "\n",
        "\n",
        "        cluster_initial_models=generate_initial_models(step,cluster,client_IDs,client_copy_models)\n",
        "        print(\" ---in making new FL----cluster models len:\", len(cluster_initial_models),\"cluster IDs:\", client_IDs)\n",
        "        #print(\"lencluster\", len(cluster_initial_models))\n",
        "        f = FL(cluster,cluster_initial_models,FL_rounds, trainloaders, testloaders, Sensitivity_percentage)\n",
        "        FL_list.append(f)\n",
        "        #plot_accuracy(f.accuracies, str(cluster))\n",
        "\n",
        "\n",
        "\n",
        "        for member in f.client_obj_list:\n",
        "            client_Models.append(member.net)\n",
        "\n",
        "        ## Save pytorch models for each client\n",
        "        for cid in client_IDs:\n",
        "          save_torch_model(client_Models[client_IDs.index(cid)], cid)\n",
        "          save_model_param(client_Models[client_IDs.index(cid)], cid, step)\n",
        "\n",
        "    print(\"----------------------Info befire clustering-------------\")\n",
        "    print(\"model_len:\", len(client_Models))\n",
        "    print(\"Client IDS:\",client_IDs )\n",
        "    '''\n",
        "    start_cluster_time = datetime.now()\n",
        "    clusters = Clustering(client_IDs, trainloaders, Sensitivity_percentage, cluster_number).Clusters\n",
        "    end_cluster_time = datetime.now()\n",
        "    exe_cluster_time = end_cluster_time - start_cluster_time\n",
        "    with open(log_file, 'a') as f:\n",
        "        f.write(f\"\\n Exe Cluster Time: {exe_cluster_time}\")\n",
        "    '''\n",
        "    print(\"new clustering:\",clusters)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fun_S156tNu",
        "outputId": "ec89e2bb-6836-4efc-cc37-0f5fe795c5e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "---------Clustering step 0\n",
            "-------------in initial genertaio\n",
            "cluster [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "clientIDs [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "len_client_models(should be 10): 0\n",
            " ---in making new FL----cluster models len: 10 cluster IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "cid is: 0\n",
            "cid is: 1\n",
            "cid is: 2\n",
            "cid is: 3\n",
            "cid is: 4\n",
            "cid is: 5\n",
            "cid is: 6\n",
            "cid is: 7\n",
            "cid is: 8\n",
            "cid is: 9\n",
            "\n",
            "Round 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-e53d7605a93b>:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "node 0: train_acc: 0.8235555555555556, test_acc:0.958\n",
            "node 1: train_acc: 0.8497142857142858, test_acc:0.9691780821917808\n",
            "node 2: train_acc: 0.8342857142857143, test_acc:1.0\n",
            "node 3: train_acc: 0.9330666666666667, test_acc:1.0\n",
            "node 4: train_acc: 0.7417777777777778, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9084, test_acc:0.9976\n",
            "node 6: train_acc: 0.71675, test_acc:0.7501875468867217\n",
            "node 7: train_acc: 0.6823333333333333, test_acc:0.992\n",
            "node 8: train_acc: 0.6683333333333333, test_acc:0.938\n",
            "node 9: train_acc: 0.8713333333333333, test_acc:0.9992\n",
            "model numbers: 10\n",
            "time 0:00:36.561999\n",
            "global acc: 0.960283229574517\n",
            "\n",
            "Round 2/10\n",
            "node 0: train_acc: 0.6644444444444444, test_acc:0.6666666666666666\n",
            "node 1: train_acc: 0.42028571428571426, test_acc:0.4229452054794521\n",
            "node 2: train_acc: 0.7774285714285715, test_acc:1.0\n",
            "node 3: train_acc: 0.16826666666666668, test_acc:0.2\n",
            "node 4: train_acc: 0.3188888888888889, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.2912, test_acc:0.996\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "node 7: train_acc: 0.8183333333333334, test_acc:1.0\n",
            "node 8: train_acc: 0.0, test_acc:0.0\n",
            "node 9: train_acc: 0.19666666666666666, test_acc:0.1992\n",
            "model numbers: 10\n",
            "time 0:01:12.401005\n",
            "global acc: 0.48181452054794527\n",
            "\n",
            "Round 3/10\n",
            "node 0: train_acc: 0.666, test_acc:0.9346666666666666\n",
            "node 1: train_acc: 0.4177142857142857, test_acc:0.4143835616438356\n",
            "node 2: train_acc: 0.428, test_acc:0.4288164665523156\n",
            "node 3: train_acc: 0.664, test_acc:0.9992\n",
            "node 4: train_acc: 0.3328888888888889, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.8736, test_acc:0.9976\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "node 7: train_acc: 0.9913333333333333, test_acc:0.998\n",
            "node 8: train_acc: 0.0, test_acc:0.0\n",
            "node 9: train_acc: 0.1996, test_acc:0.2\n",
            "model numbers: 10\n",
            "time 0:01:47.600689\n",
            "global acc: 0.5306000028196152\n",
            "\n",
            "Round 4/10\n",
            "node 0: train_acc: 0.9086666666666666, test_acc:0.9573333333333334\n",
            "node 1: train_acc: 0.416, test_acc:0.4195205479452055\n",
            "node 2: train_acc: 0.42714285714285716, test_acc:0.4288164665523156\n",
            "node 3: train_acc: 0.9566666666666667, test_acc:0.9992\n",
            "node 4: train_acc: 0.3322222222222222, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.958, test_acc:0.9976\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "node 7: train_acc: 0.998, test_acc:1.0\n",
            "node 8: train_acc: 0.3845, test_acc:0.452\n",
            "node 9: train_acc: 0.19933333333333333, test_acc:0.2\n",
            "model numbers: 10\n",
            "time 0:02:22.796772\n",
            "global acc: 0.5787803681164189\n",
            "\n",
            "Round 5/10\n",
            "node 0: train_acc: 0.9287777777777778, test_acc:0.9606666666666667\n",
            "node 1: train_acc: 0.41314285714285715, test_acc:0.4143835616438356\n",
            "node 2: train_acc: 0.426, test_acc:0.4288164665523156\n",
            "node 3: train_acc: 0.9789333333333333, test_acc:0.9992\n",
            "node 4: train_acc: 0.33266666666666667, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9356, test_acc:0.996\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "node 7: train_acc: 0.997, test_acc:1.0\n",
            "node 8: train_acc: 0.4523333333333333, test_acc:0.46\n",
            "node 9: train_acc: 0.19866666666666666, test_acc:0.2\n",
            "model numbers: 10\n",
            "time 0:02:58.351421\n",
            "global acc: 0.5792400028196152\n",
            "\n",
            "Round 6/10\n",
            "node 0: train_acc: 0.9195555555555556, test_acc:0.9486666666666667\n",
            "node 1: train_acc: 0.414, test_acc:0.4160958904109589\n",
            "node 2: train_acc: 0.42657142857142855, test_acc:0.4288164665523156\n",
            "node 3: train_acc: 0.9505333333333333, test_acc:0.9992\n",
            "node 4: train_acc: 0.33155555555555555, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9326666666666666, test_acc:0.9928\n",
            "node 6: train_acc: 0.00025, test_acc:0.0\n",
            "node 7: train_acc: 0.9963333333333333, test_acc:0.998\n",
            "node 8: train_acc: 0.4488333333333333, test_acc:0.461\n",
            "node 9: train_acc: 0.198, test_acc:0.1976\n",
            "model numbers: 10\n",
            "time 0:03:33.679307\n",
            "global acc: 0.5775512356963276\n",
            "\n",
            "Round 7/10\n",
            "node 0: train_acc: 0.9391111111111111, test_acc:0.9493333333333334\n",
            "node 1: train_acc: 0.4145714285714286, test_acc:0.4160958904109589\n",
            "node 2: train_acc: 0.4268571428571429, test_acc:0.4288164665523156\n",
            "node 3: train_acc: 0.9748, test_acc:0.9992\n",
            "node 4: train_acc: 0.3317777777777778, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.93, test_acc:0.9952\n",
            "node 6: train_acc: 0.000125, test_acc:0.0\n",
            "node 7: train_acc: 0.9966666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.44766666666666666, test_acc:0.459\n",
            "node 9: train_acc: 0.19746666666666668, test_acc:0.2\n",
            "model numbers: 10\n",
            "time 0:04:08.616289\n",
            "global acc: 0.5780979023629941\n",
            "\n",
            "Round 8/10\n",
            "node 0: train_acc: 0.9403333333333334, test_acc:0.9606666666666667\n",
            "node 1: train_acc: 0.414, test_acc:0.4160958904109589\n",
            "node 2: train_acc: 0.4785714285714286, test_acc:0.9965694682675815\n",
            "node 3: train_acc: 0.7608, test_acc:1.0\n",
            "node 4: train_acc: 0.3322222222222222, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.8309333333333333, test_acc:0.9968\n",
            "node 6: train_acc: 0.002875, test_acc:0.0\n",
            "node 7: train_acc: 0.997, test_acc:1.0\n",
            "node 8: train_acc: 0.44483333333333336, test_acc:0.461\n",
            "node 9: train_acc: 0.19733333333333333, test_acc:0.1992\n",
            "model numbers: 10\n",
            "time 0:04:44.223074\n",
            "global acc: 0.6363665358678541\n",
            "\n",
            "Round 9/10\n",
            "node 0: train_acc: 0.9392222222222222, test_acc:0.9606666666666667\n",
            "node 1: train_acc: 0.4154285714285714, test_acc:0.4160958904109589\n",
            "node 2: train_acc: 0.6971428571428572, test_acc:1.0\n",
            "node 3: train_acc: 0.9785333333333334, test_acc:0.9992\n",
            "node 4: train_acc: 0.4955555555555556, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.8696, test_acc:0.992\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "node 7: train_acc: 0.9976666666666667, test_acc:1.0\n",
            "node 8: train_acc: 0.446, test_acc:0.469\n",
            "node 9: train_acc: 0.198, test_acc:0.1968\n",
            "model numbers: 10\n",
            "time 0:05:19.853051\n",
            "global acc: 0.7032429223744292\n",
            "\n",
            "Round 10/10\n",
            "node 0: train_acc: 0.9372222222222222, test_acc:0.95\n",
            "node 1: train_acc: 0.4134285714285714, test_acc:0.4143835616438356\n",
            "node 2: train_acc: 0.84, test_acc:1.0\n",
            "node 3: train_acc: 0.6848, test_acc:0.9992\n",
            "node 4: train_acc: 0.3328888888888889, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9418666666666666, test_acc:0.9976\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "node 7: train_acc: 0.9983333333333333, test_acc:1.0\n",
            "node 8: train_acc: 0.447, test_acc:0.465\n",
            "node 9: train_acc: 0.1968, test_acc:0.1992\n",
            "model numbers: 10\n",
            "time 0:05:54.719639\n",
            "global acc: 0.6358716894977169\n",
            "----------------------Info befire clustering-------------\n",
            "model_len: 10\n",
            "Client IDS: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "cluster results:[0 1 2 1 2 2 3 1 0 2]\n",
            "new clustering: [[0, 8], [1, 3, 7], [2, 4, 5, 9], [6]]\n",
            "\n",
            "\n",
            "---------Clustering step 1\n",
            "-------------in initial genertaio\n",
            "cluster [0, 8]\n",
            "clientIDs [0, 8]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 2 cluster IDs: [0, 8]\n",
            "cid is: 0\n",
            "cid is: 8\n",
            "\n",
            "Round 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-e53d7605a93b>:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "node 0: train_acc: 0.9405555555555556, test_acc:0.958\n",
            "node 8: train_acc: 0.4505, test_acc:0.471\n",
            "model numbers: 2\n",
            "time 0:00:09.294562\n",
            "global acc: 0.7144999999999999\n",
            "\n",
            "Round 2/10\n",
            "node 0: train_acc: 0.9563333333333334, test_acc:0.9486666666666667\n",
            "node 8: train_acc: 0.4686666666666667, test_acc:0.479\n",
            "model numbers: 2\n",
            "time 0:00:18.572960\n",
            "global acc: 0.7138333333333333\n",
            "\n",
            "Round 3/10\n",
            "node 0: train_acc: 0.9555555555555556, test_acc:0.954\n",
            "node 8: train_acc: 0.4646666666666667, test_acc:0.476\n",
            "model numbers: 2\n",
            "time 0:00:26.819005\n",
            "global acc: 0.715\n",
            "\n",
            "Round 4/10\n",
            "node 0: train_acc: 0.9604444444444444, test_acc:0.95\n",
            "node 8: train_acc: 0.4678333333333333, test_acc:0.48\n",
            "model numbers: 2\n",
            "time 0:00:36.216619\n",
            "global acc: 0.715\n",
            "\n",
            "Round 5/10\n",
            "node 0: train_acc: 0.9612222222222222, test_acc:0.968\n",
            "node 8: train_acc: 0.482, test_acc:0.488\n",
            "model numbers: 2\n",
            "time 0:00:45.661776\n",
            "global acc: 0.728\n",
            "\n",
            "Round 6/10\n",
            "node 0: train_acc: 0.9635555555555556, test_acc:0.9666666666666667\n",
            "node 8: train_acc: 0.48, test_acc:0.485\n",
            "model numbers: 2\n",
            "time 0:00:53.874023\n",
            "global acc: 0.7258333333333333\n",
            "\n",
            "Round 7/10\n",
            "node 0: train_acc: 0.9615555555555556, test_acc:0.9666666666666667\n",
            "node 8: train_acc: 0.4811666666666667, test_acc:0.476\n",
            "model numbers: 2\n",
            "time 0:01:03.336248\n",
            "global acc: 0.7213333333333334\n",
            "\n",
            "Round 8/10\n",
            "node 0: train_acc: 0.9638888888888889, test_acc:0.9606666666666667\n",
            "node 8: train_acc: 0.4866666666666667, test_acc:0.493\n",
            "model numbers: 2\n",
            "time 0:01:12.602976\n",
            "global acc: 0.7268333333333333\n",
            "\n",
            "Round 9/10\n",
            "node 0: train_acc: 0.9663333333333334, test_acc:0.9686666666666667\n",
            "node 8: train_acc: 0.48533333333333334, test_acc:0.492\n",
            "model numbers: 2\n",
            "time 0:01:20.762838\n",
            "global acc: 0.7303333333333333\n",
            "\n",
            "Round 10/10\n",
            "node 0: train_acc: 0.9665555555555555, test_acc:0.9666666666666667\n",
            "node 8: train_acc: 0.4866666666666667, test_acc:0.491\n",
            "model numbers: 2\n",
            "time 0:01:30.158763\n",
            "global acc: 0.7288333333333333\n",
            "-------------in initial genertaio\n",
            "cluster [1, 3, 7]\n",
            "clientIDs [0, 8, 1, 3, 7]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 3 cluster IDs: [0, 8, 1, 3, 7]\n",
            "cid is: 1\n",
            "cid is: 3\n",
            "cid is: 7\n",
            "\n",
            "Round 1/10\n",
            "node 1: train_acc: 0.4105714285714286, test_acc:0.4178082191780822\n",
            "node 3: train_acc: 0.9616, test_acc:0.9992\n",
            "node 7: train_acc: 0.9956666666666667, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:08.685422\n",
            "global acc: 0.805669406392694\n",
            "\n",
            "Round 2/10\n",
            "node 1: train_acc: 0.41514285714285715, test_acc:0.4160958904109589\n",
            "node 3: train_acc: 0.9897333333333334, test_acc:0.9992\n",
            "node 7: train_acc: 0.998, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:16.213150\n",
            "global acc: 0.8050986301369862\n",
            "\n",
            "Round 3/10\n",
            "node 1: train_acc: 0.414, test_acc:0.4212328767123288\n",
            "node 3: train_acc: 0.9868, test_acc:1.0\n",
            "node 7: train_acc: 0.998, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:24.952094\n",
            "global acc: 0.8070776255707762\n",
            "\n",
            "Round 4/10\n",
            "node 1: train_acc: 0.414, test_acc:0.4178082191780822\n",
            "node 3: train_acc: 0.9909333333333333, test_acc:0.9992\n",
            "node 7: train_acc: 0.998, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:33.291244\n",
            "global acc: 0.805669406392694\n",
            "\n",
            "Round 5/10\n",
            "node 1: train_acc: 0.41514285714285715, test_acc:0.4195205479452055\n",
            "node 3: train_acc: 0.9897333333333334, test_acc:0.9992\n",
            "node 7: train_acc: 0.9976666666666667, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:41.188624\n",
            "global acc: 0.8062401826484017\n",
            "\n",
            "Round 6/10\n",
            "node 1: train_acc: 0.41685714285714287, test_acc:0.4178082191780822\n",
            "node 3: train_acc: 0.9878666666666667, test_acc:1.0\n",
            "node 7: train_acc: 0.9986666666666667, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:50.058141\n",
            "global acc: 0.8059360730593608\n",
            "\n",
            "Round 7/10\n",
            "node 1: train_acc: 0.416, test_acc:0.4160958904109589\n",
            "node 3: train_acc: 0.9870666666666666, test_acc:0.9992\n",
            "node 7: train_acc: 0.9986666666666667, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:58.190925\n",
            "global acc: 0.8050986301369862\n",
            "\n",
            "Round 8/10\n",
            "node 1: train_acc: 0.41514285714285715, test_acc:0.4229452054794521\n",
            "node 3: train_acc: 0.9870666666666666, test_acc:1.0\n",
            "node 7: train_acc: 0.998, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:01:06.690122\n",
            "global acc: 0.807648401826484\n",
            "\n",
            "Round 9/10\n",
            "node 1: train_acc: 0.4174285714285714, test_acc:0.4229452054794521\n",
            "node 3: train_acc: 0.9873333333333333, test_acc:0.9992\n",
            "node 7: train_acc: 0.9983333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:01:15.652787\n",
            "global acc: 0.8073817351598174\n",
            "\n",
            "Round 10/10\n",
            "node 1: train_acc: 0.414, test_acc:0.4160958904109589\n",
            "node 3: train_acc: 0.9846666666666667, test_acc:0.9992\n",
            "node 7: train_acc: 0.9983333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:01:23.536270\n",
            "global acc: 0.8050986301369862\n",
            "-------------in initial genertaio\n",
            "cluster [2, 4, 5, 9]\n",
            "clientIDs [0, 8, 1, 3, 7, 2, 4, 5, 9]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 4 cluster IDs: [0, 8, 1, 3, 7, 2, 4, 5, 9]\n",
            "cid is: 2\n",
            "cid is: 4\n",
            "cid is: 5\n",
            "cid is: 9\n",
            "\n",
            "Round 1/10\n",
            "node 2: train_acc: 0.8702857142857143, test_acc:1.0\n",
            "node 4: train_acc: 0.332, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.8866666666666667, test_acc:0.9952\n",
            "node 9: train_acc: 0.1976, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:00:13.961369\n",
            "global acc: 0.6319333333333332\n",
            "\n",
            "Round 2/10\n",
            "node 2: train_acc: 0.972, test_acc:0.9982847341337907\n",
            "node 4: train_acc: 0.33111111111111113, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.986, test_acc:0.9976\n",
            "node 9: train_acc: 0.19813333333333333, test_acc:0.2\n",
            "model numbers: 4\n",
            "time 0:00:27.756605\n",
            "global acc: 0.6323045168667811\n",
            "\n",
            "Round 3/10\n",
            "node 2: train_acc: 0.984, test_acc:0.9982847341337907\n",
            "node 4: train_acc: 0.3317777777777778, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9732, test_acc:0.9976\n",
            "node 9: train_acc: 0.19813333333333333, test_acc:0.1976\n",
            "model numbers: 4\n",
            "time 0:00:41.360492\n",
            "global acc: 0.6317045168667811\n",
            "\n",
            "Round 4/10\n",
            "node 2: train_acc: 0.9725714285714285, test_acc:1.0\n",
            "node 4: train_acc: 0.33355555555555555, test_acc:0.3333333333333333\n",
            "node 5: train_acc: 0.9873333333333333, test_acc:0.9976\n",
            "node 9: train_acc: 0.1984, test_acc:0.1984\n",
            "model numbers: 4\n",
            "time 0:00:55.118328\n",
            "global acc: 0.6323333333333333\n",
            "\n",
            "Round 5/10\n",
            "node 2: train_acc: 0.9888571428571429, test_acc:0.9982847341337907\n",
            "node 4: train_acc: 0.8055555555555556, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9789333333333333, test_acc:0.9984\n",
            "node 9: train_acc: 0.19893333333333332, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:08.697594\n",
            "global acc: 0.7986378502001142\n",
            "\n",
            "Round 6/10\n",
            "node 2: train_acc: 0.9691428571428572, test_acc:1.0\n",
            "node 4: train_acc: 0.962, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9822666666666666, test_acc:0.9984\n",
            "node 9: train_acc: 0.19893333333333332, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:22.450864\n",
            "global acc: 0.7990666666666667\n",
            "\n",
            "Round 7/10\n",
            "node 2: train_acc: 0.9842857142857143, test_acc:1.0\n",
            "node 4: train_acc: 0.9835555555555555, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9809333333333333, test_acc:0.9984\n",
            "node 9: train_acc: 0.19866666666666666, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:36.184728\n",
            "global acc: 0.7990666666666667\n",
            "\n",
            "Round 8/10\n",
            "node 2: train_acc: 0.9777142857142858, test_acc:1.0\n",
            "node 4: train_acc: 0.9731111111111111, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9772, test_acc:0.9968\n",
            "node 9: train_acc: 0.19866666666666666, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:49.944929\n",
            "global acc: 0.7986666666666666\n",
            "\n",
            "Round 9/10\n",
            "node 2: train_acc: 0.9777142857142858, test_acc:1.0\n",
            "node 4: train_acc: 0.9755555555555555, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9736, test_acc:0.9976\n",
            "node 9: train_acc: 0.19853333333333334, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:02:03.608301\n",
            "global acc: 0.7988666666666667\n",
            "\n",
            "Round 10/10\n",
            "node 2: train_acc: 0.9802857142857143, test_acc:1.0\n",
            "node 4: train_acc: 0.9728888888888889, test_acc:0.9973333333333333\n",
            "node 5: train_acc: 0.9785333333333334, test_acc:0.996\n",
            "node 9: train_acc: 0.19933333333333333, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:02:17.138291\n",
            "global acc: 0.7981333333333333\n",
            "-------------in initial genertaio\n",
            "cluster [6]\n",
            "clientIDs [0, 8, 1, 3, 7, 2, 4, 5, 9, 6]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 1 cluster IDs: [0, 8, 1, 3, 7, 2, 4, 5, 9, 6]\n",
            "cid is: 6\n",
            "\n",
            "Round 1/10\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "model numbers: 1\n",
            "time 0:00:04.294993\n",
            "global acc: 0.0\n",
            "\n",
            "Round 2/10\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "model numbers: 1\n",
            "time 0:00:08.710777\n",
            "global acc: 0.0\n",
            "\n",
            "Round 3/10\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "model numbers: 1\n",
            "time 0:00:14.111093\n",
            "global acc: 0.0\n",
            "\n",
            "Round 4/10\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "model numbers: 1\n",
            "time 0:00:18.433539\n",
            "global acc: 0.0\n",
            "\n",
            "Round 5/10\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "model numbers: 1\n",
            "time 0:00:23.296977\n",
            "global acc: 0.0\n",
            "\n",
            "Round 6/10\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "model numbers: 1\n",
            "time 0:00:28.192320\n",
            "global acc: 0.0\n",
            "\n",
            "Round 7/10\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "model numbers: 1\n",
            "time 0:00:32.568265\n",
            "global acc: 0.0\n",
            "\n",
            "Round 8/10\n",
            "node 6: train_acc: 0.0, test_acc:0.0\n",
            "model numbers: 1\n",
            "time 0:00:38.177647\n",
            "global acc: 0.0\n",
            "\n",
            "Round 9/10\n",
            "node 6: train_acc: 0.00025, test_acc:0.0\n",
            "model numbers: 1\n",
            "time 0:00:42.510829\n",
            "global acc: 0.0\n",
            "\n",
            "Round 10/10\n",
            "node 6: train_acc: 0.62525, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:46.823613\n",
            "global acc: 0.7501875468867217\n",
            "----------------------Info befire clustering-------------\n",
            "model_len: 10\n",
            "Client IDS: [0, 8, 1, 3, 7, 2, 4, 5, 9, 6]\n",
            "cluster results:[0 0 1 1 1 2 2 2 2 3]\n",
            "new clustering: [[0, 8], [1, 3, 7], [2, 4, 5, 9], [6]]\n",
            "\n",
            "\n",
            "---------Clustering step 2\n",
            "-------------in initial genertaio\n",
            "cluster [0, 8]\n",
            "clientIDs [0, 8]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 2 cluster IDs: [0, 8]\n",
            "cid is: 0\n",
            "cid is: 8\n",
            "\n",
            "Round 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-e53d7605a93b>:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "node 0: train_acc: 0.967, test_acc:0.972\n",
            "node 8: train_acc: 0.4866666666666667, test_acc:0.495\n",
            "model numbers: 2\n",
            "time 0:00:09.241879\n",
            "global acc: 0.7335\n",
            "\n",
            "Round 2/10\n",
            "node 0: train_acc: 0.9686666666666667, test_acc:0.9713333333333334\n",
            "node 8: train_acc: 0.48966666666666664, test_acc:0.491\n",
            "model numbers: 2\n",
            "time 0:00:18.629800\n",
            "global acc: 0.7311666666666667\n",
            "\n",
            "Round 3/10\n",
            "node 0: train_acc: 0.9676666666666667, test_acc:0.9713333333333334\n",
            "node 8: train_acc: 0.489, test_acc:0.494\n",
            "model numbers: 2\n",
            "time 0:00:26.910286\n",
            "global acc: 0.7326666666666667\n",
            "\n",
            "Round 4/10\n",
            "node 0: train_acc: 0.9692222222222222, test_acc:0.9726666666666667\n",
            "node 8: train_acc: 0.48966666666666664, test_acc:0.494\n",
            "model numbers: 2\n",
            "time 0:00:36.116083\n",
            "global acc: 0.7333333333333334\n",
            "\n",
            "Round 5/10\n",
            "node 0: train_acc: 0.9708888888888889, test_acc:0.9733333333333334\n",
            "node 8: train_acc: 0.49, test_acc:0.488\n",
            "model numbers: 2\n",
            "time 0:00:45.541131\n",
            "global acc: 0.7306666666666667\n",
            "\n",
            "Round 6/10\n",
            "node 0: train_acc: 0.9728888888888889, test_acc:0.9726666666666667\n",
            "node 8: train_acc: 0.49033333333333334, test_acc:0.496\n",
            "model numbers: 2\n",
            "time 0:00:53.910691\n",
            "global acc: 0.7343333333333333\n",
            "\n",
            "Round 7/10\n",
            "node 0: train_acc: 0.9732222222222222, test_acc:0.9753333333333334\n",
            "node 8: train_acc: 0.49016666666666664, test_acc:0.49\n",
            "model numbers: 2\n",
            "time 0:01:02.836757\n",
            "global acc: 0.7326666666666667\n",
            "\n",
            "Round 8/10\n",
            "node 0: train_acc: 0.974, test_acc:0.9753333333333334\n",
            "node 8: train_acc: 0.49066666666666664, test_acc:0.495\n",
            "model numbers: 2\n",
            "time 0:01:12.126676\n",
            "global acc: 0.7351666666666667\n",
            "\n",
            "Round 9/10\n",
            "node 0: train_acc: 0.9726666666666667, test_acc:0.9766666666666667\n",
            "node 8: train_acc: 0.49133333333333334, test_acc:0.495\n",
            "model numbers: 2\n",
            "time 0:01:20.937355\n",
            "global acc: 0.7358333333333333\n",
            "\n",
            "Round 10/10\n",
            "node 0: train_acc: 0.9747777777777777, test_acc:0.9786666666666667\n",
            "node 8: train_acc: 0.49083333333333334, test_acc:0.494\n",
            "model numbers: 2\n",
            "time 0:01:29.673993\n",
            "global acc: 0.7363333333333333\n",
            "-------------in initial genertaio\n",
            "cluster [1, 3, 7]\n",
            "clientIDs [0, 8, 1, 3, 7]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 3 cluster IDs: [0, 8, 1, 3, 7]\n",
            "cid is: 1\n",
            "cid is: 3\n",
            "cid is: 7\n",
            "\n",
            "Round 1/10\n",
            "node 1: train_acc: 0.41714285714285715, test_acc:0.4212328767123288\n",
            "node 3: train_acc: 0.9866666666666667, test_acc:0.9992\n",
            "node 7: train_acc: 0.9983333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:08.952424\n",
            "global acc: 0.8068109589041096\n",
            "\n",
            "Round 2/10\n",
            "node 1: train_acc: 0.41628571428571426, test_acc:0.4195205479452055\n",
            "node 3: train_acc: 0.9890666666666666, test_acc:0.9992\n",
            "node 7: train_acc: 0.9986666666666667, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:17.018362\n",
            "global acc: 0.8062401826484017\n",
            "\n",
            "Round 3/10\n",
            "node 1: train_acc: 0.41514285714285715, test_acc:0.4178082191780822\n",
            "node 3: train_acc: 0.9878666666666667, test_acc:0.9992\n",
            "node 7: train_acc: 0.9993333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:25.676736\n",
            "global acc: 0.805669406392694\n",
            "\n",
            "Round 4/10\n",
            "node 1: train_acc: 0.41628571428571426, test_acc:0.4160958904109589\n",
            "node 3: train_acc: 0.9873333333333333, test_acc:0.9992\n",
            "node 7: train_acc: 0.9983333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:34.642530\n",
            "global acc: 0.8050986301369862\n",
            "\n",
            "Round 5/10\n",
            "node 1: train_acc: 0.4174285714285714, test_acc:0.4178082191780822\n",
            "node 3: train_acc: 0.9873333333333333, test_acc:1.0\n",
            "node 7: train_acc: 0.9983333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:42.451316\n",
            "global acc: 0.8059360730593608\n",
            "\n",
            "Round 6/10\n",
            "node 1: train_acc: 0.4157142857142857, test_acc:0.4178082191780822\n",
            "node 3: train_acc: 0.9905333333333334, test_acc:1.0\n",
            "node 7: train_acc: 0.9993333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:51.339908\n",
            "global acc: 0.8059360730593608\n",
            "\n",
            "Round 7/10\n",
            "node 1: train_acc: 0.4157142857142857, test_acc:0.4178082191780822\n",
            "node 3: train_acc: 0.9873333333333333, test_acc:0.9976\n",
            "node 7: train_acc: 0.9986666666666667, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:01:00.189182\n",
            "global acc: 0.8051360730593607\n",
            "\n",
            "Round 8/10\n",
            "node 1: train_acc: 0.4145714285714286, test_acc:0.4178082191780822\n",
            "node 3: train_acc: 0.9878666666666667, test_acc:0.9992\n",
            "node 7: train_acc: 0.9993333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:01:08.002715\n",
            "global acc: 0.805669406392694\n",
            "\n",
            "Round 9/10\n",
            "node 1: train_acc: 0.416, test_acc:0.4178082191780822\n",
            "node 3: train_acc: 0.9881333333333333, test_acc:1.0\n",
            "node 7: train_acc: 0.9986666666666667, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:01:16.923292\n",
            "global acc: 0.8059360730593608\n",
            "\n",
            "Round 10/10\n",
            "node 1: train_acc: 0.4165714285714286, test_acc:0.4195205479452055\n",
            "node 3: train_acc: 0.9868, test_acc:0.9992\n",
            "node 7: train_acc: 0.9993333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:01:25.655570\n",
            "global acc: 0.8062401826484017\n",
            "-------------in initial genertaio\n",
            "cluster [2, 4, 5, 9]\n",
            "clientIDs [0, 8, 1, 3, 7, 2, 4, 5, 9]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 4 cluster IDs: [0, 8, 1, 3, 7, 2, 4, 5, 9]\n",
            "cid is: 2\n",
            "cid is: 4\n",
            "cid is: 5\n",
            "cid is: 9\n",
            "\n",
            "Round 1/10\n",
            "node 2: train_acc: 0.9791428571428571, test_acc:1.0\n",
            "node 4: train_acc: 0.9728888888888889, test_acc:1.0\n",
            "node 5: train_acc: 0.9826666666666667, test_acc:0.9984\n",
            "node 9: train_acc: 0.19893333333333332, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:00:13.412369\n",
            "global acc: 0.7994\n",
            "\n",
            "Round 2/10\n",
            "node 2: train_acc: 0.9757142857142858, test_acc:1.0\n",
            "node 4: train_acc: 0.9851111111111112, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9714666666666667, test_acc:0.9984\n",
            "node 9: train_acc: 0.1988, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:00:27.042531\n",
            "global acc: 0.7990666666666667\n",
            "\n",
            "Round 3/10\n",
            "node 2: train_acc: 0.9851428571428571, test_acc:1.0\n",
            "node 4: train_acc: 0.9695555555555555, test_acc:1.0\n",
            "node 5: train_acc: 0.9858666666666667, test_acc:0.9984\n",
            "node 9: train_acc: 0.1988, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:00:40.697095\n",
            "global acc: 0.7994\n",
            "\n",
            "Round 4/10\n",
            "node 2: train_acc: 0.97, test_acc:1.0\n",
            "node 4: train_acc: 0.9808888888888889, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9737333333333333, test_acc:0.9984\n",
            "node 9: train_acc: 0.1992, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:00:54.338176\n",
            "global acc: 0.7990666666666667\n",
            "\n",
            "Round 5/10\n",
            "node 2: train_acc: 0.9882857142857143, test_acc:1.0\n",
            "node 4: train_acc: 0.9848888888888889, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9852, test_acc:0.9984\n",
            "node 9: train_acc: 0.1992, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:07.972850\n",
            "global acc: 0.7990666666666667\n",
            "\n",
            "Round 6/10\n",
            "node 2: train_acc: 0.9722857142857143, test_acc:1.0\n",
            "node 4: train_acc: 0.9824444444444445, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9794666666666667, test_acc:0.9984\n",
            "node 9: train_acc: 0.19853333333333334, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:21.634632\n",
            "global acc: 0.7990666666666667\n",
            "\n",
            "Round 7/10\n",
            "node 2: train_acc: 0.9782857142857143, test_acc:1.0\n",
            "node 4: train_acc: 0.9851111111111112, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9852, test_acc:0.9984\n",
            "node 9: train_acc: 0.19893333333333332, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:35.338830\n",
            "global acc: 0.7990666666666667\n",
            "\n",
            "Round 8/10\n",
            "node 2: train_acc: 0.9848571428571429, test_acc:1.0\n",
            "node 4: train_acc: 0.9846666666666667, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9782666666666666, test_acc:0.9984\n",
            "node 9: train_acc: 0.1996, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:48.976462\n",
            "global acc: 0.7990666666666667\n",
            "\n",
            "Round 9/10\n",
            "node 2: train_acc: 0.9808571428571429, test_acc:1.0\n",
            "node 4: train_acc: 0.9826666666666667, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9846666666666667, test_acc:0.9992\n",
            "node 9: train_acc: 0.19893333333333332, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:02:02.866814\n",
            "global acc: 0.7992666666666667\n",
            "\n",
            "Round 10/10\n",
            "node 2: train_acc: 0.9794285714285714, test_acc:1.0\n",
            "node 4: train_acc: 0.9828888888888889, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9777333333333333, test_acc:0.9984\n",
            "node 9: train_acc: 0.19946666666666665, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:02:16.542636\n",
            "global acc: 0.7990666666666667\n",
            "-------------in initial genertaio\n",
            "cluster [6]\n",
            "clientIDs [0, 8, 1, 3, 7, 2, 4, 5, 9, 6]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 1 cluster IDs: [0, 8, 1, 3, 7, 2, 4, 5, 9, 6]\n",
            "cid is: 6\n",
            "\n",
            "Round 1/10\n",
            "node 6: train_acc: 0.75, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:04.349630\n",
            "global acc: 0.7501875468867217\n",
            "\n",
            "Round 2/10\n",
            "node 6: train_acc: 0.75, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:09.642644\n",
            "global acc: 0.7501875468867217\n",
            "\n",
            "Round 3/10\n",
            "node 6: train_acc: 0.75, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:13.995307\n",
            "global acc: 0.7501875468867217\n",
            "\n",
            "Round 4/10\n",
            "node 6: train_acc: 0.75, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:18.311391\n",
            "global acc: 0.7501875468867217\n",
            "\n",
            "Round 5/10\n",
            "node 6: train_acc: 0.75, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:23.709601\n",
            "global acc: 0.7501875468867217\n",
            "\n",
            "Round 6/10\n",
            "node 6: train_acc: 0.75, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:28.019208\n",
            "global acc: 0.7501875468867217\n",
            "\n",
            "Round 7/10\n",
            "node 6: train_acc: 0.75, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:32.901795\n",
            "global acc: 0.7501875468867217\n",
            "\n",
            "Round 8/10\n",
            "node 6: train_acc: 0.75, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:37.875172\n",
            "global acc: 0.7501875468867217\n",
            "\n",
            "Round 9/10\n",
            "node 6: train_acc: 0.75, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:42.183644\n",
            "global acc: 0.7501875468867217\n",
            "\n",
            "Round 10/10\n",
            "node 6: train_acc: 0.75, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:47.519870\n",
            "global acc: 0.7501875468867217\n",
            "----------------------Info befire clustering-------------\n",
            "model_len: 10\n",
            "Client IDS: [0, 8, 1, 3, 7, 2, 4, 5, 9, 6]\n",
            "cluster results:[0 0 1 1 1 2 2 2 2 3]\n",
            "new clustering: [[0, 8], [1, 3, 7], [2, 4, 5, 9], [6]]\n",
            "\n",
            "\n",
            "---------Clustering step 3\n",
            "-------------in initial genertaio\n",
            "cluster [0, 8]\n",
            "clientIDs [0, 8]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 2 cluster IDs: [0, 8]\n",
            "cid is: 0\n",
            "cid is: 8\n",
            "\n",
            "Round 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-e53d7605a93b>:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "node 0: train_acc: 0.9752222222222222, test_acc:0.9713333333333334\n",
            "node 8: train_acc: 0.49066666666666664, test_acc:0.493\n",
            "model numbers: 2\n",
            "time 0:00:08.112652\n",
            "global acc: 0.7321666666666666\n",
            "\n",
            "Round 2/10\n",
            "node 0: train_acc: 0.9777777777777777, test_acc:0.978\n",
            "node 8: train_acc: 0.49033333333333334, test_acc:0.494\n",
            "model numbers: 2\n",
            "time 0:00:17.467562\n",
            "global acc: 0.736\n",
            "\n",
            "Round 3/10\n",
            "node 0: train_acc: 0.9765555555555555, test_acc:0.976\n",
            "node 8: train_acc: 0.4905, test_acc:0.495\n",
            "model numbers: 2\n",
            "time 0:00:26.746600\n",
            "global acc: 0.7355\n",
            "\n",
            "Round 4/10\n",
            "node 0: train_acc: 0.9766666666666667, test_acc:0.9786666666666667\n",
            "node 8: train_acc: 0.49083333333333334, test_acc:0.496\n",
            "model numbers: 2\n",
            "time 0:00:34.890674\n",
            "global acc: 0.7373333333333334\n",
            "\n",
            "Round 5/10\n",
            "node 0: train_acc: 0.978, test_acc:0.97\n",
            "node 8: train_acc: 0.49216666666666664, test_acc:0.496\n",
            "model numbers: 2\n",
            "time 0:00:44.047838\n",
            "global acc: 0.733\n",
            "\n",
            "Round 6/10\n",
            "node 0: train_acc: 0.9776666666666667, test_acc:0.978\n",
            "node 8: train_acc: 0.49133333333333334, test_acc:0.495\n",
            "model numbers: 2\n",
            "time 0:00:53.406429\n",
            "global acc: 0.7364999999999999\n",
            "\n",
            "Round 7/10\n",
            "node 0: train_acc: 0.9782222222222222, test_acc:0.98\n",
            "node 8: train_acc: 0.491, test_acc:0.495\n",
            "model numbers: 2\n",
            "time 0:01:01.530115\n",
            "global acc: 0.7375\n",
            "\n",
            "Round 8/10\n",
            "node 0: train_acc: 0.9771111111111112, test_acc:0.9786666666666667\n",
            "node 8: train_acc: 0.49216666666666664, test_acc:0.495\n",
            "model numbers: 2\n",
            "time 0:01:10.879037\n",
            "global acc: 0.7368333333333333\n",
            "\n",
            "Round 9/10\n",
            "node 0: train_acc: 0.9787777777777777, test_acc:0.978\n",
            "node 8: train_acc: 0.493, test_acc:0.497\n",
            "model numbers: 2\n",
            "time 0:01:20.236695\n",
            "global acc: 0.7375\n",
            "\n",
            "Round 10/10\n",
            "node 0: train_acc: 0.9793333333333333, test_acc:0.98\n",
            "node 8: train_acc: 0.4925, test_acc:0.496\n",
            "model numbers: 2\n",
            "time 0:01:28.594222\n",
            "global acc: 0.738\n",
            "-------------in initial genertaio\n",
            "cluster [1, 3, 7]\n",
            "clientIDs [0, 8, 1, 3, 7]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 3 cluster IDs: [0, 8, 1, 3, 7]\n",
            "cid is: 1\n",
            "cid is: 3\n",
            "cid is: 7\n",
            "\n",
            "Round 1/10\n",
            "node 1: train_acc: 0.4174285714285714, test_acc:0.4195205479452055\n",
            "node 3: train_acc: 0.9898666666666667, test_acc:0.9992\n",
            "node 7: train_acc: 0.9993333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:08.885841\n",
            "global acc: 0.8062401826484017\n",
            "\n",
            "Round 2/10\n",
            "node 1: train_acc: 0.4174285714285714, test_acc:0.4229452054794521\n",
            "node 3: train_acc: 0.988, test_acc:0.9992\n",
            "node 7: train_acc: 0.999, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:17.764312\n",
            "global acc: 0.8073817351598174\n",
            "\n",
            "Round 3/10\n",
            "node 1: train_acc: 0.4157142857142857, test_acc:0.4178082191780822\n",
            "node 3: train_acc: 0.9836, test_acc:0.9992\n",
            "node 7: train_acc: 0.9993333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:25.633889\n",
            "global acc: 0.805669406392694\n",
            "\n",
            "Round 4/10\n",
            "node 1: train_acc: 0.4174285714285714, test_acc:0.4229452054794521\n",
            "node 3: train_acc: 0.9893333333333333, test_acc:0.996\n",
            "node 7: train_acc: 0.9986666666666667, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:34.554520\n",
            "global acc: 0.8063150684931507\n",
            "\n",
            "Round 5/10\n",
            "node 1: train_acc: 0.416, test_acc:0.4178082191780822\n",
            "node 3: train_acc: 0.9882666666666666, test_acc:0.9992\n",
            "node 7: train_acc: 0.9986666666666667, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:43.390885\n",
            "global acc: 0.805669406392694\n",
            "\n",
            "Round 6/10\n",
            "node 1: train_acc: 0.4197142857142857, test_acc:0.4178082191780822\n",
            "node 3: train_acc: 0.9881333333333333, test_acc:0.9992\n",
            "node 7: train_acc: 0.9986666666666667, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:51.052134\n",
            "global acc: 0.805669406392694\n",
            "\n",
            "Round 7/10\n",
            "node 1: train_acc: 0.4208571428571429, test_acc:0.4212328767123288\n",
            "node 3: train_acc: 0.9908, test_acc:0.9992\n",
            "node 7: train_acc: 0.999, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:59.925290\n",
            "global acc: 0.8068109589041096\n",
            "\n",
            "Round 8/10\n",
            "node 1: train_acc: 0.4197142857142857, test_acc:0.4212328767123288\n",
            "node 3: train_acc: 0.9886666666666667, test_acc:0.9992\n",
            "node 7: train_acc: 0.9983333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:01:08.334805\n",
            "global acc: 0.8068109589041096\n",
            "\n",
            "Round 9/10\n",
            "node 1: train_acc: 0.4237142857142857, test_acc:0.4246575342465753\n",
            "node 3: train_acc: 0.9894666666666667, test_acc:0.9992\n",
            "node 7: train_acc: 0.9996666666666667, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:01:16.473191\n",
            "global acc: 0.8079525114155252\n",
            "\n",
            "Round 10/10\n",
            "node 1: train_acc: 0.4237142857142857, test_acc:0.4229452054794521\n",
            "node 3: train_acc: 0.9892, test_acc:0.9992\n",
            "node 7: train_acc: 0.9993333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:01:25.351745\n",
            "global acc: 0.8073817351598174\n",
            "-------------in initial genertaio\n",
            "cluster [2, 4, 5, 9]\n",
            "clientIDs [0, 8, 1, 3, 7, 2, 4, 5, 9]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 4 cluster IDs: [0, 8, 1, 3, 7, 2, 4, 5, 9]\n",
            "cid is: 2\n",
            "cid is: 4\n",
            "cid is: 5\n",
            "cid is: 9\n",
            "\n",
            "Round 1/10\n",
            "node 2: train_acc: 0.986, test_acc:1.0\n",
            "node 4: train_acc: 0.9473333333333334, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9864, test_acc:0.9976\n",
            "node 9: train_acc: 0.19866666666666666, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:00:13.528238\n",
            "global acc: 0.7988666666666667\n",
            "\n",
            "Round 2/10\n",
            "node 2: train_acc: 0.9748571428571429, test_acc:1.0\n",
            "node 4: train_acc: 0.9848888888888889, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9808, test_acc:0.9984\n",
            "node 9: train_acc: 0.19826666666666667, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:00:27.299066\n",
            "global acc: 0.7990666666666667\n",
            "\n",
            "Round 3/10\n",
            "node 2: train_acc: 0.988, test_acc:1.0\n",
            "node 4: train_acc: 0.9624444444444444, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9906666666666667, test_acc:0.9976\n",
            "node 9: train_acc: 0.1984, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:00:41.176495\n",
            "global acc: 0.7988666666666667\n",
            "\n",
            "Round 4/10\n",
            "node 2: train_acc: 0.9688571428571429, test_acc:0.9965694682675815\n",
            "node 4: train_acc: 0.9855555555555555, test_acc:1.0\n",
            "node 5: train_acc: 0.9782666666666666, test_acc:0.9992\n",
            "node 9: train_acc: 0.19866666666666666, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:00:54.941319\n",
            "global acc: 0.7987423670668954\n",
            "\n",
            "Round 5/10\n",
            "node 2: train_acc: 0.9848571428571429, test_acc:1.0\n",
            "node 4: train_acc: 0.9811111111111112, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9892, test_acc:0.9984\n",
            "node 9: train_acc: 0.19866666666666666, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:08.639571\n",
            "global acc: 0.7990666666666667\n",
            "\n",
            "Round 6/10\n",
            "node 2: train_acc: 0.9668571428571429, test_acc:1.0\n",
            "node 4: train_acc: 0.9793333333333333, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9768, test_acc:0.9992\n",
            "node 9: train_acc: 0.19813333333333333, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:22.336562\n",
            "global acc: 0.7992666666666667\n",
            "\n",
            "Round 7/10\n",
            "node 2: train_acc: 0.9865714285714285, test_acc:1.0\n",
            "node 4: train_acc: 0.9668888888888889, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9925333333333334, test_acc:0.9992\n",
            "node 9: train_acc: 0.19933333333333333, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:36.131385\n",
            "global acc: 0.7992666666666667\n",
            "\n",
            "Round 8/10\n",
            "node 2: train_acc: 0.9442857142857143, test_acc:1.0\n",
            "node 4: train_acc: 0.9788888888888889, test_acc:1.0\n",
            "node 5: train_acc: 0.9809333333333333, test_acc:0.9984\n",
            "node 9: train_acc: 0.19906666666666667, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:49.866945\n",
            "global acc: 0.7994\n",
            "\n",
            "Round 9/10\n",
            "node 2: train_acc: 0.9848571428571429, test_acc:1.0\n",
            "node 4: train_acc: 0.9811111111111112, test_acc:1.0\n",
            "node 5: train_acc: 0.9914666666666667, test_acc:0.9984\n",
            "node 9: train_acc: 0.19853333333333334, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:02:03.775908\n",
            "global acc: 0.7994\n",
            "\n",
            "Round 10/10\n",
            "node 2: train_acc: 0.8985714285714286, test_acc:1.0\n",
            "node 4: train_acc: 0.9871111111111112, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9785333333333334, test_acc:0.9992\n",
            "node 9: train_acc: 0.19906666666666667, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:02:17.396324\n",
            "global acc: 0.7992666666666667\n",
            "-------------in initial genertaio\n",
            "cluster [6]\n",
            "clientIDs [0, 8, 1, 3, 7, 2, 4, 5, 9, 6]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 1 cluster IDs: [0, 8, 1, 3, 7, 2, 4, 5, 9, 6]\n",
            "cid is: 6\n",
            "\n",
            "Round 1/10\n",
            "node 6: train_acc: 0.75, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:05.286825\n",
            "global acc: 0.7501875468867217\n",
            "\n",
            "Round 2/10\n",
            "node 6: train_acc: 0.74975, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:09.819456\n",
            "global acc: 0.7501875468867217\n",
            "\n",
            "Round 3/10\n",
            "node 6: train_acc: 0.749875, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:14.144231\n",
            "global acc: 0.7501875468867217\n",
            "\n",
            "Round 4/10\n",
            "node 6: train_acc: 0.749625, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:19.683824\n",
            "global acc: 0.7501875468867217\n",
            "\n",
            "Round 5/10\n",
            "node 6: train_acc: 0.7495, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:24.020466\n",
            "global acc: 0.7501875468867217\n",
            "\n",
            "Round 6/10\n",
            "node 6: train_acc: 0.749625, test_acc:0.7501875468867217\n",
            "model numbers: 1\n",
            "time 0:00:28.392652\n",
            "global acc: 0.7501875468867217\n",
            "\n",
            "Round 7/10\n",
            "node 6: train_acc: 0.749125, test_acc:0.7494373593398349\n",
            "model numbers: 1\n",
            "time 0:00:33.866298\n",
            "global acc: 0.7494373593398349\n",
            "\n",
            "Round 8/10\n",
            "node 6: train_acc: 0.74825, test_acc:0.7486871717929482\n",
            "model numbers: 1\n",
            "time 0:00:38.252942\n",
            "global acc: 0.7486871717929482\n",
            "\n",
            "Round 9/10\n",
            "node 6: train_acc: 0.74875, test_acc:0.746436609152288\n",
            "model numbers: 1\n",
            "time 0:00:42.868194\n",
            "global acc: 0.746436609152288\n",
            "\n",
            "Round 10/10\n",
            "node 6: train_acc: 0.748625, test_acc:0.7419354838709677\n",
            "model numbers: 1\n",
            "time 0:00:48.190987\n",
            "global acc: 0.7419354838709677\n",
            "----------------------Info befire clustering-------------\n",
            "model_len: 10\n",
            "Client IDS: [0, 8, 1, 3, 7, 2, 4, 5, 9, 6]\n",
            "cluster results:[0 0 1 1 1 2 2 2 2 3]\n",
            "new clustering: [[0, 8], [1, 3, 7], [2, 4, 5, 9], [6]]\n",
            "\n",
            "\n",
            "---------Clustering step 4\n",
            "-------------in initial genertaio\n",
            "cluster [0, 8]\n",
            "clientIDs [0, 8]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 2 cluster IDs: [0, 8]\n",
            "cid is: 0\n",
            "cid is: 8\n",
            "\n",
            "Round 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-e53d7605a93b>:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "node 0: train_acc: 0.979, test_acc:0.968\n",
            "node 8: train_acc: 0.49116666666666664, test_acc:0.495\n",
            "model numbers: 2\n",
            "time 0:00:09.259672\n",
            "global acc: 0.7315\n",
            "\n",
            "Round 2/10\n",
            "node 0: train_acc: 0.9771111111111112, test_acc:0.9806666666666667\n",
            "node 8: train_acc: 0.49416666666666664, test_acc:0.495\n",
            "model numbers: 2\n",
            "time 0:00:17.572686\n",
            "global acc: 0.7378333333333333\n",
            "\n",
            "Round 3/10\n",
            "node 0: train_acc: 0.9785555555555555, test_acc:0.9793333333333333\n",
            "node 8: train_acc: 0.49233333333333335, test_acc:0.496\n",
            "model numbers: 2\n",
            "time 0:00:26.974704\n",
            "global acc: 0.7376666666666667\n",
            "\n",
            "Round 4/10\n",
            "node 0: train_acc: 0.9773333333333334, test_acc:0.976\n",
            "node 8: train_acc: 0.49283333333333335, test_acc:0.496\n",
            "model numbers: 2\n",
            "time 0:00:36.441367\n",
            "global acc: 0.736\n",
            "\n",
            "Round 5/10\n",
            "node 0: train_acc: 0.9802222222222222, test_acc:0.9786666666666667\n",
            "node 8: train_acc: 0.4915, test_acc:0.496\n",
            "model numbers: 2\n",
            "time 0:00:44.672943\n",
            "global acc: 0.7373333333333334\n",
            "\n",
            "Round 6/10\n",
            "node 0: train_acc: 0.978, test_acc:0.9773333333333334\n",
            "node 8: train_acc: 0.49283333333333335, test_acc:0.496\n",
            "model numbers: 2\n",
            "time 0:00:53.973028\n",
            "global acc: 0.7366666666666667\n",
            "\n",
            "Round 7/10\n",
            "node 0: train_acc: 0.9801111111111112, test_acc:0.9813333333333333\n",
            "node 8: train_acc: 0.49366666666666664, test_acc:0.495\n",
            "model numbers: 2\n",
            "time 0:01:03.284963\n",
            "global acc: 0.7381666666666666\n",
            "\n",
            "Round 8/10\n",
            "node 0: train_acc: 0.979, test_acc:0.9786666666666667\n",
            "node 8: train_acc: 0.49266666666666664, test_acc:0.495\n",
            "model numbers: 2\n",
            "time 0:01:11.401987\n",
            "global acc: 0.7368333333333333\n",
            "\n",
            "Round 9/10\n",
            "node 0: train_acc: 0.9804444444444445, test_acc:0.9806666666666667\n",
            "node 8: train_acc: 0.49283333333333335, test_acc:0.496\n",
            "model numbers: 2\n",
            "time 0:01:20.796848\n",
            "global acc: 0.7383333333333333\n",
            "\n",
            "Round 10/10\n",
            "node 0: train_acc: 0.98, test_acc:0.98\n",
            "node 8: train_acc: 0.49333333333333335, test_acc:0.495\n",
            "model numbers: 2\n",
            "time 0:01:29.876747\n",
            "global acc: 0.7375\n",
            "-------------in initial genertaio\n",
            "cluster [1, 3, 7]\n",
            "clientIDs [0, 8, 1, 3, 7]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 3 cluster IDs: [0, 8, 1, 3, 7]\n",
            "cid is: 1\n",
            "cid is: 3\n",
            "cid is: 7\n",
            "\n",
            "Round 1/10\n",
            "node 1: train_acc: 0.42142857142857143, test_acc:0.4229452054794521\n",
            "node 3: train_acc: 0.9901333333333333, test_acc:0.9992\n",
            "node 7: train_acc: 0.999, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:07.580294\n",
            "global acc: 0.8073817351598174\n",
            "\n",
            "Round 2/10\n",
            "node 1: train_acc: 0.42228571428571426, test_acc:0.4246575342465753\n",
            "node 3: train_acc: 0.9892, test_acc:0.9992\n",
            "node 7: train_acc: 0.999, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:16.259324\n",
            "global acc: 0.8079525114155252\n",
            "\n",
            "Round 3/10\n",
            "node 1: train_acc: 0.4237142857142857, test_acc:0.4229452054794521\n",
            "node 3: train_acc: 0.9878666666666667, test_acc:0.9992\n",
            "node 7: train_acc: 0.9993333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:25.011158\n",
            "global acc: 0.8073817351598174\n",
            "\n",
            "Round 4/10\n",
            "node 1: train_acc: 0.4248571428571429, test_acc:0.4229452054794521\n",
            "node 3: train_acc: 0.9909333333333333, test_acc:0.9992\n",
            "node 7: train_acc: 0.9993333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:32.677165\n",
            "global acc: 0.8073817351598174\n",
            "\n",
            "Round 5/10\n",
            "node 1: train_acc: 0.424, test_acc:0.4246575342465753\n",
            "node 3: train_acc: 0.9854666666666667, test_acc:0.9992\n",
            "node 7: train_acc: 0.9996666666666667, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:41.669760\n",
            "global acc: 0.8079525114155252\n",
            "\n",
            "Round 6/10\n",
            "node 1: train_acc: 0.424, test_acc:0.4263698630136986\n",
            "node 3: train_acc: 0.992, test_acc:0.9976\n",
            "node 7: train_acc: 1.0, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:50.009683\n",
            "global acc: 0.8079899543378996\n",
            "\n",
            "Round 7/10\n",
            "node 1: train_acc: 0.42542857142857143, test_acc:0.4263698630136986\n",
            "node 3: train_acc: 0.9884, test_acc:0.9984\n",
            "node 7: train_acc: 0.9993333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:00:58.383151\n",
            "global acc: 0.8082566210045662\n",
            "\n",
            "Round 8/10\n",
            "node 1: train_acc: 0.42428571428571427, test_acc:0.4229452054794521\n",
            "node 3: train_acc: 0.9908, test_acc:0.9984\n",
            "node 7: train_acc: 0.9993333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:01:07.152121\n",
            "global acc: 0.8071150684931506\n",
            "\n",
            "Round 9/10\n",
            "node 1: train_acc: 0.42514285714285716, test_acc:0.4229452054794521\n",
            "node 3: train_acc: 0.9930666666666667, test_acc:0.9992\n",
            "node 7: train_acc: 0.9993333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:01:14.740422\n",
            "global acc: 0.8073817351598174\n",
            "\n",
            "Round 10/10\n",
            "node 1: train_acc: 0.42428571428571427, test_acc:0.4229452054794521\n",
            "node 3: train_acc: 0.9921333333333333, test_acc:0.9992\n",
            "node 7: train_acc: 0.9993333333333333, test_acc:1.0\n",
            "model numbers: 3\n",
            "time 0:01:23.425257\n",
            "global acc: 0.8073817351598174\n",
            "-------------in initial genertaio\n",
            "cluster [2, 4, 5, 9]\n",
            "clientIDs [0, 8, 1, 3, 7, 2, 4, 5, 9]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 4 cluster IDs: [0, 8, 1, 3, 7, 2, 4, 5, 9]\n",
            "cid is: 2\n",
            "cid is: 4\n",
            "cid is: 5\n",
            "cid is: 9\n",
            "\n",
            "Round 1/10\n",
            "node 2: train_acc: 0.9888571428571429, test_acc:1.0\n",
            "node 4: train_acc: 0.9735555555555555, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9821333333333333, test_acc:0.9968\n",
            "node 9: train_acc: 0.19853333333333334, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:00:13.485769\n",
            "global acc: 0.7986666666666666\n",
            "\n",
            "Round 2/10\n",
            "node 2: train_acc: 0.9654285714285714, test_acc:1.0\n",
            "node 4: train_acc: 0.9908888888888889, test_acc:1.0\n",
            "node 5: train_acc: 0.9884, test_acc:0.9984\n",
            "node 9: train_acc: 0.19906666666666667, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:00:27.110909\n",
            "global acc: 0.7994\n",
            "\n",
            "Round 3/10\n",
            "node 2: train_acc: 0.986, test_acc:1.0\n",
            "node 4: train_acc: 0.9688888888888889, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9796, test_acc:0.9984\n",
            "node 9: train_acc: 0.19933333333333333, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:00:40.823668\n",
            "global acc: 0.7990666666666667\n",
            "\n",
            "Round 4/10\n",
            "node 2: train_acc: 0.9602857142857143, test_acc:1.0\n",
            "node 4: train_acc: 0.9897777777777778, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9890666666666666, test_acc:0.9992\n",
            "node 9: train_acc: 0.19946666666666665, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:00:54.476215\n",
            "global acc: 0.7992666666666667\n",
            "\n",
            "Round 5/10\n",
            "node 2: train_acc: 0.9917142857142857, test_acc:1.0\n",
            "node 4: train_acc: 0.978, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9817333333333333, test_acc:0.9976\n",
            "node 9: train_acc: 0.19733333333333333, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:08.043821\n",
            "global acc: 0.7988666666666667\n",
            "\n",
            "Round 6/10\n",
            "node 2: train_acc: 0.9194285714285715, test_acc:1.0\n",
            "node 4: train_acc: 0.9917777777777778, test_acc:1.0\n",
            "node 5: train_acc: 0.9932, test_acc:0.9968\n",
            "node 9: train_acc: 0.19893333333333332, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:21.676383\n",
            "global acc: 0.7989999999999999\n",
            "\n",
            "Round 7/10\n",
            "node 2: train_acc: 0.9922857142857143, test_acc:1.0\n",
            "node 4: train_acc: 0.9697777777777777, test_acc:1.0\n",
            "node 5: train_acc: 0.9733333333333334, test_acc:0.9984\n",
            "node 9: train_acc: 0.19906666666666667, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:35.531556\n",
            "global acc: 0.7994\n",
            "\n",
            "Round 8/10\n",
            "node 2: train_acc: 0.9462857142857143, test_acc:0.9931389365351629\n",
            "node 4: train_acc: 0.9922222222222222, test_acc:1.0\n",
            "node 5: train_acc: 0.9925333333333334, test_acc:0.9984\n",
            "node 9: train_acc: 0.1992, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:01:49.356284\n",
            "global acc: 0.7976847341337906\n",
            "\n",
            "Round 9/10\n",
            "node 2: train_acc: 0.9908571428571429, test_acc:1.0\n",
            "node 4: train_acc: 0.9644444444444444, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9792, test_acc:0.9984\n",
            "node 9: train_acc: 0.1992, test_acc:0.1992\n",
            "model numbers: 4\n",
            "time 0:02:03.160810\n",
            "global acc: 0.7990666666666667\n",
            "\n",
            "Round 10/10\n",
            "node 2: train_acc: 0.952, test_acc:1.0\n",
            "node 4: train_acc: 0.9913333333333333, test_acc:0.9986666666666667\n",
            "node 5: train_acc: 0.9928, test_acc:0.9992\n",
            "node 9: train_acc: 0.1988, test_acc:0.1968\n",
            "model numbers: 4\n",
            "time 0:02:17.289715\n",
            "global acc: 0.7986666666666667\n",
            "-------------in initial genertaio\n",
            "cluster [6]\n",
            "clientIDs [0, 8, 1, 3, 7, 2, 4, 5, 9, 6]\n",
            "len_client_models(should be 10): 10\n",
            " ---in making new FL----cluster models len: 1 cluster IDs: [0, 8, 1, 3, 7, 2, 4, 5, 9, 6]\n",
            "cid is: 6\n",
            "\n",
            "Round 1/10\n",
            "node 6: train_acc: 0.746875, test_acc:0.7449362340585146\n",
            "model numbers: 1\n",
            "time 0:00:04.926667\n",
            "global acc: 0.7449362340585146\n",
            "\n",
            "Round 2/10\n",
            "node 6: train_acc: 0.747375, test_acc:0.7441860465116279\n",
            "model numbers: 1\n",
            "time 0:00:09.234818\n",
            "global acc: 0.7441860465116279\n",
            "\n",
            "Round 3/10\n",
            "node 6: train_acc: 0.7475, test_acc:0.741185296324081\n",
            "model numbers: 1\n",
            "time 0:00:14.601810\n",
            "global acc: 0.741185296324081\n",
            "\n",
            "Round 4/10\n",
            "node 6: train_acc: 0.747375, test_acc:0.7419354838709677\n",
            "model numbers: 1\n",
            "time 0:00:19.078306\n",
            "global acc: 0.7419354838709677\n",
            "\n",
            "Round 5/10\n",
            "node 6: train_acc: 0.746875, test_acc:0.7456864216054013\n",
            "model numbers: 1\n",
            "time 0:00:23.420273\n",
            "global acc: 0.7456864216054013\n",
            "\n",
            "Round 6/10\n",
            "node 6: train_acc: 0.7465, test_acc:0.7441860465116279\n",
            "model numbers: 1\n",
            "time 0:00:28.923277\n",
            "global acc: 0.7441860465116279\n",
            "\n",
            "Round 7/10\n",
            "node 6: train_acc: 0.746375, test_acc:0.7396849212303076\n",
            "model numbers: 1\n",
            "time 0:00:33.238179\n",
            "global acc: 0.7396849212303076\n",
            "\n",
            "Round 8/10\n",
            "node 6: train_acc: 0.74575, test_acc:0.7456864216054013\n",
            "model numbers: 1\n",
            "time 0:00:37.600128\n",
            "global acc: 0.7456864216054013\n",
            "\n",
            "Round 9/10\n",
            "node 6: train_acc: 0.747125, test_acc:0.7419354838709677\n",
            "model numbers: 1\n",
            "time 0:00:43.109222\n",
            "global acc: 0.7419354838709677\n",
            "\n",
            "Round 10/10\n",
            "node 6: train_acc: 0.746875, test_acc:0.7419354838709677\n",
            "model numbers: 1\n",
            "time 0:00:47.429234\n",
            "global acc: 0.7419354838709677\n",
            "----------------------Info befire clustering-------------\n",
            "model_len: 10\n",
            "Client IDS: [0, 8, 1, 3, 7, 2, 4, 5, 9, 6]\n",
            "cluster results:[0 0 1 1 1 2 2 2 2 0]\n",
            "new clustering: [[0, 8, 6], [1, 3, 7], [2, 4, 5, 9]]\n"
          ]
        }
      ],
      "source": [
        "#--------------------------------\n",
        "import copy\n",
        "\n",
        "clusters=[]\n",
        "\n",
        "initial = [i for i in range(num_clients)]\n",
        "clusters.append(initial)\n",
        "\n",
        "#client_IDs=[6,4,2,1,3]\n",
        "def generate_initial_models(step,cluster,client_IDs,client_Models):\n",
        "    print(\"-------------in initial genertaio\")\n",
        "    print(\"cluster\", cluster)\n",
        "    print(\"clientIDs\", client_IDs)\n",
        "    print(\"len_client_models(should be 10):\",len(client_Models))\n",
        "    list1=[]\n",
        "    if step==0:\n",
        "        for member in range(len(cluster)):\n",
        "            list1.append(Net())\n",
        "    else:\n",
        "        for index in cluster:\n",
        "            list1.append(client_Models[client_IDs.index(index)])\n",
        "    return list1\n",
        "\n",
        "\n",
        "\n",
        "## ---------------main\n",
        "client_Models=[]\n",
        "client_copy_models = []\n",
        "\n",
        "for step in range(Clustering_period):\n",
        "    client_copy_models=copy.deepcopy(client_Models)\n",
        "    client_Models=[]\n",
        "    print(\"\\n\\n---------Clustering step\", step)\n",
        "    FL_list=[]\n",
        "    client_IDs=[]\n",
        "    for cluster in clusters:\n",
        "        for Id in cluster:\n",
        "            client_IDs.append(Id)\n",
        "\n",
        "\n",
        "        cluster_initial_models=generate_initial_models(step,cluster,client_IDs,client_copy_models)\n",
        "        print(\" ---in making new FL----cluster models len:\", len(cluster_initial_models),\"cluster IDs:\", client_IDs)\n",
        "        #print(\"lencluster\", len(cluster_initial_models))\n",
        "        f = FL(cluster,cluster_initial_models,FL_rounds, trainloaders, testloaders, Sensitivity_percentage)\n",
        "        FL_list.append(f)\n",
        "        #plot_accuracy(f.accuracies, str(cluster))\n",
        "\n",
        "\n",
        "\n",
        "        for member in f.client_obj_list:\n",
        "            client_Models.append(member.net)\n",
        "\n",
        "        ## Save pytorch models for each client\n",
        "        for cid in client_IDs:\n",
        "          save_torch_model(client_Models[client_IDs.index(cid)], cid)\n",
        "          save_model_param(client_Models[client_IDs.index(cid)], cid, step)\n",
        "\n",
        "    print(\"----------------------Info befire clustering-------------\")\n",
        "    print(\"model_len:\", len(client_Models))\n",
        "    print(\"Client IDS:\",client_IDs )\n",
        "\n",
        "    start_cluster_time = datetime.now()\n",
        "    clusters = Clustering(client_IDs, trainloaders, Sensitivity_percentage, cluster_number).Clusters\n",
        "    end_cluster_time = datetime.now()\n",
        "    exe_cluster_time = end_cluster_time - start_cluster_time\n",
        "    with open(log_file, 'a') as f:\n",
        "        f.write(f\"\\n Exe Cluster Time: {exe_cluster_time}\")\n",
        "\n",
        "    print(\"new clustering:\",clusters)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n69tixG3pztj"
      },
      "source": [
        "# **NEW PARTITIONING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LCdtOH4qfjD"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.utils.data as data\n",
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torchvision.datasets import MNIST, CIFAR10, SVHN, FashionMNIST, CIFAR100, ImageFolder, DatasetFolder, utils\n",
        "from torchvision.datasets.vision import VisionDataset\n",
        "from torchvision.datasets.utils import download_file_from_google_drive, check_integrity\n",
        "from functools import partial\n",
        "from typing import Optional, Callable\n",
        "from torch.utils.model_zoo import tqdm\n",
        "import PIL\n",
        "import tarfile\n",
        "import torchvision\n",
        "\n",
        "import os\n",
        "import os.path\n",
        "import logging\n",
        "import torchvision.datasets.utils as utils\n",
        "\n",
        "logging.basicConfig()\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "IMG_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
        "\n",
        "def mkdirs(dirpath):\n",
        "    try:\n",
        "        os.makedirs(dirpath)\n",
        "    except Exception as _:\n",
        "        pass\n",
        "\n",
        "def accimage_loader(path):\n",
        "    import accimage\n",
        "    try:\n",
        "        return accimage.Image(path)\n",
        "    except IOError:\n",
        "        # Potentially a decoding problem, fall back to PIL.Image\n",
        "        return pil_loader(path)\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(path, 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "\n",
        "\n",
        "def default_loader(path):\n",
        "    from torchvision import get_image_backend\n",
        "    if get_image_backend() == 'accimage':\n",
        "        return accimage_loader(path)\n",
        "    else:\n",
        "        return pil_loader(path)\n",
        "\n",
        "class CustomTensorDataset(data.TensorDataset):\n",
        "    def __getitem__(self, index):\n",
        "        return tuple(tensor[index] for tensor in self.tensors) + (index,)\n",
        "\n",
        "\n",
        "class MNIST_truncated(data.Dataset):\n",
        "\n",
        "    def __init__(self, root, dataidxs=None, train=True, transform=None, target_transform=None, download=False):\n",
        "\n",
        "        self.root = root\n",
        "        self.dataidxs = dataidxs\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.download = download\n",
        "\n",
        "        self.data, self.target = self.__build_truncated_dataset__()\n",
        "\n",
        "    def __build_truncated_dataset__(self):\n",
        "\n",
        "        mnist_dataobj = MNIST(self.root, self.train, self.transform, self.target_transform, self.download)\n",
        "\n",
        "        # if self.train:\n",
        "        #     data = mnist_dataobj.train_data\n",
        "        #     target = mnist_dataobj.train_labels\n",
        "        # else:\n",
        "        #     data = mnist_dataobj.test_data\n",
        "        #     target = mnist_dataobj.test_labels\n",
        "\n",
        "        data = mnist_dataobj.data\n",
        "        target = mnist_dataobj.targets\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            data = data[self.dataidxs]\n",
        "            target = target[self.dataidxs]\n",
        "\n",
        "        return data, target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], self.target[index]\n",
        "\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        img = Image.fromarray(img.numpy(), mode='L')\n",
        "\n",
        "        # print(\"mnist img:\", img)\n",
        "        # print(\"mnist target:\", target)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "class FashionMNIST_truncated(data.Dataset):\n",
        "\n",
        "    def __init__(self, root, dataidxs=None, train=True, transform=None, target_transform=None, download=False):\n",
        "\n",
        "        self.root = root\n",
        "        self.dataidxs = dataidxs\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.download = download\n",
        "\n",
        "        self.data, self.target = self.__build_truncated_dataset__()\n",
        "\n",
        "    def __build_truncated_dataset__(self):\n",
        "\n",
        "        mnist_dataobj = FashionMNIST(self.root, self.train, self.transform, self.target_transform, self.download)\n",
        "\n",
        "        # if self.train:\n",
        "        #     data = mnist_dataobj.train_data\n",
        "        #     target = mnist_dataobj.train_labels\n",
        "        # else:\n",
        "        #     data = mnist_dataobj.test_data\n",
        "        #     target = mnist_dataobj.test_labels\n",
        "\n",
        "        data = mnist_dataobj.data\n",
        "        target = mnist_dataobj.targets\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            data = data[self.dataidxs]\n",
        "            target = target[self.dataidxs]\n",
        "\n",
        "        return data, target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], self.target[index]\n",
        "\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        img = Image.fromarray(img.numpy(), mode='L')\n",
        "\n",
        "        # print(\"mnist img:\", img)\n",
        "        # print(\"mnist target:\", target)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "class SVHN_custom(data.Dataset):\n",
        "\n",
        "    def __init__(self, root, dataidxs=None, train=True, transform=None, target_transform=None, download=False):\n",
        "\n",
        "        self.root = root\n",
        "        self.dataidxs = dataidxs\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.download = download\n",
        "\n",
        "        self.data, self.target = self.__build_truncated_dataset__()\n",
        "\n",
        "    def __build_truncated_dataset__(self):\n",
        "        if self.train is True:\n",
        "            # svhn_dataobj1 = SVHN(self.root, 'train', self.transform, self.target_transform, self.download)\n",
        "            # svhn_dataobj2 = SVHN(self.root, 'extra', self.transform, self.target_transform, self.download)\n",
        "            # data = np.concatenate((svhn_dataobj1.data, svhn_dataobj2.data), axis=0)\n",
        "            # target = np.concatenate((svhn_dataobj1.labels, svhn_dataobj2.labels), axis=0)\n",
        "\n",
        "            svhn_dataobj = SVHN(self.root, 'train', self.transform, self.target_transform, self.download)\n",
        "            data = svhn_dataobj.data\n",
        "            target = svhn_dataobj.labels\n",
        "        else:\n",
        "            svhn_dataobj = SVHN(self.root, 'test', self.transform, self.target_transform, self.download)\n",
        "            data = svhn_dataobj.data\n",
        "            target = svhn_dataobj.labels\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            data = data[self.dataidxs]\n",
        "            target = target[self.dataidxs]\n",
        "        # print(\"svhn data:\", data)\n",
        "        # print(\"len svhn data:\", len(data))\n",
        "        # print(\"type svhn data:\", type(data))\n",
        "        # print(\"svhn target:\", target)\n",
        "        # print(\"type svhn target\", type(target))\n",
        "        return data, target\n",
        "\n",
        "    # def truncate_channel(self, index):\n",
        "    #     for i in range(index.shape[0]):\n",
        "    #         gs_index = index[i]\n",
        "    #         self.data[gs_index, :, :, 1] = 0.0\n",
        "    #         self.data[gs_index, :, :, 2] = 0.0\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], self.target[index]\n",
        "        # print(\"svhn img:\", img)\n",
        "        # print(\"svhn target:\", target)\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        img = Image.fromarray(np.transpose(img, (1, 2, 0)))\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "# torchvision CelebA\n",
        "class CelebA_custom(VisionDataset):\n",
        "    \"\"\"`Large-scale CelebFaces Attributes (CelebA) Dataset <http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html>`_ Dataset.\n",
        "\n",
        "    Args:\n",
        "        root (string): Root directory where images are downloaded to.\n",
        "        split (string): One of {'train', 'valid', 'test', 'all'}.\n",
        "            Accordingly dataset is selected.\n",
        "        target_type (string or list, optional): Type of target to use, ``attr``, ``identity``, ``bbox``,\n",
        "            or ``landmarks``. Can also be a list to output a tuple with all specified target types.\n",
        "            The targets represent:\n",
        "                ``attr`` (np.array shape=(40,) dtype=int): binary (0, 1) labels for attributes\n",
        "                ``identity`` (int): label for each person (data points with the same identity are the same person)\n",
        "                ``bbox`` (np.array shape=(4,) dtype=int): bounding box (x, y, width, height)\n",
        "                ``landmarks`` (np.array shape=(10,) dtype=int): landmark points (lefteye_x, lefteye_y, righteye_x,\n",
        "                    righteye_y, nose_x, nose_y, leftmouth_x, leftmouth_y, rightmouth_x, rightmouth_y)\n",
        "            Defaults to ``attr``. If empty, ``None`` will be returned as target.\n",
        "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
        "            and returns a transformed version. E.g, ``transforms.ToTensor``\n",
        "        target_transform (callable, optional): A function/transform that takes in the\n",
        "            target and transforms it.\n",
        "        download (bool, optional): If true, downloads the dataset from the internet and\n",
        "            puts it in root directory. If dataset is already downloaded, it is not\n",
        "            downloaded again.\n",
        "    \"\"\"\n",
        "\n",
        "    base_folder = \"celeba\"\n",
        "    # There currently does not appear to be a easy way to extract 7z in python (without introducing additional\n",
        "    # dependencies). The \"in-the-wild\" (not aligned+cropped) images are only in 7z, so they are not available\n",
        "    # right now.\n",
        "    file_list = [\n",
        "        # File ID                         MD5 Hash                            Filename\n",
        "        (\"0B7EVK8r0v71pZjFTYXZWM3FlRnM\", \"00d2c5bc6d35e252742224ab0c1e8fcb\", \"img_align_celeba.zip\"),\n",
        "        # (\"0B7EVK8r0v71pbWNEUjJKdDQ3dGc\", \"b6cd7e93bc7a96c2dc33f819aa3ac651\", \"img_align_celeba_png.7z\"),\n",
        "        # (\"0B7EVK8r0v71peklHb0pGdDl6R28\", \"b6cd7e93bc7a96c2dc33f819aa3ac651\", \"img_celeba.7z\"),\n",
        "        (\"0B7EVK8r0v71pblRyaVFSWGxPY0U\", \"75e246fa4810816ffd6ee81facbd244c\", \"list_attr_celeba.txt\"),\n",
        "        (\"1_ee_0u7vcNLOfNLegJRHmolfH5ICW-XS\", \"32bd1bd63d3c78cd57e08160ec5ed1e2\", \"identity_CelebA.txt\"),\n",
        "        (\"0B7EVK8r0v71pbThiMVRxWXZ4dU0\", \"00566efa6fedff7a56946cd1c10f1c16\", \"list_bbox_celeba.txt\"),\n",
        "        (\"0B7EVK8r0v71pd0FJY3Blby1HUTQ\", \"cc24ecafdb5b50baae59b03474781f8c\", \"list_landmarks_align_celeba.txt\"),\n",
        "        # (\"0B7EVK8r0v71pTzJIdlJWdHczRlU\", \"063ee6ddb681f96bc9ca28c6febb9d1a\", \"list_landmarks_celeba.txt\"),\n",
        "        (\"0B7EVK8r0v71pY0NSMzRuSXJEVkk\", \"d32c9cbf5e040fd4025c592c306e6668\", \"list_eval_partition.txt\"),\n",
        "    ]\n",
        "\n",
        "    def __init__(self, root, dataidxs=None, split=\"train\", target_type=\"attr\", transform=None,\n",
        "                 target_transform=None, download=False):\n",
        "        import pandas\n",
        "        super(CelebA_custom, self).__init__(root, transform=transform,\n",
        "                                     target_transform=target_transform)\n",
        "        self.split = split\n",
        "        if isinstance(target_type, list):\n",
        "            self.target_type = target_type\n",
        "        else:\n",
        "            self.target_type = [target_type]\n",
        "\n",
        "        if not self.target_type and self.target_transform is not None:\n",
        "            raise RuntimeError('target_transform is specified but target_type is empty')\n",
        "\n",
        "        if download:\n",
        "            self.download()\n",
        "\n",
        "        if not self._check_integrity():\n",
        "            raise RuntimeError('Dataset not found or corrupted.' +\n",
        "                               ' You can use download=True to download it')\n",
        "\n",
        "        split_map = {\n",
        "            \"train\": 0,\n",
        "            \"valid\": 1,\n",
        "            \"test\": 2,\n",
        "            \"all\": None,\n",
        "        }\n",
        "        split = split_map[split.lower()]\n",
        "\n",
        "        fn = partial(os.path.join, self.root, self.base_folder)\n",
        "        splits = pandas.read_csv(fn(\"list_eval_partition.txt\"), delim_whitespace=True, header=None, index_col=0)\n",
        "        identity = pandas.read_csv(fn(\"identity_CelebA.txt\"), delim_whitespace=True, header=None, index_col=0)\n",
        "        bbox = pandas.read_csv(fn(\"list_bbox_celeba.txt\"), delim_whitespace=True, header=1, index_col=0)\n",
        "        landmarks_align = pandas.read_csv(fn(\"list_landmarks_align_celeba.txt\"), delim_whitespace=True, header=1)\n",
        "        attr = pandas.read_csv(fn(\"list_attr_celeba.txt\"), delim_whitespace=True, header=1)\n",
        "\n",
        "        mask = slice(None) if split is None else (splits[1] == split)\n",
        "\n",
        "        self.filename = splits[mask].index.values\n",
        "        self.identity = torch.as_tensor(identity[mask].values)\n",
        "        self.bbox = torch.as_tensor(bbox[mask].values)\n",
        "        self.landmarks_align = torch.as_tensor(landmarks_align[mask].values)\n",
        "        self.attr = torch.as_tensor(attr[mask].values)\n",
        "        self.attr = (self.attr + 1) // 2  # map from {-1, 1} to {0, 1}\n",
        "        self.attr_names = list(attr.columns)\n",
        "        self.gender_index = self.attr_names.index('Male')\n",
        "        self.dataidxs = dataidxs\n",
        "        if self.dataidxs is None:\n",
        "            self.target = self.attr[:, self.gender_index:self.gender_index + 1].reshape(-1)\n",
        "        else:\n",
        "            self.target = self.attr[self.dataidxs, self.gender_index:self.gender_index + 1].reshape(-1)\n",
        "\n",
        "    def _check_integrity(self):\n",
        "        for (_, md5, filename) in self.file_list:\n",
        "            fpath = os.path.join(self.root, self.base_folder, filename)\n",
        "            _, ext = os.path.splitext(filename)\n",
        "            # Allow original archive to be deleted (zip and 7z)\n",
        "            # Only need the extracted images\n",
        "            if ext not in [\".zip\", \".7z\"] and not check_integrity(fpath, md5):\n",
        "                return False\n",
        "\n",
        "        # Should check a hash of the images\n",
        "        return os.path.isdir(os.path.join(self.root, self.base_folder, \"img_align_celeba\"))\n",
        "\n",
        "    def download(self):\n",
        "        import zipfile\n",
        "\n",
        "        if self._check_integrity():\n",
        "            print('Files already downloaded and verified')\n",
        "            return\n",
        "\n",
        "        for (file_id, md5, filename) in self.file_list:\n",
        "            download_file_from_google_drive(file_id, os.path.join(self.root, self.base_folder), filename, md5)\n",
        "\n",
        "        with zipfile.ZipFile(os.path.join(self.root, self.base_folder, \"img_align_celeba.zip\"), \"r\") as f:\n",
        "            f.extractall(os.path.join(self.root, self.base_folder))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.dataidxs is None:\n",
        "            X = PIL.Image.open(os.path.join(self.root, self.base_folder, \"img_align_celeba\", self.filename[index]))\n",
        "\n",
        "            target = []\n",
        "            for t in self.target_type:\n",
        "                if t == \"attr\":\n",
        "                    target.append(self.attr[index, self.gender_index])\n",
        "                elif t == \"identity\":\n",
        "                    target.append(self.identity[index, 0])\n",
        "                elif t == \"bbox\":\n",
        "                    target.append(self.bbox[index, :])\n",
        "                elif t == \"landmarks\":\n",
        "                    target.append(self.landmarks_align[index, :])\n",
        "                else:\n",
        "                    # TODO: refactor with utils.verify_str_arg\n",
        "                    raise ValueError(\"Target type \\\"{}\\\" is not recognized.\".format(t))\n",
        "        else:\n",
        "            X = PIL.Image.open(os.path.join(self.root, self.base_folder, \"img_align_celeba\", self.filename[self.dataidxs[index]]))\n",
        "\n",
        "            target = []\n",
        "            for t in self.target_type:\n",
        "                if t == \"attr\":\n",
        "                    target.append(self.attr[self.dataidxs[index], self.gender_index])\n",
        "                elif t == \"identity\":\n",
        "                    target.append(self.identity[self.dataidxs[index], 0])\n",
        "                elif t == \"bbox\":\n",
        "                    target.append(self.bbox[self.dataidxs[index], :])\n",
        "                elif t == \"landmarks\":\n",
        "                    target.append(self.landmarks_align[self.dataidxs[index], :])\n",
        "                else:\n",
        "                    # TODO: refactor with utils.verify_str_arg\n",
        "                    raise ValueError(\"Target type \\\"{}\\\" is not recognized.\".format(t))\n",
        "\n",
        "        if self.transform is not None:\n",
        "            X = self.transform(X)\n",
        "        #print(\"target[0]:\", target[0])\n",
        "        if target:\n",
        "            target = tuple(target) if len(target) > 1 else target[0]\n",
        "\n",
        "            if self.target_transform is not None:\n",
        "                target = self.target_transform(target)\n",
        "        else:\n",
        "            target = None\n",
        "        #print(\"celeba target:\", target)\n",
        "        return X, target\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.dataidxs is None:\n",
        "            return len(self.attr)\n",
        "        else:\n",
        "            return len(self.dataidxs)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        lines = [\"Target type: {target_type}\", \"Split: {split}\"]\n",
        "        return '\\n'.join(lines).format(**self.__dict__)\n",
        "\n",
        "\n",
        "\n",
        "class CIFAR10_truncated(data.Dataset):\n",
        "\n",
        "    def __init__(self, root, dataidxs=None, train=True, transform=None, target_transform=None, download=False):\n",
        "\n",
        "        self.root = root\n",
        "        self.dataidxs = dataidxs\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.download = download\n",
        "\n",
        "        self.data, self.target = self.__build_truncated_dataset__()\n",
        "\n",
        "    def __build_truncated_dataset__(self):\n",
        "\n",
        "        cifar_dataobj = CIFAR10(self.root, self.train, self.transform, self.target_transform, self.download)\n",
        "\n",
        "        data = cifar_dataobj.data\n",
        "        target = np.array(cifar_dataobj.targets)\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            data = data[self.dataidxs]\n",
        "            target = target[self.dataidxs]\n",
        "\n",
        "        return data, target\n",
        "\n",
        "    def truncate_channel(self, index):\n",
        "        for i in range(index.shape[0]):\n",
        "            gs_index = index[i]\n",
        "            self.data[gs_index, :, :, 1] = 0.0\n",
        "            self.data[gs_index, :, :, 2] = 0.0\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], self.target[index]\n",
        "\n",
        "        # print(\"cifar10 img:\", img)\n",
        "        # print(\"cifar10 target:\", target)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "def gen_bar_updater() -> Callable[[int, int, int], None]:\n",
        "    pbar = tqdm(total=None)\n",
        "\n",
        "    def bar_update(count, block_size, total_size):\n",
        "        if pbar.total is None and total_size:\n",
        "            pbar.total = total_size\n",
        "        progress_bytes = count * block_size\n",
        "        pbar.update(progress_bytes - pbar.n)\n",
        "\n",
        "    return bar_update\n",
        "\n",
        "\n",
        "def download_url(url: str, root: str, filename: Optional[str] = None, md5: Optional[str] = None) -> None:\n",
        "    \"\"\"Download a file from a url and place it in root.\n",
        "    Args:\n",
        "        url (str): URL to download file from\n",
        "        root (str): Directory to place downloaded file in\n",
        "        filename (str, optional): Name to save the file under. If None, use the basename of the URL\n",
        "        md5 (str, optional): MD5 checksum of the download. If None, do not check\n",
        "    \"\"\"\n",
        "    import urllib\n",
        "\n",
        "    root = os.path.expanduser(root)\n",
        "    if not filename:\n",
        "        filename = os.path.basename(url)\n",
        "    fpath = os.path.join(root, filename)\n",
        "\n",
        "    os.makedirs(root, exist_ok=True)\n",
        "\n",
        "    # check if file is already present locally\n",
        "    if check_integrity(fpath, md5):\n",
        "        print('Using downloaded and verified file: ' + fpath)\n",
        "    else:   # download the file\n",
        "        try:\n",
        "            print('Downloading ' + url + ' to ' + fpath)\n",
        "            urllib.request.urlretrieve(\n",
        "                url, fpath,\n",
        "                reporthook=gen_bar_updater()\n",
        "            )\n",
        "        except (urllib.error.URLError, IOError) as e:  # type: ignore[attr-defined]\n",
        "            if url[:5] == 'https':\n",
        "                url = url.replace('https:', 'http:')\n",
        "                print('Failed download. Trying https -> http instead.'\n",
        "                      ' Downloading ' + url + ' to ' + fpath)\n",
        "                urllib.request.urlretrieve(\n",
        "                    url, fpath,\n",
        "                    reporthook=gen_bar_updater()\n",
        "                )\n",
        "            else:\n",
        "                raise e\n",
        "        # check integrity of downloaded file\n",
        "        if not check_integrity(fpath, md5):\n",
        "            raise RuntimeError(\"File not found or corrupted.\")\n",
        "\n",
        "def _is_tarxz(filename: str) -> bool:\n",
        "    return filename.endswith(\".tar.xz\")\n",
        "\n",
        "\n",
        "def _is_tar(filename: str) -> bool:\n",
        "    return filename.endswith(\".tar\")\n",
        "\n",
        "\n",
        "def _is_targz(filename: str) -> bool:\n",
        "    return filename.endswith(\".tar.gz\")\n",
        "\n",
        "\n",
        "def _is_tgz(filename: str) -> bool:\n",
        "    return filename.endswith(\".tgz\")\n",
        "\n",
        "\n",
        "def _is_gzip(filename: str) -> bool:\n",
        "    return filename.endswith(\".gz\") and not filename.endswith(\".tar.gz\")\n",
        "\n",
        "\n",
        "def _is_zip(filename: str) -> bool:\n",
        "    return filename.endswith(\".zip\")\n",
        "\n",
        "\n",
        "def extract_archive(from_path: str, to_path: Optional[str] = None, remove_finished: bool = False) -> None:\n",
        "    if to_path is None:\n",
        "        to_path = os.path.dirname(from_path)\n",
        "\n",
        "    if _is_tar(from_path):\n",
        "        with tarfile.open(from_path, 'r') as tar:\n",
        "            def is_within_directory(directory, target):\n",
        "\n",
        "                abs_directory = os.path.abspath(directory)\n",
        "                abs_target = os.path.abspath(target)\n",
        "\n",
        "                prefix = os.path.commonprefix([abs_directory, abs_target])\n",
        "\n",
        "                return prefix == abs_directory\n",
        "\n",
        "            def safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n",
        "\n",
        "                for member in tar.getmembers():\n",
        "                    member_path = os.path.join(path, member.name)\n",
        "                    if not is_within_directory(path, member_path):\n",
        "                        raise Exception(\"Attempted Path Traversal in Tar File\")\n",
        "\n",
        "                tar.extractall(path, members, numeric_owner=numeric_owner)\n",
        "\n",
        "\n",
        "            safe_extract(tar, path=to_path)\n",
        "    elif _is_targz(from_path) or _is_tgz(from_path):\n",
        "        with tarfile.open(from_path, 'r:gz') as tar:\n",
        "            def is_within_directory(directory, target):\n",
        "\n",
        "                abs_directory = os.path.abspath(directory)\n",
        "                abs_target = os.path.abspath(target)\n",
        "\n",
        "                prefix = os.path.commonprefix([abs_directory, abs_target])\n",
        "\n",
        "                return prefix == abs_directory\n",
        "\n",
        "            def safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n",
        "\n",
        "                for member in tar.getmembers():\n",
        "                    member_path = os.path.join(path, member.name)\n",
        "                    if not is_within_directory(path, member_path):\n",
        "                        raise Exception(\"Attempted Path Traversal in Tar File\")\n",
        "\n",
        "                tar.extractall(path, members, numeric_owner=numeric_owner)\n",
        "\n",
        "\n",
        "            safe_extract(tar, path=to_path)\n",
        "    elif _is_tarxz(from_path):\n",
        "        with tarfile.open(from_path, 'r:xz') as tar:\n",
        "            def is_within_directory(directory, target):\n",
        "\n",
        "                abs_directory = os.path.abspath(directory)\n",
        "                abs_target = os.path.abspath(target)\n",
        "\n",
        "                prefix = os.path.commonprefix([abs_directory, abs_target])\n",
        "\n",
        "                return prefix == abs_directory\n",
        "\n",
        "            def safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n",
        "\n",
        "                for member in tar.getmembers():\n",
        "                    member_path = os.path.join(path, member.name)\n",
        "                    if not is_within_directory(path, member_path):\n",
        "                        raise Exception(\"Attempted Path Traversal in Tar File\")\n",
        "\n",
        "                tar.extractall(path, members, numeric_owner=numeric_owner)\n",
        "\n",
        "\n",
        "            safe_extract(tar, path=to_path)\n",
        "    elif _is_gzip(from_path):\n",
        "        to_path = os.path.join(to_path, os.path.splitext(os.path.basename(from_path))[0])\n",
        "        with open(to_path, \"wb\") as out_f, gzip.GzipFile(from_path) as zip_f:\n",
        "            out_f.write(zip_f.read())\n",
        "    elif _is_zip(from_path):\n",
        "        with zipfile.ZipFile(from_path, 'r') as z:\n",
        "            z.extractall(to_path)\n",
        "    else:\n",
        "        raise ValueError(\"Extraction of {} not supported\".format(from_path))\n",
        "\n",
        "    if remove_finished:\n",
        "        os.remove(from_path)\n",
        "\n",
        "\n",
        "def download_and_extract_archive(\n",
        "    url: str,\n",
        "    download_root: str,\n",
        "    extract_root: Optional[str] = None,\n",
        "    filename: Optional[str] = None,\n",
        "    md5: Optional[str] = None,\n",
        "    remove_finished: bool = False,\n",
        ") -> None:\n",
        "    download_root = os.path.expanduser(download_root)\n",
        "    if extract_root is None:\n",
        "        extract_root = download_root\n",
        "    if not filename:\n",
        "        filename = os.path.basename(url)\n",
        "\n",
        "    download_url(url, download_root, filename, md5)\n",
        "\n",
        "    archive = os.path.join(download_root, filename)\n",
        "    print(\"Extracting {} to {}\".format(archive, extract_root))\n",
        "    extract_archive(archive, extract_root, remove_finished)\n",
        "\n",
        "class FEMNIST(MNIST):\n",
        "    \"\"\"\n",
        "    This dataset is derived from the Leaf repository\n",
        "    (https://github.com/TalwalkarLab/leaf) pre-processing of the Extended MNIST\n",
        "    dataset, grouping examples by writer. Details about Leaf were published in\n",
        "    \"LEAF: A Benchmark for Federated Settings\" https://arxiv.org/abs/1812.01097.\n",
        "    \"\"\"\n",
        "    resources = [\n",
        "        ('https://raw.githubusercontent.com/tao-shen/FEMNIST_pytorch/master/femnist.tar.gz',\n",
        "         '59c65cec646fc57fe92d27d83afdf0ed')]\n",
        "\n",
        "    def __init__(self, root, dataidxs=None, train=True, transform=None, target_transform=None,\n",
        "                 download=False):\n",
        "        super(MNIST, self).__init__(root, transform=transform,\n",
        "                                    target_transform=target_transform)\n",
        "        self.train = train\n",
        "        self.dataidxs = dataidxs\n",
        "\n",
        "        if download:\n",
        "            self.download()\n",
        "\n",
        "        if not self._check_exists():\n",
        "            raise RuntimeError('Dataset not found.' +\n",
        "                               ' You can use download=True to download it')\n",
        "        if self.train:\n",
        "            data_file = self.training_file\n",
        "        else:\n",
        "            data_file = self.test_file\n",
        "\n",
        "        self.data, self.targets, self.users_index = torch.load(os.path.join(self.processed_folder, data_file))\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            self.data = self.data[self.dataidxs]\n",
        "            self.targets = self.targets[self.dataidxs]\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index], int(self.targets[index])\n",
        "        img = Image.fromarray(img.numpy(), mode='F')\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "        return img, target\n",
        "\n",
        "    def download(self):\n",
        "        \"\"\"Download the FEMNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
        "        import shutil\n",
        "\n",
        "        if self._check_exists():\n",
        "            return\n",
        "\n",
        "        mkdirs(self.raw_folder)\n",
        "        mkdirs(self.processed_folder)\n",
        "\n",
        "        # download files\n",
        "        for url, md5 in self.resources:\n",
        "            filename = url.rpartition('/')[2]\n",
        "            download_and_extract_archive(url, download_root=self.raw_folder, filename=filename, md5=md5)\n",
        "\n",
        "        # process and save as torch files\n",
        "        print('Processing...')\n",
        "        shutil.move(os.path.join(self.raw_folder, self.training_file), self.processed_folder)\n",
        "        shutil.move(os.path.join(self.raw_folder, self.test_file), self.processed_folder)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _check_exists(self) -> bool:\n",
        "        return all(\n",
        "            check_integrity(os.path.join(self.raw_folder, os.path.splitext(os.path.basename(url))[0]+os.path.splitext(os.path.basename(url))[1]))\n",
        "            for url, _ in self.resources\n",
        "        )\n",
        "\n",
        "\n",
        "class Generated(MNIST):\n",
        "\n",
        "    def __init__(self, root, dataidxs=None, train=True, transform=None, target_transform=None,\n",
        "                 download=False):\n",
        "        super(MNIST, self).__init__(root, transform=transform,\n",
        "                                    target_transform=target_transform)\n",
        "        self.train = train\n",
        "        self.dataidxs = dataidxs\n",
        "\n",
        "        if self.train:\n",
        "            self.data = np.load(\"data/generated/X_train.npy\")\n",
        "            self.targets = np.load(\"data/generated/y_train.npy\")\n",
        "        else:\n",
        "            self.data = np.load(\"data/generated/X_test.npy\")\n",
        "            self.targets = np.load(\"data/generated/y_test.npy\")\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            self.data = self.data[self.dataidxs]\n",
        "            self.targets = self.targets[self.dataidxs]\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data, target = self.data[index], self.targets[index]\n",
        "        return data, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "\n",
        "class genData(MNIST):\n",
        "    def __init__(self, data, targets):\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "    def __getitem__(self,index):\n",
        "        data, target = self.data[index], self.targets[index]\n",
        "        return data, target\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "class CIFAR100_truncated(data.Dataset):\n",
        "\n",
        "    def __init__(self, root, dataidxs=None, train=True, transform=None, target_transform=None, download=False):\n",
        "\n",
        "        self.root = root\n",
        "        self.dataidxs = dataidxs\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.download = download\n",
        "\n",
        "        self.data, self.target = self.__build_truncated_dataset__()\n",
        "\n",
        "    def __build_truncated_dataset__(self):\n",
        "\n",
        "        cifar_dataobj = CIFAR100(self.root, self.train, self.transform, self.target_transform, self.download)\n",
        "\n",
        "        if torchvision.__version__ == '0.2.1':\n",
        "            if self.train:\n",
        "                data, target = cifar_dataobj.train_data, np.array(cifar_dataobj.train_labels)\n",
        "            else:\n",
        "                data, target = cifar_dataobj.test_data, np.array(cifar_dataobj.test_labels)\n",
        "        else:\n",
        "            data = cifar_dataobj.data\n",
        "            target = np.array(cifar_dataobj.targets)\n",
        "\n",
        "        if self.dataidxs is not None:\n",
        "            data = data[self.dataidxs]\n",
        "            target = target[self.dataidxs]\n",
        "\n",
        "        return data, target\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], self.target[index]\n",
        "        img = Image.fromarray(img)\n",
        "        # print(\"cifar10 img:\", img)\n",
        "        # print(\"cifar10 target:\", target)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ImageFolder_custom(DatasetFolder):\n",
        "    def __init__(self, root, dataidxs=None, train=True, transform=None, target_transform=None, download=None):\n",
        "        self.root = root\n",
        "        self.dataidxs = dataidxs\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        imagefolder_obj = ImageFolder(self.root, self.transform, self.target_transform)\n",
        "        self.loader = imagefolder_obj.loader\n",
        "        if self.dataidxs is not None:\n",
        "            self.samples = np.array(imagefolder_obj.samples)[self.dataidxs]\n",
        "        else:\n",
        "            self.samples = np.array(imagefolder_obj.samples)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.samples[index][0]\n",
        "        target = self.samples[index][1]\n",
        "        target = int(target)\n",
        "        sample = self.loader(path)\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return sample, target\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.dataidxs is None:\n",
        "            return len(self.samples)\n",
        "        else:\n",
        "            return len(self.dataidxs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKR2--GFpi_U"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import DataLoader\n",
        "import copy\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.optim as optim\n",
        "import torchvision.utils as vutils\n",
        "import time\n",
        "import random\n",
        "\n",
        "import sklearn.datasets as sk\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "\n",
        "logging.basicConfig()\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "def mkdirs(dirpath):\n",
        "    try:\n",
        "        os.makedirs(dirpath)\n",
        "    except Exception as _:\n",
        "        pass\n",
        "\n",
        "def load_mnist_data(datadir):\n",
        "\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    mnist_train_ds = MNIST_truncated(datadir, train=True, download=True, transform=transform)\n",
        "    mnist_test_ds = MNIST_truncated(datadir, train=False, download=True, transform=transform)\n",
        "\n",
        "    X_train, y_train = mnist_train_ds.data, mnist_train_ds.target\n",
        "    X_test, y_test = mnist_test_ds.data, mnist_test_ds.target\n",
        "\n",
        "    X_train = X_train.data.numpy()\n",
        "    y_train = y_train.data.numpy()\n",
        "    X_test = X_test.data.numpy()\n",
        "    y_test = y_test.data.numpy()\n",
        "\n",
        "    return (X_train, y_train, X_test, y_test)\n",
        "\n",
        "def load_fmnist_data(datadir):\n",
        "\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    mnist_train_ds = FashionMNIST_truncated(datadir, train=True, download=True, transform=transform)\n",
        "    mnist_test_ds = FashionMNIST_truncated(datadir, train=False, download=True, transform=transform)\n",
        "\n",
        "    X_train, y_train = mnist_train_ds.data, mnist_train_ds.target\n",
        "    X_test, y_test = mnist_test_ds.data, mnist_test_ds.target\n",
        "\n",
        "    X_train = X_train.data.numpy()\n",
        "    y_train = y_train.data.numpy()\n",
        "    X_test = X_test.data.numpy()\n",
        "    y_test = y_test.data.numpy()\n",
        "\n",
        "    return (X_train, y_train, X_test, y_test)\n",
        "\n",
        "def load_svhn_data(datadir):\n",
        "\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    svhn_train_ds = SVHN_custom(datadir, train=True, download=True, transform=transform)\n",
        "    svhn_test_ds = SVHN_custom(datadir, train=False, download=True, transform=transform)\n",
        "\n",
        "    X_train, y_train = svhn_train_ds.data, svhn_train_ds.target\n",
        "    X_test, y_test = svhn_test_ds.data, svhn_test_ds.target\n",
        "\n",
        "    # X_train = X_train.data.numpy()\n",
        "    # y_train = y_train.data.numpy()\n",
        "    # X_test = X_test.data.numpy()\n",
        "    # y_test = y_test.data.numpy()\n",
        "\n",
        "    return (X_train, y_train, X_test, y_test)\n",
        "\n",
        "\n",
        "def load_cifar10_data(datadir):\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "    cifar10_train_ds = CIFAR10_truncated(datadir, train=True, download=True, transform=transform)\n",
        "    cifar10_test_ds = CIFAR10_truncated(datadir, train=False, download=True, transform=transform)\n",
        "\n",
        "    X_train, y_train = cifar10_train_ds.data, cifar10_train_ds.target\n",
        "    X_test, y_test = cifar10_test_ds.data, cifar10_test_ds.target\n",
        "\n",
        "    # y_train = y_train.numpy()\n",
        "    # y_test = y_test.numpy()\n",
        "\n",
        "    return (X_train, y_train, X_test, y_test)\n",
        "\n",
        "def load_celeba_data(datadir):\n",
        "\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    celeba_train_ds = CelebA_custom(datadir, split='train', target_type=\"attr\", download=True, transform=transform)\n",
        "    celeba_test_ds = CelebA_custom(datadir, split='test', target_type=\"attr\", download=True, transform=transform)\n",
        "\n",
        "    gender_index = celeba_train_ds.attr_names.index('Male')\n",
        "    y_train =  celeba_train_ds.attr[:,gender_index:gender_index+1].reshape(-1)\n",
        "    y_test = celeba_test_ds.attr[:,gender_index:gender_index+1].reshape(-1)\n",
        "\n",
        "    # y_train = y_train.numpy()\n",
        "    # y_test = y_test.numpy()\n",
        "\n",
        "    return (None, y_train, None, y_test)\n",
        "\n",
        "def load_femnist_data(datadir):\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    mnist_train_ds = FEMNIST(datadir, train=True, transform=transform, download=True)\n",
        "    mnist_test_ds = FEMNIST(datadir, train=False, transform=transform, download=True)\n",
        "\n",
        "    X_train, y_train, u_train = mnist_train_ds.data, mnist_train_ds.targets, mnist_train_ds.users_index\n",
        "    X_test, y_test, u_test = mnist_test_ds.data, mnist_test_ds.targets, mnist_test_ds.users_index\n",
        "\n",
        "    X_train = X_train.data.numpy()\n",
        "    y_train = y_train.data.numpy()\n",
        "    u_train = np.array(u_train)\n",
        "    X_test = X_test.data.numpy()\n",
        "    y_test = y_test.data.numpy()\n",
        "    u_test = np.array(u_test)\n",
        "\n",
        "    return (X_train, y_train, u_train, X_test, y_test, u_test)\n",
        "\n",
        "def load_cifar100_data(datadir):\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    cifar100_train_ds = CIFAR100_truncated(datadir, train=True, download=True, transform=transform)\n",
        "    cifar100_test_ds = CIFAR100_truncated(datadir, train=False, download=True, transform=transform)\n",
        "\n",
        "    X_train, y_train = cifar100_train_ds.data, cifar100_train_ds.target\n",
        "    X_test, y_test = cifar100_test_ds.data, cifar100_test_ds.target\n",
        "\n",
        "    # y_train = y_train.numpy()\n",
        "    # y_test = y_test.numpy()\n",
        "\n",
        "    return (X_train, y_train, X_test, y_test)\n",
        "\n",
        "\n",
        "def load_tinyimagenet_data(datadir):\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    xray_train_ds = ImageFolder_custom(datadir+'./train/', transform=transform)\n",
        "    xray_test_ds = ImageFolder_custom(datadir+'./val/', transform=transform)\n",
        "\n",
        "    X_train, y_train = np.array([s[0] for s in xray_train_ds.samples]), np.array([int(s[1]) for s in xray_train_ds.samples])\n",
        "    X_test, y_test = np.array([s[0] for s in xray_test_ds.samples]), np.array([int(s[1]) for s in xray_test_ds.samples])\n",
        "\n",
        "    return (X_train, y_train, X_test, y_test)\n",
        "\n",
        "def record_net_data_stats(y_train, net_dataidx_map, logdir):\n",
        "\n",
        "    net_cls_counts = {}\n",
        "\n",
        "    for net_i, dataidx in net_dataidx_map.items():\n",
        "        unq, unq_cnt = np.unique(y_train[dataidx], return_counts=True)\n",
        "        tmp = {unq[i]: unq_cnt[i] for i in range(len(unq))}\n",
        "        net_cls_counts[net_i] = tmp\n",
        "\n",
        "    logger.info('Data statistics: %s' % str(net_cls_counts))\n",
        "\n",
        "    return net_cls_counts\n",
        "\n",
        "def partition_data(dataset, datadir, logdir, partition, n_parties, beta=0.4):\n",
        "    #np.random.seed(2020)\n",
        "    #torch.manual_seed(2020)\n",
        "\n",
        "    if dataset == 'mnist':\n",
        "        X_train, y_train, X_test, y_test = load_mnist_data(datadir)\n",
        "    elif dataset == 'fmnist':\n",
        "        X_train, y_train, X_test, y_test = load_fmnist_data(datadir)\n",
        "    elif dataset == 'cifar10':\n",
        "        X_train, y_train, X_test, y_test = load_cifar10_data(datadir)\n",
        "    elif dataset == 'svhn':\n",
        "        X_train, y_train, X_test, y_test = load_svhn_data(datadir)\n",
        "    elif dataset == 'celeba':\n",
        "        X_train, y_train, X_test, y_test = load_celeba_data(datadir)\n",
        "    elif dataset == 'femnist':\n",
        "        X_train, y_train, u_train, X_test, y_test, u_test = load_femnist_data(datadir)\n",
        "    elif dataset == 'cifar100':\n",
        "        X_train, y_train, X_test, y_test = load_cifar100_data(datadir)\n",
        "    elif dataset == 'tinyimagenet':\n",
        "        X_train, y_train, X_test, y_test = load_tinyimagenet_data(datadir)\n",
        "    elif dataset == 'generated':\n",
        "        X_train, y_train = [], []\n",
        "        for loc in range(4):\n",
        "            for i in range(1000):\n",
        "                p1 = random.random()\n",
        "                p2 = random.random()\n",
        "                p3 = random.random()\n",
        "                if loc > 1:\n",
        "                    p2 = -p2\n",
        "                if loc % 2 ==1:\n",
        "                    p3 = -p3\n",
        "                if i % 2 == 0:\n",
        "                    X_train.append([p1, p2, p3])\n",
        "                    y_train.append(0)\n",
        "                else:\n",
        "                    X_train.append([-p1, -p2, -p3])\n",
        "                    y_train.append(1)\n",
        "        X_test, y_test = [], []\n",
        "        for i in range(1000):\n",
        "            p1 = random.random() * 2 - 1\n",
        "            p2 = random.random() * 2 - 1\n",
        "            p3 = random.random() * 2 - 1\n",
        "            X_test.append([p1, p2, p3])\n",
        "            if p1>0:\n",
        "                y_test.append(0)\n",
        "            else:\n",
        "                y_test.append(1)\n",
        "        X_train = np.array(X_train, dtype=np.float32)\n",
        "        X_test = np.array(X_test, dtype=np.float32)\n",
        "        y_train = np.array(y_train, dtype=np.int32)\n",
        "        y_test = np.array(y_test, dtype=np.int64)\n",
        "        idxs = np.linspace(0,3999,4000,dtype=np.int64)\n",
        "        batch_idxs = np.array_split(idxs, n_parties)\n",
        "        net_dataidx_map = {i: batch_idxs[i] for i in range(n_parties)}\n",
        "        mkdirs(\"data/generated/\")\n",
        "        np.save(\"data/generated/X_train.npy\",X_train)\n",
        "        np.save(\"data/generated/X_test.npy\",X_test)\n",
        "        np.save(\"data/generated/y_train.npy\",y_train)\n",
        "        np.save(\"data/generated/y_test.npy\",y_test)\n",
        "\n",
        "    #elif dataset == 'covtype':\n",
        "    #    cov_type = sk.fetch_covtype('./data')\n",
        "    #    num_train = int(581012 * 0.75)\n",
        "    #    idxs = np.random.permutation(581012)\n",
        "    #    X_train = np.array(cov_type['data'][idxs[:num_train]], dtype=np.float32)\n",
        "    #    y_train = np.array(cov_type['target'][idxs[:num_train]], dtype=np.int32) - 1\n",
        "    #    X_test = np.array(cov_type['data'][idxs[num_train:]], dtype=np.float32)\n",
        "    #    y_test = np.array(cov_type['target'][idxs[num_train:]], dtype=np.int32) - 1\n",
        "    #    mkdirs(\"data/generated/\")\n",
        "    #    np.save(\"data/generated/X_train.npy\",X_train)\n",
        "    #    np.save(\"data/generated/X_test.npy\",X_test)\n",
        "    #    np.save(\"data/generated/y_train.npy\",y_train)\n",
        "    #    np.save(\"data/generated/y_test.npy\",y_test)\n",
        "\n",
        "    elif dataset in ('rcv1', 'SUSY', 'covtype'):\n",
        "        X_train, y_train = load_svmlight_file(datadir+dataset)\n",
        "        X_train = X_train.todense()\n",
        "        num_train = int(X_train.shape[0] * 0.75)\n",
        "        if dataset == 'covtype':\n",
        "            y_train = y_train-1\n",
        "        else:\n",
        "            y_train = (y_train+1)/2\n",
        "        idxs = np.random.permutation(X_train.shape[0])\n",
        "\n",
        "        X_test = np.array(X_train[idxs[num_train:]], dtype=np.float32)\n",
        "        y_test = np.array(y_train[idxs[num_train:]], dtype=np.int32)\n",
        "        X_train = np.array(X_train[idxs[:num_train]], dtype=np.float32)\n",
        "        y_train = np.array(y_train[idxs[:num_train]], dtype=np.int32)\n",
        "\n",
        "        mkdirs(\"data/generated/\")\n",
        "        np.save(\"data/generated/X_train.npy\",X_train)\n",
        "        np.save(\"data/generated/X_test.npy\",X_test)\n",
        "        np.save(\"data/generated/y_train.npy\",y_train)\n",
        "        np.save(\"data/generated/y_test.npy\",y_test)\n",
        "\n",
        "    elif dataset in ('a9a'):\n",
        "        X_train, y_train = load_svmlight_file(datadir+\"a9a\")\n",
        "        X_test, y_test = load_svmlight_file(datadir+\"a9a.t\")\n",
        "        X_train = X_train.todense()\n",
        "        X_test = X_test.todense()\n",
        "        X_test = np.c_[X_test, np.zeros((len(y_test), X_train.shape[1] - np.size(X_test[0, :])))]\n",
        "\n",
        "        X_train = np.array(X_train, dtype=np.float32)\n",
        "        X_test = np.array(X_test, dtype=np.float32)\n",
        "        y_train = (y_train+1)/2\n",
        "        y_test = (y_test+1)/2\n",
        "        y_train = np.array(y_train, dtype=np.int32)\n",
        "        y_test = np.array(y_test, dtype=np.int32)\n",
        "\n",
        "        mkdirs(\"data/generated/\")\n",
        "        np.save(\"data/generated/X_train.npy\",X_train)\n",
        "        np.save(\"data/generated/X_test.npy\",X_test)\n",
        "        np.save(\"data/generated/y_train.npy\",y_train)\n",
        "        np.save(\"data/generated/y_test.npy\",y_test)\n",
        "\n",
        "\n",
        "    n_train = y_train.shape[0]\n",
        "\n",
        "    if partition == \"homo\":\n",
        "        idxs = np.random.permutation(n_train)\n",
        "        batch_idxs = np.array_split(idxs, n_parties)\n",
        "        net_dataidx_map = {i: batch_idxs[i] for i in range(n_parties)}\n",
        "\n",
        "\n",
        "    elif partition == \"noniid-labeldir\":\n",
        "        print(\"here nowwww\")\n",
        "        min_size = 0\n",
        "        min_require_size = 10\n",
        "        K = 10\n",
        "        if dataset in ('celeba', 'covtype', 'a9a', 'rcv1', 'SUSY'):\n",
        "            K = 2\n",
        "            # min_require_size = 100\n",
        "        if dataset == 'cifar100':\n",
        "            K = 100\n",
        "        elif dataset == 'tinyimagenet':\n",
        "            K = 200\n",
        "\n",
        "        N = y_train.shape[0]\n",
        "        #np.random.seed(2020)\n",
        "        net_dataidx_map = {}\n",
        "\n",
        "        while min_size < min_require_size:\n",
        "            idx_batch = [[] for _ in range(n_parties)]\n",
        "            for k in range(K):\n",
        "                idx_k = np.where(y_train == k)[0]\n",
        "                np.random.shuffle(idx_k)\n",
        "                proportions = np.random.dirichlet(np.repeat(beta, n_parties))\n",
        "                # logger.info(\"proportions1: \", proportions)\n",
        "                # logger.info(\"sum pro1:\", np.sum(proportions))\n",
        "                ## Balance\n",
        "                proportions = np.array([p * (len(idx_j) < N / n_parties) for p, idx_j in zip(proportions, idx_batch)])\n",
        "                # logger.info(\"proportions2: \", proportions)\n",
        "                proportions = proportions / proportions.sum()\n",
        "                # logger.info(\"proportions3: \", proportions)\n",
        "                proportions = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]\n",
        "                # logger.info(\"proportions4: \", proportions)\n",
        "                idx_batch = [idx_j + idx.tolist() for idx_j, idx in zip(idx_batch, np.split(idx_k, proportions))]\n",
        "                min_size = min([len(idx_j) for idx_j in idx_batch])\n",
        "                # if K == 2 and n_parties <= 10:\n",
        "                #     if np.min(proportions) < 200:\n",
        "                #         min_size = 0\n",
        "                #         break\n",
        "\n",
        "\n",
        "        for j in range(n_parties):\n",
        "            np.random.shuffle(idx_batch[j])\n",
        "            net_dataidx_map[j] = idx_batch[j]\n",
        "        print(\"map\",net_dataidx_map)\n",
        "\n",
        "    elif partition > \"noniid-#label0\" and partition <= \"noniid-#label9\":\n",
        "        num = eval(partition[13:])\n",
        "        if dataset in ('celeba', 'covtype', 'a9a', 'rcv1', 'SUSY'):\n",
        "            num = 1\n",
        "            K = 2\n",
        "        else:\n",
        "            K = 10\n",
        "        if dataset == \"cifar100\":\n",
        "            K = 100\n",
        "        elif dataset == \"tinyimagenet\":\n",
        "            K = 200\n",
        "        if num == 10:\n",
        "            net_dataidx_map ={i:np.ndarray(0,dtype=np.int64) for i in range(n_parties)}\n",
        "            for i in range(10):\n",
        "                idx_k = np.where(y_train==i)[0]\n",
        "                np.random.shuffle(idx_k)\n",
        "                split = np.array_split(idx_k,n_parties)\n",
        "                for j in range(n_parties):\n",
        "                    net_dataidx_map[j]=np.append(net_dataidx_map[j],split[j])\n",
        "        else:\n",
        "            times=[0 for i in range(K)]\n",
        "            contain=[]\n",
        "            for i in range(n_parties):\n",
        "                current=[i%K]\n",
        "                times[i%K]+=1\n",
        "                j=1\n",
        "                while (j<num):\n",
        "                    ind=random.randint(0,K-1)\n",
        "                    if (ind not in current):\n",
        "                        j=j+1\n",
        "                        current.append(ind)\n",
        "                        times[ind]+=1\n",
        "                contain.append(current)\n",
        "            net_dataidx_map ={i:np.ndarray(0,dtype=np.int64) for i in range(n_parties)}\n",
        "            test_dataidx_map ={i:np.ndarray(0,dtype=np.int64) for i in range(n_parties)}\n",
        "            for i in range(K):\n",
        "                idx_k = np.where(y_train==i)[0]\n",
        "                idx_t = np.where(y_test==i)[0]\n",
        "                np.random.shuffle(idx_k)\n",
        "                np.random.shuffle(idx_t)\n",
        "                split = np.array_split(idx_k,times[i])\n",
        "                splitt = np.array_split(idx_t,times[i])\n",
        "                ids=0\n",
        "                for j in range(n_parties):\n",
        "                    if i in contain[j]:\n",
        "                        net_dataidx_map[j]=np.append(net_dataidx_map[j],split[ids])\n",
        "                        test_dataidx_map[j]=np.append(test_dataidx_map[j],splitt[ids])\n",
        "                        ids+=1\n",
        "\n",
        "    elif partition == \"iid-diff-quantity\":\n",
        "        idxs = np.random.permutation(n_train)\n",
        "        min_size = 0\n",
        "        while min_size < 10:\n",
        "            proportions = np.random.dirichlet(np.repeat(beta, n_parties))\n",
        "            proportions = proportions/proportions.sum()\n",
        "            min_size = np.min(proportions*len(idxs))\n",
        "        proportions = (np.cumsum(proportions)*len(idxs)).astype(int)[:-1]\n",
        "        batch_idxs = np.split(idxs,proportions)\n",
        "        net_dataidx_map = {i: batch_idxs[i] for i in range(n_parties)}\n",
        "\n",
        "    elif partition == \"mixed\":\n",
        "        min_size = 0\n",
        "        min_require_size = 10\n",
        "        K = 10\n",
        "        if dataset in ('celeba', 'covtype', 'a9a', 'rcv1', 'SUSY'):\n",
        "            K = 2\n",
        "            # min_require_size = 100\n",
        "\n",
        "        N = y_train.shape[0]\n",
        "        net_dataidx_map = {}\n",
        "\n",
        "        times=[1 for i in range(10)]\n",
        "        contain=[]\n",
        "        for i in range(n_parties):\n",
        "            current=[i%K]\n",
        "            j=1\n",
        "            while (j<2):\n",
        "                ind=random.randint(0,K-1)\n",
        "                if (ind not in current and times[ind]<2):\n",
        "                    j=j+1\n",
        "                    current.append(ind)\n",
        "                    times[ind]+=1\n",
        "            contain.append(current)\n",
        "        net_dataidx_map ={i:np.ndarray(0,dtype=np.int64) for i in range(n_parties)}\n",
        "\n",
        "\n",
        "        min_size = 0\n",
        "        while min_size < 10:\n",
        "            proportions = np.random.dirichlet(np.repeat(beta, n_parties))\n",
        "            proportions = proportions/proportions.sum()\n",
        "            min_size = np.min(proportions*n_train)\n",
        "\n",
        "        for i in range(K):\n",
        "            idx_k = np.where(y_train==i)[0]\n",
        "            np.random.shuffle(idx_k)\n",
        "\n",
        "            proportions_k = np.random.dirichlet(np.repeat(beta, 2))\n",
        "            #proportions_k = np.ndarray(0,dtype=np.float64)\n",
        "            #for j in range(n_parties):\n",
        "            #    if i in contain[j]:\n",
        "            #        proportions_k=np.append(proportions_k ,proportions[j])\n",
        "\n",
        "            proportions_k = (np.cumsum(proportions_k)*len(idx_k)).astype(int)[:-1]\n",
        "\n",
        "            split = np.split(idx_k, proportions_k)\n",
        "            ids=0\n",
        "            for j in range(n_parties):\n",
        "                if i in contain[j]:\n",
        "                    net_dataidx_map[j]=np.append(net_dataidx_map[j],split[ids])\n",
        "                    ids+=1\n",
        "\n",
        "    elif partition == \"real\" and dataset == \"femnist\":\n",
        "        num_user = u_train.shape[0]\n",
        "        user = np.zeros(num_user+1,dtype=np.int32)\n",
        "        for i in range(1,num_user+1):\n",
        "            user[i] = user[i-1] + u_train[i-1]\n",
        "        no = np.random.permutation(num_user)\n",
        "        batch_idxs = np.array_split(no, n_parties)\n",
        "        net_dataidx_map = {i:np.zeros(0,dtype=np.int32) for i in range(n_parties)}\n",
        "        for i in range(n_parties):\n",
        "            for j in batch_idxs[i]:\n",
        "                net_dataidx_map[i]=np.append(net_dataidx_map[i], np.arange(user[j], user[j+1]))\n",
        "\n",
        "    elif partition == \"transfer-from-femnist\":\n",
        "        stat = np.load(\"femnist-dis.npy\")\n",
        "        n_total = stat.shape[0]\n",
        "        chosen = np.random.permutation(n_total)[:n_parties]\n",
        "        stat = stat[chosen,:]\n",
        "\n",
        "        if dataset in ('celeba', 'covtype', 'a9a', 'rcv1', 'SUSY'):\n",
        "            K = 2\n",
        "        else:\n",
        "            K = 10\n",
        "\n",
        "        N = y_train.shape[0]\n",
        "        #np.random.seed(2020)\n",
        "        net_dataidx_map = {}\n",
        "\n",
        "        idx_batch = [[] for _ in range(n_parties)]\n",
        "        for k in range(K):\n",
        "            idx_k = np.where(y_train == k)[0]\n",
        "            np.random.shuffle(idx_k)\n",
        "            proportions = stat[:,k]\n",
        "            # logger.info(\"proportions2: \", proportions)\n",
        "            proportions = proportions / proportions.sum()\n",
        "            # logger.info(\"proportions3: \", proportions)\n",
        "            proportions = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]\n",
        "            # logger.info(\"proportions4: \", proportions)\n",
        "            idx_batch = [idx_j + idx.tolist() for idx_j, idx in zip(idx_batch, np.split(idx_k, proportions))]\n",
        "\n",
        "\n",
        "        for j in range(n_parties):\n",
        "            np.random.shuffle(idx_batch[j])\n",
        "            net_dataidx_map[j] = idx_batch[j]\n",
        "\n",
        "    elif partition == \"transfer-from-criteo\":\n",
        "        stat0 = np.load(\"criteo-dis.npy\")\n",
        "\n",
        "        n_total = stat0.shape[0]\n",
        "        flag=True\n",
        "        while (flag):\n",
        "            chosen = np.random.permutation(n_total)[:n_parties]\n",
        "            stat = stat0[chosen,:]\n",
        "            check = [0 for i in range(10)]\n",
        "            for ele in stat:\n",
        "                for j in range(10):\n",
        "                    if ele[j]>0:\n",
        "                        check[j]=1\n",
        "            flag=False\n",
        "            for i in range(10):\n",
        "                if check[i]==0:\n",
        "                    flag=True\n",
        "                    break\n",
        "\n",
        "\n",
        "        if dataset in ('celeba', 'covtype', 'a9a', 'rcv1', 'SUSY'):\n",
        "            K = 2\n",
        "            stat[:,0]=np.sum(stat[:,:5],axis=1)\n",
        "            stat[:,1]=np.sum(stat[:,5:],axis=1)\n",
        "        else:\n",
        "            K = 10\n",
        "\n",
        "        N = y_train.shape[0]\n",
        "        #np.random.seed(2020)\n",
        "        net_dataidx_map = {}\n",
        "\n",
        "        idx_batch = [[] for _ in range(n_parties)]\n",
        "        for k in range(K):\n",
        "            idx_k = np.where(y_train == k)[0]\n",
        "            np.random.shuffle(idx_k)\n",
        "            proportions = stat[:,k]\n",
        "            # logger.info(\"proportions2: \", proportions)\n",
        "            proportions = proportions / proportions.sum()\n",
        "            # logger.info(\"proportions3: \", proportions)\n",
        "            proportions = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]\n",
        "            # logger.info(\"proportions4: \", proportions)\n",
        "            idx_batch = [idx_j + idx.tolist() for idx_j, idx in zip(idx_batch, np.split(idx_k, proportions))]\n",
        "\n",
        "\n",
        "        for j in range(n_parties):\n",
        "            np.random.shuffle(idx_batch[j])\n",
        "            net_dataidx_map[j] = idx_batch[j]\n",
        "\n",
        "    traindata_cls_counts = record_net_data_stats(y_train, net_dataidx_map, logdir)\n",
        "    return (X_train, y_train, X_test, y_test, net_dataidx_map, test_dataidx_map, traindata_cls_counts)\n",
        "\n",
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=1., net_id=None, total=0):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "        self.net_id = net_id\n",
        "        self.num = int(sqrt(total))\n",
        "        if self.num * self.num < total:\n",
        "            self.num = self.num + 1\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        if self.net_id is None:\n",
        "            return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "        else:\n",
        "            tmp = torch.randn(tensor.size())\n",
        "            filt = torch.zeros(tensor.size())\n",
        "            size = int(28 / self.num)\n",
        "            row = int(self.net_id / size)\n",
        "            col = self.net_id % size\n",
        "            for i in range(size):\n",
        "                for j in range(size):\n",
        "                    filt[:,row*size+i,col*size+j] = 1\n",
        "            tmp = tmp * filt\n",
        "            return tensor + tmp * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
        "\n",
        "def get_dataloader(dataset, datadir, train_bs, test_bs, dataidxs=None, testidxs=None, noise_level=0, net_id=None, total=0):\n",
        "    if dataset in ('mnist', 'femnist', 'fmnist', 'cifar10', 'svhn', 'generated', 'covtype', 'a9a', 'rcv1', 'SUSY', 'cifar100', 'tinyimagenet'):\n",
        "        if dataset == 'mnist':\n",
        "            dl_obj = MNIST_truncated\n",
        "\n",
        "            transform_train = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
        "\n",
        "            transform_test = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
        "\n",
        "        elif dataset == 'femnist':\n",
        "            dl_obj = FEMNIST\n",
        "            transform_train = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
        "            transform_test = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
        "\n",
        "        elif dataset == 'fmnist':\n",
        "            dl_obj = FashionMNIST_truncated\n",
        "            transform_train = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
        "            transform_test = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
        "\n",
        "        elif dataset == 'svhn':\n",
        "            dl_obj = SVHN_custom\n",
        "            transform_train = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
        "            transform_test = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
        "\n",
        "\n",
        "        elif dataset == 'cifar10':\n",
        "            print(\"in cifar10\")\n",
        "            dl_obj = CIFAR10_truncated\n",
        "\n",
        "            transform_train = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Lambda(lambda x: F.pad(\n",
        "                    Variable(x.unsqueeze(0), requires_grad=False),\n",
        "                    (4, 4, 4, 4), mode='reflect').data.squeeze()),\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.RandomCrop(32),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                AddGaussianNoise(0., noise_level, net_id, total)\n",
        "            ])\n",
        "            # data prep for test set\n",
        "            transform_test = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                AddGaussianNoise(0., noise_level, net_id, total)])\n",
        "\n",
        "        elif dataset == 'cifar100':\n",
        "            print(\"in 100\")\n",
        "            dl_obj = CIFAR100_truncated\n",
        "\n",
        "            normalize = transforms.Normalize(mean=[0.5070751592371323, 0.48654887331495095, 0.4409178433670343],\n",
        "                                             std=[0.2673342858792401, 0.2564384629170883, 0.27615047132568404])\n",
        "            # transform_train = transforms.Compose([\n",
        "            #     transforms.RandomCrop(32),\n",
        "            #     transforms.RandomHorizontalFlip(),\n",
        "            #     transforms.ToTensor(),\n",
        "            #     normalize\n",
        "            # ])\n",
        "            transform_train = transforms.Compose([\n",
        "                # transforms.ToPILImage(),\n",
        "                transforms.RandomCrop(32, padding=4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomRotation(15),\n",
        "                transforms.ToTensor(),\n",
        "                normalize\n",
        "            ])\n",
        "            # data prep for test set\n",
        "            transform_test = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                normalize])\n",
        "        elif dataset == 'tinyimagenet':\n",
        "            dl_obj = ImageFolder_custom\n",
        "            transform_train = transforms.Compose([\n",
        "                transforms.Resize(32),\n",
        "                transforms.RandomCrop(32, padding=4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomRotation(15),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "            ])\n",
        "            transform_test = transforms.Compose([\n",
        "                transforms.Resize(32),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "            ])\n",
        "\n",
        "        else:\n",
        "            dl_obj = Generated\n",
        "            transform_train = None\n",
        "            transform_test = None\n",
        "\n",
        "\n",
        "        if dataset == \"tinyimagenet\":\n",
        "            train_ds = dl_obj(datadir+'./train/', dataidxs=dataidxs, transform=transform_train)\n",
        "            test_ds = dl_obj(datadir+'./val/', transform=transform_test)\n",
        "        else:\n",
        "            print(\"dir\", datadir)\n",
        "            train_ds = dl_obj(datadir, dataidxs=dataidxs, train=True, transform=transform_train, download=True)\n",
        "            test_ds = dl_obj(datadir, dataidxs=testidxs, train=False, transform=transform_test, download=True)\n",
        "\n",
        "        train_dl = data.DataLoader(dataset=train_ds, batch_size=train_bs, shuffle=True, drop_last=False)\n",
        "        test_dl = data.DataLoader(dataset=test_ds, batch_size=test_bs, shuffle=False, drop_last=False)\n",
        "        print(train_ds, \"train ds\")\n",
        "\n",
        "    return train_dl, test_dl, train_ds, test_ds\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_clN6TKC_yK4"
      },
      "outputs": [],
      "source": [
        "def get_loaders(num_clients):\n",
        "\n",
        "  X_train, y_train, X_test, y_test, net_dataidx_map, test_dataidx_map, traindata_cls_counts = partition_data(dataset='fmnist', datadir='./data/', logdir='./logs/', partition='noniid-#label2', n_parties=10, beta=0.5)\n",
        "  print(\"shapes\", X_train.shape, y_train.shape)\n",
        "  trainloaders = []\n",
        "  testloaders = []\n",
        "  for client_id in range(num_clients):\n",
        "\n",
        "    dataidxs = net_dataidx_map[client_id]\n",
        "    testidxs = test_dataidx_map[client_id]\n",
        "\n",
        "    train_dl_local, test_dl_local, train_ds_local, test_ds_local = get_dataloader(dataset='fmnist', datadir='./data/', train_bs=64, test_bs=64, dataidxs=dataidxs, testidxs=testidxs)\n",
        "    trainloaders.append(train_dl_local)\n",
        "    testloaders.append(test_dl_local)\n",
        "\n",
        "  return trainloaders, testloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "NOVdqhCnXRps",
        "outputId": "38b3f46a-ac8e-4d5c-c5d1-a0f9e784a4d8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ngradients = np.random.randn(1000)\\nprint(\"grads\", len(gradients))\\n\\nvisualize_gradients_and_stats(gradients)\\n'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "\n",
        "def plot_gradient_spectrum(gradients):\n",
        "\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(range(len(gradients)), gradients)\n",
        "  plt.xlabel(\"Index\")\n",
        "  plt.ylabel(\"Magnitude\")\n",
        "  plt.title(\"Gradients\")\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "\n",
        "gradients = np.random.randn(1000)\n",
        "plot_gradient_spectrum(gradients)\n",
        "\n",
        "def visualize_gradients_and_stats(gradients):\n",
        "  bin_width = 0.0005\n",
        "  bins = np.arange(min(gradients), max(gradients) + bin_width, bin_width)\n",
        "  hist, bin_edges = np.histogram(gradients, bins=bins)\n",
        "\n",
        "\n",
        "  grad_skewness = skew(gradients)\n",
        "  grad_kurtosis = kurtosis(gradients)\n",
        "\n",
        "\n",
        "  plt.figure(figsize=(7,5))\n",
        "  plt.bar(bin_edges[:-1], hist, width=bin_width, edgecolor='black', align='edge')\n",
        "  plt.xlabel(\"Gradient Vlaue\")\n",
        "  plt.ylabel(\"Frequency\")\n",
        "  plt.title(\"Gradient Distribution\\ Skewness: {:.2f}, Kurtosis: {:.2f}\".format(grad_skewness, grad_kurtosis))\n",
        "\n",
        "\n",
        "  plt.show()\n",
        "  return grad_skewness, grad_kurtosis\n",
        "'''\n",
        "gradients = np.random.randn(1000)\n",
        "print(\"grads\", len(gradients))\n",
        "\n",
        "visualize_gradients_and_stats(gradients)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAkkAg78hugh"
      },
      "source": [
        "# **MAIN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh0qFpvLuqB2"
      },
      "source": [
        "# **PLOT ACCURACIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-tkHl4xus0b"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy(accuracies, title: str):\n",
        "  print(accuracies)\n",
        "  fl_rounds = accuracies.keys()\n",
        "  print(\"rounds\", fl_rounds)\n",
        "  accuracy_list = accuracies.values()\n",
        "\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(fl_rounds, accuracy_list)\n",
        "  plt.xlabel(\"FL Rounds\")\n",
        "  plt.ylabel(\"Accuracy Magnitude\")\n",
        "  plt.title(title)\n",
        "  plt.grid(True)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tJu3T-ixHRsC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rvvwOLmqCmmo"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}