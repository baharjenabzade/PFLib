{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94RMdQaUxKVi"
      },
      "source": [
        "### Installing dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBlE2sgnNJlL",
        "outputId": "7d00ab18-a402-4800-f78e-7076bdad7781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.7/364.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[simulation] flwr_datasets[vision] torch torchvision matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5CCFFvyAFGI"
      },
      "source": [
        "# **IMPORTING ESSENTIAL LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbMejWmNxKVm"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose, RandomHorizontalFlip, RandomRotation\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "\n",
        "from datasets.utils.logging import disable_progress_bar\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "from flwr_datasets import FederatedDataset\n",
        "\n",
        "\n",
        "## Run on CPU\n",
        "DEVICE = torch.device(\"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lceN7ByxKVo"
      },
      "source": [
        "\n",
        "# **PREPARING IID DATASET**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527,
          "referenced_widgets": [
            "5412fcfd51b944a58cbffac601ed3b01",
            "553eb205e7c748c791e3ee1095b947ea",
            "d3efea749c7542b8ba5fb078bb67be8a",
            "87be248dbc3d486283a561b0b1d1f3a7",
            "2a6e1d07cb204bbf8ae42ef6427e4026",
            "9d8d602d077c42e29bc15af6095bee73",
            "a5b8cd68b90c46f485f71be1775b17cb",
            "604d2575082546d4950b88dde1b58918",
            "8ad19bb025dd456ebda8dbb8977ad5d3",
            "237d678f3a304f31a5ff016ea0db4d6f",
            "906c0a430a5047f2b750ecdc7844ae76",
            "3121b65f58af47e7a982bfa475a88b6a",
            "53f8b87f16dd4e8494fabfca2737a2cd",
            "9ca09450a12e4c05995ae3724779791c",
            "f061875ce37f4b8a959385d0e1fc8573",
            "b13a129aae0e4e3da404bf0ad28a2010",
            "ade872cb07ea40d1a3c69a5fa9758f57",
            "e78fceb701c1403fb03884e1c314ae29",
            "3ba88b6458e64c96bad2e44feafdd460",
            "970d6a7bf93b40838da3341e89836332",
            "17ac04a9bda143a69a8e9fee794b8d67",
            "e1583090194b4ff29366df2497f46834"
          ]
        },
        "id": "g3qgOWkJxKVq",
        "outputId": "4cf66b53-c598-452e-ca06-c274640c3f4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/5.16k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5412fcfd51b944a58cbffac601ed3b01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/120M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3121b65f58af47e7a982bfa475a88b6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-6b3b3c84bf7b>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtrainloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-6b3b3c84bf7b>\u001b[0m in \u001b[0;36mload_datasets\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mvalloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpartition_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_clients'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpartition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_partition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartition_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mpartition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpartition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr_datasets/federated_dataset.py\u001b[0m in \u001b[0;36mload_partition\u001b[0;34m(self, partition_id, split)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \"\"\"\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_prepared\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset is not loaded yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr_datasets/federated_dataset.py\u001b[0m in \u001b[0;36m_prepare_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mhappen\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresplitting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \"\"\"\n\u001b[0;32m--> 237\u001b[0;31m         self._dataset = datasets.load_dataset(\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2615\u001b[0m     \u001b[0;31m# Download and prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2616\u001b[0;31m     builder_instance.download_and_prepare(\n\u001b[0m\u001b[1;32m   2617\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2618\u001b[0m         \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m   1027\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                             \u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_proc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m                         self._download_and_prepare(\n\u001b[0m\u001b[1;32m   1030\u001b[0m                             \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m                             \u001b[0mverification_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0msplit_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSplitDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0msplit_generators_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_split_generators_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0msplit_generators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msplit_generators_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;31m# Checksums verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/parquet/parquet.py\u001b[0m in \u001b[0;36m_split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"At least one data file must be specified, but got data_files={self.config.data_files}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_on_the_fly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36mdownload_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mextracted_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextracted\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mURL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \"\"\"\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_recorded_sizes_checksums\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mstack_multiprocessing_download_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             downloaded_path_or_paths = map_nested(\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0mdownload_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0murl_or_urls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m         mapped = [\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhf_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0miterable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         mapped = [\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhf_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    397\u001b[0m             }\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    397\u001b[0m             }\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     ):\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmapped_item\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmapped_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;31m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     ):\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmapped_item\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmapped_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;31m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36m_download_batched\u001b[0;34m(self, url_or_filenames, download_config)\u001b[0m\n\u001b[1;32m    311\u001b[0m             )\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             return [\n\u001b[0m\u001b[1;32m    314\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0murl_or_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl_or_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             return [\n\u001b[0;32m--> 314\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0murl_or_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl_or_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36m_download_single\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# append the relative path to the base_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0murl_or_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl_or_path_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracked_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_origin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         output_path = get_from_cache(\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, use_auth_token, ignore_url_params, storage_options, download_desc, disable_tqdm)\u001b[0m\n\u001b[1;32m    674\u001b[0m                 \u001b[0mftp_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mscheme\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"http\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"https\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                 fsspec_get(\n\u001b[0m\u001b[1;32m    677\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/file_utils.py\u001b[0m in \u001b[0;36mfsspec_get\u001b[0;34m(url, temp_file, storage_options, desc, disable_tqdm)\u001b[0m\n\u001b[1;32m    383\u001b[0m         }\n\u001b[1;32m    384\u001b[0m     )\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_file_system.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(self, rpath, lpath, callback, outfile, **kwargs)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             http_get(\n\u001b[0m\u001b[1;32m    639\u001b[0m                 url=hf_hub_url(\n\u001b[1;32m    640\u001b[0m                     \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolve_remote_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                 \u001b[0mtemp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m                 \u001b[0mnew_resume_size\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0;31m# Some data has been downloaded from the server so we reset the number of retries.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "cfg = {'num_rounds': 5, 'num_clients': 10,\n",
        "       'batch_size': 32, 'num_clients_per_round_fit':2,\n",
        "       'num_clients_per_round_eval':2,\n",
        "       'config_fit': {'lr': 0.01, 'momentum': 0.9, 'local_epochs' : 1}}\n",
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "def load_datasets():\n",
        "    fds = FederatedDataset(dataset=\"cifar10\", partitioners={\"train\": cfg.get('num_clients')})\n",
        "\n",
        "\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for partition_id in range(cfg.get('num_clients')):\n",
        "        partition = fds.load_partition(partition_id, \"train\")\n",
        "        partition = partition.with_transform(transform_train)\n",
        "        partition = partition.train_test_split(train_size=0.8, seed=42)\n",
        "        trainloaders.append(DataLoader(partition[\"train\"], batch_size=cfg.get('batch_size')))\n",
        "        valloaders.append(DataLoader(partition[\"test\"], batch_size=cfg.get('batch_size')))\n",
        "    testset = fds.load_split(\"test\").with_transform(transform_test)\n",
        "    testloader = DataLoader(testset, batch_size=cfg.get('batch_size'))\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-U0HUte7FNu"
      },
      "source": [
        "# **PREPARING NON-IID DATASET**\n",
        "***CLASS VERSION***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_xml_assignments(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    node_assignments = {}\n",
        "    for node in root.findall('Node'):\n",
        "        node_id = int(node.get('id'))\n",
        "        shards = [(int(dp.get('classLabel')), int(dp.get('shard'))) for dp in node.findall('DataPair')]\n",
        "        node_assignments[node_id] = shards\n",
        "    return node_assignments\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "TgoJoXjCvD34",
        "outputId": "1d4a82f4-91bd-48cf-9a4b-53b510ba520b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fa6b4fa1-44bd-431d-9fdc-d864e6ce9180\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fa6b4fa1-44bd-431d-9fdc-d864e6ce9180\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving shards.xml to shards.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZAHOnBy7TEY",
        "outputId": "9e5fd37e-f7e3-4615-ed8c-41b797501ecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:15<00:00, 11077311.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "data 50000 10000\n",
            "train\n",
            "test\n",
            "[(1, 3), (2, 11), (3, 18), (2, 5)] ids\n",
            "done\n",
            "[(2, 5), (3, 0), (3, 10), (1, 1)] ids\n",
            "done\n",
            "[(3, 13), (1, 1), (2, 8), (2, 3)] ids\n",
            "done\n",
            "[(2, 10), (1, 12), (3, 16), (1, 9)] ids\n",
            "done\n",
            "[(5, 18), (4, 17), (6, 2), (4, 18)] ids\n",
            "done\n",
            "[(4, 13), (6, 6), (5, 11), (6, 4)] ids\n",
            "done\n",
            "[(6, 17), (5, 4), (4, 7), (5, 11)] ids\n",
            "done\n",
            "[(10, 17), (8, 12), (9, 2), (7, 16)] ids\n",
            "done\n",
            "[(9, 19), (8, 0), (9, 5), (7, 15)] ids\n",
            "done\n",
            "[(8, 9), (9, 14), (10, 7), (7, 13)] ids\n",
            "done\n",
            "final 10 10\n"
          ]
        }
      ],
      "source": [
        "class Dataset:\n",
        "  def __init__(self):\n",
        "    self.num_classes = 10\n",
        "    self.num_shards_per_class = 10\n",
        "    self.transform = Compose([\n",
        "      ToTensor(),\n",
        "      Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "      ])\n",
        "\n",
        "  def load_CIFAR10_dataset(self):\n",
        "    train = CIFAR10(root= './data', train= True, download= True, transform= self.transform)\n",
        "    test = CIFAR10(root= './data', train= False, download= True, transform= self.transform)\n",
        "    return train, test\n",
        "\n",
        "  def divide_class_into_shards(self, dataset, num_classes: int, num_shards_per_class: int):\n",
        "    num_shards = num_classes * num_shards_per_class\n",
        "    num_imgs = int(len(dataset)/ num_shards_per_class / num_classes)\n",
        "    ## Create a list to store indices for each class\n",
        "    class_indices = [[] for _ in range(num_classes)]\n",
        "    labels = np.array(dataset.targets)\n",
        "\n",
        "    # Group the indices of each class\n",
        "    for idx, label in enumerate(labels):\n",
        "      class_indices[label].append(idx)\n",
        "\n",
        "    # Shuffle indices within each class\n",
        "\n",
        "    for i in range(num_classes):\n",
        "      np.random.shuffle(class_indices[i])\n",
        "\n",
        "    shards = []\n",
        "    for i in range(num_classes):\n",
        "      for j in range(num_shards_per_class):\n",
        "        shards.append(class_indices[i][j*num_imgs:(j+1)*num_imgs])\n",
        "    shards = np.array(shards)\n",
        "    return shards, num_shards\n",
        "\n",
        "  def load_shards_from_xml_file(self, xml_file, train, test, num_clients):\n",
        "    node_assignments = parse_xml_assignments(xml_file)\n",
        "    train_data_indices = {i: np.array([], dtype='int64') for i in range(num_clients)}\n",
        "    test_data_indices = {i: np.array([], dtype='int64') for i in range(num_clients)}\n",
        "    train_shards, _ = self.divide_class_into_shards(train, 10, 20)\n",
        "    test_shards, _ = self.divide_class_into_shards(test, 10, 20)\n",
        "    trainLoaders = []\n",
        "    testLoaders = []\n",
        "    for node in range(num_clients):\n",
        "      shard_ids = node_assignments[node]\n",
        "      print(shard_ids, \"ids\")\n",
        "      indices_tr = [(shard_id[0] - 1) * 20 + shard_id[1] for shard_id in shard_ids]\n",
        "      indices_ts = [(shard_id[0] - 1) * 20 + random.randint(1,19) for shard_id in shard_ids]\n",
        "      print(\"done\")\n",
        "      train_indices = np.concatenate([train_shards[idx] for idx in indices_tr])\n",
        "      test_indices = np.concatenate([test_shards[idx] for idx in indices_ts])\n",
        "      train_loader = DataLoader(Subset(train, train_indices), batch_size=64, shuffle=True)\n",
        "      trainLoaders.append(train_loader)\n",
        "      test_loader = DataLoader(Subset(test, test_indices), batch_size=64, shuffle=True)\n",
        "      testLoaders.append(test_loader)\n",
        "\n",
        "    return trainLoaders, testLoaders\n",
        "  def noniid_split(self, dataset, num_classes: int, num_clients: int, num_shards_per_class: int):\n",
        "\n",
        "    shards, num_shards = self.divide_class_into_shards(dataset, num_classes, num_shards_per_class)\n",
        "    ## Ensure each client gets 2 shards from different classes\n",
        "    client_data_indices = {i: np.array([], dtype='int64') for i in range(num_clients)}\n",
        "    shards_per_client = 4\n",
        "    shards_assignments = np.zeros(num_shards, dtype=bool)\n",
        "    classes = []\n",
        "    for client in range(num_clients):\n",
        "      assigned_shards = []\n",
        "      classes_assigned = []\n",
        "\n",
        "      while len(assigned_shards) < shards_per_client:\n",
        "        shard_idx = np.random.choice(np.where(shards_assignments == False)[0])\n",
        "        class_idx = shard_idx // num_shards_per_class\n",
        "        if class_idx not in classes_assigned:\n",
        "          assigned_shards.append(shard_idx)\n",
        "          classes_assigned.append(class_idx)\n",
        "          shards_assignments[shard_idx] = True\n",
        "\n",
        "      classes.append(classes_assigned)\n",
        "      print(classes_assigned)\n",
        "\n",
        "      for shard in assigned_shards:\n",
        "        print(\"in shatd\")\n",
        "        client_data_indices[client] = np.concatenate((client_data_indices[client], shards[shard]), axis=0)\n",
        "    return client_data_indices, classes\n",
        "  def partition_test_data_based_on_train(self, dataset, train_idx, num_classes: int, num_clients: int, num_shards_per_class: int):\n",
        "\n",
        "    shards, num_shards = self.divide_class_into_shards(dataset, num_classes, num_shards_per_class)\n",
        "    ## Ensure each client gets 2 shards from different classes\n",
        "    client_data_indices = {i: np.array([], dtype='int64') for i in range(num_clients)}\n",
        "    shards_per_client = 4\n",
        "    shards_assignments = np.zeros(num_shards, dtype=bool)\n",
        "    classes = []\n",
        "    for client in range(num_clients):\n",
        "      assigned_shards = []\n",
        "      classes_assigned = []\n",
        "\n",
        "      while len(assigned_shards) < shards_per_client:\n",
        "        class_idx = train_idx[client][len(assigned_shards)]\n",
        "        #shard_idx = np.random.choice(np.where(shards_assignments == False)[0])\n",
        "        shard_idx = (class_idx * 20) + random.randint(1,19)\n",
        "        #if class_idx not in classes_assigned:\n",
        "        assigned_shards.append(shard_idx)\n",
        "        classes_assigned.append(class_idx)\n",
        "          #shards_assignments[shard_idx] = True\n",
        "\n",
        "      classes.append(classes_assigned)\n",
        "      print(classes_assigned)\n",
        "\n",
        "      for shard in assigned_shards:\n",
        "        client_data_indices[client] = np.concatenate((client_data_indices[client], shards[shard]), axis=0)\n",
        "    return client_data_indices\n",
        "  def get_dataloaders(self, dataset, indices, batch_size= 32):\n",
        "    loaders = []\n",
        "    for client_idx in indices:\n",
        "      subset = Subset(dataset, indices[client_idx])\n",
        "      loader = DataLoader(subset, batch_size=32, shuffle= True)\n",
        "      loaders.append(loader)\n",
        "    return loaders\n",
        "\n",
        "dataset = Dataset()\n",
        "train_data, test_data = dataset.load_CIFAR10_dataset()\n",
        "print(\"data\", len(train_data), len(test_data))\n",
        "#train_indices , train_idx = dataset.noniid_split(train_data, 10, 50, 20)\n",
        "print(\"train\")\n",
        "#test_indices = dataset.partition_test_data_based_on_train(test_data, train_idx, 10, 50, 20)\n",
        "print(\"test\")\n",
        "#trainloaders = dataset.get_dataloaders(train_data, train_indices)\n",
        "#testloaders = dataset.get_dataloaders(test_data, test_indices)\n",
        "trainloaders, testloaders = dataset.load_shards_from_xml_file(\"shards.xml\", train_data, test_data, 10)\n",
        "print(\"final\", len(trainloaders), len(testloaders))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMaRzsLt4OW6"
      },
      "outputs": [],
      "source": [
        "# Transforming test and train data for CIFAR10 dataset\n",
        "transform_train = Compose([\n",
        "      RandomHorizontalFlip(),\n",
        "      RandomRotation(10),\n",
        "      ToTensor(),\n",
        "      Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "      ])\n",
        "transform_test = Compose([\n",
        "      ToTensor(),\n",
        "      Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "      ])\n",
        "def set_transform(batch):\n",
        "  batch[\"img\"] = [transform_test(img) for img in batch[\"img\"]]\n",
        "  return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dumElUSlxKVs"
      },
      "source": [
        "# **DEFINE THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "-w3Ot4yF071c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Net, self).__init__()\n",
        "        # Load a pre-trained ResNet18 model\n",
        "        self.resnet18 = models.resnet18(pretrained=False)\n",
        "\n",
        "        # Replace the fully connected layer to match the number of classes\n",
        "        self.resnet18.fc = nn.Linear(self.resnet18.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet18(x)"
      ],
      "metadata": {
        "id": "W4B2-g_pziHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBbs4nFfxKVs"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4itXCi_LxKVt"
      },
      "outputs": [],
      "source": [
        "def train(net, trainloader, epochs: int, verbose=False):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkPuJMWFAbaU"
      },
      "source": [
        "# **DEFINE THE CLIENT CLASS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FoThsxnxKVu"
      },
      "outputs": [],
      "source": [
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip9JUfTGxKVv"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, net, trainloader, testloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.testloader)\n",
        "        return float(loss), len(self.testloader), {\"accuracy\": float(accuracy)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6woQhUnAkgT"
      },
      "source": [
        "# **GENERATE CLIENTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUJkU2QcxKVv"
      },
      "outputs": [],
      "source": [
        "\n",
        "def client_fn(cid: str) -> FlowerClient:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "    return FlowerClient(net = Net().to(DEVICE),\n",
        "                        trainloader = trainloaders[int(cid)],\n",
        "                        testloader = testloaders[int(cid)]).to_client()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm1Dp0JUAnwp"
      },
      "source": [
        "# **FEDERATED LEARNING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncYgVIUqxKVw",
        "outputId": "ed5b2ec8-66cc-497e-9aeb-1c8af86b8668"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=1, no round_timeout\n",
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-06-13 08:08:17,697\tINFO worker.py:1752 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0, 'memory': 8005329716.0, 'object_store_memory': 4002664857.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=1708)\u001b[0m 2024-06-13 08:08:26.725701: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=1708)\u001b[0m 2024-06-13 08:08:26.725792: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=1708)\u001b[0m 2024-06-13 08:08:26.730290: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=1708)\u001b[0m 2024-06-13 08:08:29.032383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 50 clients (out of 50)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 50 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 50 clients (out of 50)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 50 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 1 round(s) in 242.93s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.07950439410209657\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.07950439410209657"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "      # Sample 50% of available clients for evaluation**\n",
        "    min_fit_clients=50,  # Never sample less than 10 clients for training\n",
        "    min_evaluate_clients=25,  # Never sample less than 5 clients for evaluation\n",
        "    min_available_clients=50,  # Wait until all 10 clients are available\n",
        ")\n",
        "\n",
        "# Specify the resources each of your clients need. By default, each\n",
        "# client will be allocated 1x CPU and 0x GPUs\n",
        "client_resources = {\"num_cpus\": 1, \"num_gpus\": 0.0}\n",
        "if DEVICE.type == \"cuda\":\n",
        "    # here we are assigning an entire GPU for each client.\n",
        "    client_resources = {\"num_cpus\": 1, \"num_gpus\": 1.0}\n",
        "    # Refer to our documentation for more details about Flower Simulations\n",
        "    # and how to setup these `client_resources`.\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=50,\n",
        "    config=fl.server.ServerConfig(num_rounds=1),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMJZejuiLGxV"
      },
      "outputs": [],
      "source": [
        "def get_evaluate_fn(testloader):\n",
        "\n",
        "    def evaluate_fn(server_round: int, parameters, config):\n",
        "\n",
        "        model = Net()\n",
        "        # set parameters to the model\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "        # call test\n",
        "        loss, accuracy = test(\n",
        "            model, testloader\n",
        "        )  # <-------------------------- calls the `test` function, just what we did in the centralised setting\n",
        "        return {\"loss\": loss}, {\"accuracy\": accuracy}\n",
        "\n",
        "    return evaluate_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcgZ05NYxKVx"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T63FBaKmxKVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65228e81-8b27-40ef-97b4-bea2c22e6d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n",
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-06-21 12:48:45,383\tINFO worker.py:1752 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'object_store_memory': 4021914009.0, 'memory': 8043828020.0, 'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=3864)\u001b[0m 2024-06-21 12:48:51.833060: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=3864)\u001b[0m 2024-06-21 12:48:51.833159: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=3864)\u001b[0m 2024-06-21 12:48:51.841797: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=3864)\u001b[0m 2024-06-21 12:48:54.213305: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): {'loss': 0.018206617760658263}, {'accuracy': 0.1}\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (1, {'loss': 0.019368455171585083}, {'accuracy': 0.1}, 36.007805288999975)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (2, {'loss': 0.019441022276878356}, {'accuracy': 0.1283}, 89.14214296199998)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (3, {'loss': 0.01945649983882904}, {'accuracy': 0.1003}, 140.977107015)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (4, {'loss': 0.018738104772567748}, {'accuracy': 0.1443}, 193.992486869)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (5, {'loss': 0.018341946029663086}, {'accuracy': 0.1475}, 243.46204673900002)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 266.53s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.04635088068246841\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.04568152040243149\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.045542571425437925\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.04425659388303756\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.043189320027828215\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 0: {'loss': 0.018206617760658263}\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: {'loss': 0.019368455171585083}\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: {'loss': 0.019441022276878356}\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: {'loss': 0.01945649983882904}\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: {'loss': 0.018738104772567748}\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: {'loss': 0.018341946029663086}\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.125),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 0.187),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.151),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 0.20600000000000002),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 0.21200000000000002)]}\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(0, 0.1),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (1, 0.1),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 0.1283),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.1003),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 0.1443),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 0.1475)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        }
      ],
      "source": [
        "client_resources = {\"num_cpus\": 1, \"num_gpus\": 0.0}\n",
        "if DEVICE.type == \"cuda\":\n",
        "    # here we are assigning an entire GPU for each client.\n",
        "    client_resources = {\"num_cpus\": 1, \"num_gpus\": 1.0}\n",
        "    # Refer to our documentation for more details about Flower Simulations\n",
        "    # and how to setup these `client_resources`.\n",
        "dataset = Dataset()\n",
        "train_data, test_data = dataset.load_CIFAR10_dataset()\n",
        "testloader = DataLoader(test_data, batch_size=128)\n",
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    #fraction_evaluate=0.5,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=5,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,\n",
        "    evaluate_fn=get_evaluate_fn(testloader),\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "history = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=10,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD7WtZ2V9IFM"
      },
      "source": [
        "# **PLOT ACCURACY & LOSS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "8jCcmKCi9HHM",
        "outputId": "3cf4842c-ccaa-4c03-f14a-f8252decef3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "history.metrics_centralized = {'accuracy': [(0, 0.0999), (1, 0.1), (2, 0.1), (3, 0.1421), (4, 0.1474), (5, 0.1675)]}\n",
            "[1.8217692899703979, 1.8806333589553834, 1.9606520628929136, 1.8852365946769714, 1.9047117972373961, 1.8345305633544922]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'CIFAR10 - NON-IID - 50 clients with 50 clients per round')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(f\"{history.metrics_centralized = }\")\n",
        "\n",
        "global_accuracy_centralised = history.metrics_centralized[\"accuracy\"]\n",
        "global_loss = [100.0 * (history.losses_centralized[i][1][\"loss\"]) for i in range(len(history.losses_centralized))]\n",
        "print(global_loss)\n",
        "round = [data[0] for data in global_accuracy_centralised]\n",
        "acc = [100.0 * data[1] for data in global_accuracy_centralised]\n",
        "plt.plot(acc, label = \"accuracy\")\n",
        "plt.plot(global_loss, label = \"loss\")\n",
        "plt.grid()\n",
        "plt.xlabel(\"Round\")\n",
        "plt.legend()\n",
        "plt.title(\"CIFAR10 - NON-IID - 50 clients with 50 clients per round\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpSq_ci0bts8"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from lxml import etree\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import KMeans\n",
        "import copy\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "Clustering_method=\"Mask\"\n",
        "Clustering_period = 2\n",
        "cluster_number=3\n",
        "log_path=datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S_\") + Clustering_method\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARtm0-QgdXaR"
      },
      "source": [
        "# **PARSE .XML FILES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "pxxSWWO8dbRp",
        "outputId": "ee4433e0-09ee-44c2-fccc-1f9b3a571497"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-71c2df16-6b61-4f7d-bc26-2d2eb32b2ec1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-71c2df16-6b61-4f7d-bc26-2d2eb32b2ec1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving clusters_main.xml to clusters_main (1).xml\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-96a72e87-79e6-4ecb-bfc1-296f471c1ede\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-96a72e87-79e6-4ecb-bfc1-296f471c1ede\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving clusters.xml to clusters (1).xml\n"
          ]
        }
      ],
      "source": [
        "def parse_xml_assignments(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    node_assignments = {}\n",
        "    for node in root.findall('Node'):\n",
        "        node_id = int(node.get('id'))\n",
        "        shards = [(int(dp.get('classLabel')), int(dp.get('shard'))) for dp in node.findall('DataPair')]\n",
        "        node_assignments[node_id] = shards\n",
        "    return node_assignments\n",
        "\n",
        "def parse_clusters_from_file(filename):\n",
        "    tree = ET.parse(filename)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Initialize a dictionary to store the cluster data\n",
        "    cluster_dict = {}\n",
        "\n",
        "    # Iterate over each cluster element in the XML\n",
        "    for cluster in root.findall('Cluster'):\n",
        "        cluster_id = int(cluster.get('id'))\n",
        "        nodes = []\n",
        "\n",
        "        # Iterate over each node within the cluster\n",
        "        for node in cluster.findall('Node'):\n",
        "            node_id = int(node.get('id'))\n",
        "            nodes.append(node_id)\n",
        "\n",
        "        # Add the list of nodes to the dictionary under the cluster ID\n",
        "        cluster_dict[cluster_id] = nodes\n",
        "\n",
        "    return cluster_dict\n",
        "\n",
        "\n",
        "## Begin Federated Training\n",
        "from google.colab import files\n",
        "uploaded1 = files.upload()\n",
        "uploaded2 = files.upload()\n",
        "Cluster_file_path = 'clusters.xml'\n",
        "Cluster_file_path_main = 'clusters_main.xml'\n",
        "shutil.copy(Cluster_file_path_main, Cluster_file_path)\n",
        "import datetime;\n",
        "log_file = log_path + '.log'\n",
        "os.mkdir(log_path)\n",
        "open(log_file, 'a').close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGYASrOqSN57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "504ec6a8-6574-4822-ba44-1ace5d898dc5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1ICOZBKZ3aJ"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List, Optional, Tuple, Union, Callable\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from flwr.common import (\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    MetricsAggregationFn,\n",
        "    NDArrays,\n",
        "    Parameters,\n",
        "    Scalar,\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        ")\n",
        "from flwr.common.logger import log\n",
        "from flwr.server.client_manager import ClientManager\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.server.strategy.aggregate import aggregate, weighted_loss_avg, aggregate_inplace\n",
        "from logging import WARNING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxSnoYZgC4xu"
      },
      "source": [
        "# **CALCULATING THE SIMILARITY DISTANCE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm1_UNt7pb5Z"
      },
      "outputs": [],
      "source": [
        "def normalize_distance(distances, num_clients):\n",
        "        min1 = np.min(np.ma.masked_equal(distances, 0))\n",
        "        max1 = np.max(np.ma.masked_equal(distances, 0))\n",
        "\n",
        "        normal_distances = np.zeros((num_clients, num_clients))\n",
        "\n",
        "        for i in range(num_clients):\n",
        "            normal_distances[i][i] = 0\n",
        "            for j in range(i+1, num_clients):\n",
        "                normal_distances[i][j] = normal_distances[j][i] = (\n",
        "                    distances[i][j]-min1)/(max1-min1)\n",
        "            # print(\"after:\",item, distances[item])\n",
        "        return normal_distances\n",
        "\n",
        "## Function to calculate the number of common IDs\n",
        "def calculate_common_ids(arr1, arr2):\n",
        "    return len(set(arr1).intersection(set(arr2)))\n",
        "\n",
        "def ExtractDistances(sensitive_weights, mask_number, num_clients):\n",
        "      similarity_matrix = np.zeros((num_clients, num_clients))\n",
        "      for i in range(num_clients):\n",
        "          for j in range(i + 1, num_clients):\n",
        "              similarity = calculate_common_ids(\n",
        "                  sensitive_weights[i], sensitive_weights[j])\n",
        "              similarity_matrix[i, j] = similarity\n",
        "              similarity_matrix[j, i] = similarity\n",
        "          similarity_matrix[i, i] = mask_number\n",
        "\n",
        "        # Convert similarity matrix to distance matrix\n",
        "        # Note: Higher similarity means closer distance\n",
        "      distances = mask_number - similarity_matrix\n",
        "      normal_distances = normalize_distance(distances, num_clients)\n",
        "      return normal_distances\n",
        "def assign_ids_to_weights(client_params_history):\n",
        "    weight_id_map = {}\n",
        "    weight_id = 0\n",
        "    for cid, params in client_params_history.items():\n",
        "        weight_id_map[cid] = {}\n",
        "        num_weights = len(params)\n",
        "        for i in range(num_weights):\n",
        "            weight_id_map[cid][i] = weight_id\n",
        "            weight_id += 1\n",
        "    return weight_id_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPdEAtp4CMxc"
      },
      "source": [
        "# **IMPLEMENT STRATEGY FOR CLUSTERING**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FedCluster(fl.server.strategy.Strategy):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        fraction_fit: float = 1.0,\n",
        "        fraction_evaluate: float = 1.0,\n",
        "        min_fit_clients: int = 2,\n",
        "        min_evaluate_clients: int = 2,\n",
        "        min_available_clients: int = 2,\n",
        "        num_clusters: int = 3,\n",
        "        clustering_round: int = 1,\n",
        "        sensitivity_percentage: float = 0.01,\n",
        "        evaluate_fn: Optional[\n",
        "            Callable[\n",
        "                [int, NDArrays, Dict[str, Scalar]],\n",
        "                Optional[Tuple[float, Dict[str, Scalar]]],\n",
        "            ]\n",
        "        ] = None,\n",
        "        on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        accept_failures: bool = True,\n",
        "        initial_parameters: Optional[Parameters] = None,\n",
        "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        inplace: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        if (\n",
        "            min_fit_clients > min_available_clients\n",
        "            or min_evaluate_clients > min_available_clients\n",
        "        ):\n",
        "            log(WARNING, WARNING_MIN_AVAILABLE_CLIENTS_TOO_LOW)\n",
        "\n",
        "        self.fraction_fit = fraction_fit\n",
        "        self.fraction_evaluate = fraction_evaluate\n",
        "        self.min_fit_clients = min_fit_clients\n",
        "        self.min_evaluate_clients = min_evaluate_clients\n",
        "        self.min_available_clients = min_available_clients\n",
        "        self.evaluate_fn = evaluate_fn\n",
        "        self.on_fit_config_fn = on_fit_config_fn\n",
        "        self.on_evaluate_config_fn = on_evaluate_config_fn\n",
        "        self.accept_failures = accept_failures\n",
        "        self.initial_parameters = initial_parameters\n",
        "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
        "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
        "        self.inplace = inplace\n",
        "        self.num_clusters = num_clusters\n",
        "        self.clustering_round = clustering_round\n",
        "        self. sensitivity_percentage = sensitivity_percentage\n",
        "        self.client_params_history = {}\n",
        "        self.client_clusters = None\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        \"\"\"Compute a string representation of the strategy.\"\"\"\n",
        "        rep = f\"FedCluster(accept_failures={self.accept_failures})\"\n",
        "        return rep\n",
        "\n",
        "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
        "        \"\"\"Return the sample size and the required number of available clients.\"\"\"\n",
        "        num_clients = int(num_available_clients * self.fraction_fit)\n",
        "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
        "\n",
        "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
        "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
        "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
        "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
        "\n",
        "    def initialize_parameters(\n",
        "        self, client_manager: ClientManager\n",
        "    ) -> Optional[Parameters]:\n",
        "        \"\"\"Initialize global model parameters.\"\"\"\n",
        "        initial_parameters = self.initial_parameters\n",
        "        self.initial_parameters = None  # Don't keep initial parameters in memory\n",
        "        return initial_parameters\n",
        "\n",
        "    def evaluate(\n",
        "        self, server_round: int, parameters: Parameters\n",
        "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
        "        if self.evaluate_fn is None:\n",
        "            # No evaluation function provided\n",
        "            return None\n",
        "        parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
        "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
        "        if eval_res is None:\n",
        "            return None\n",
        "        loss, metrics = eval_res\n",
        "        return loss, metrics\n",
        "\n",
        "    def configure_fit(\n",
        "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
        "        \"\"\"Configure the next round of training.\"\"\"\n",
        "        config = {}\n",
        "        if self.on_fit_config_fn is not None:\n",
        "            # Custom fit config function provided\n",
        "            config = self.on_fit_config_fn(server_round)\n",
        "        fit_ins = FitIns(parameters, config)\n",
        "\n",
        "        # Sample clients\n",
        "        sample_size, min_num_clients = self.num_fit_clients(\n",
        "            client_manager.num_available()\n",
        "        )\n",
        "        clients = client_manager.sample(\n",
        "            num_clients=sample_size, min_num_clients=min_num_clients\n",
        "        )\n",
        "\n",
        "        # Return client/config pairs\n",
        "        return [(client, fit_ins) for client in clients]\n",
        "\n",
        "    def configure_evaluate(\n",
        "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
        "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
        "        # Do not configure federated evaluation if fraction eval is 0.\n",
        "        if self.fraction_evaluate == 0.0:\n",
        "            return []\n",
        "\n",
        "        # Parameters and config\n",
        "        config = {}\n",
        "        if self.on_evaluate_config_fn is not None:\n",
        "            # Custom evaluation config function provided\n",
        "            config = self.on_evaluate_config_fn(server_round)\n",
        "        evaluate_ins = EvaluateIns(parameters, config)\n",
        "\n",
        "        # Sample clients\n",
        "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
        "            client_manager.num_available()\n",
        "        )\n",
        "        clients = client_manager.sample(\n",
        "            num_clients=sample_size, min_num_clients=min_num_clients\n",
        "        )\n",
        "\n",
        "        # Return client/config pairs\n",
        "        return [(client, evaluate_ins) for client in clients]\n",
        "\n",
        "    def compute_top_10_percent_params(self, parameters: np.ndarray) -> List[int]:\n",
        "      param_magnitudes = np.abs(parameters)\n",
        "      num_params = len(param_magnitudes)\n",
        "      num_top_params = int(0.1 * num_params)\n",
        "\n",
        "      top_10_percent_params = np.argsort(param_magnitudes)[-num_top_params:]\n",
        "      return top_10_percent_params\n",
        "\n",
        "    def create_client_vectors(self, client_params_flat: Dict[str, np.ndarray], top_10_percent_params: Dict[str, List[int]]) -> np.ndarray:\n",
        "      param_set = set()\n",
        "      for ids in top_10_percent_params.values():\n",
        "        param_set.update(ids)\n",
        "      param_set = list(param_set)\n",
        "\n",
        "      client_vectors = []\n",
        "      for cid, params in client_params_flat.items():\n",
        "        binary_vector = np.zeros(len(param_set), dtype=int)\n",
        "        for idx in top_10_percent_params[cid]:\n",
        "          binary_vector[param_set.index(idx)] = 1\n",
        "        client_vectors.append(binary_vector)\n",
        "      return np.array(client_vectors)\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
        "        if not results:\n",
        "            return None, {}\n",
        "        # Do not aggregate if there are failures and failures are not accepted\n",
        "        if not self.accept_failures and failures:\n",
        "            return None, {}\n",
        "\n",
        "        if self.inplace:\n",
        "            # Does in-place weighted average of results\n",
        "            aggregated_ndarrays = aggregate_inplace(results)\n",
        "        else:\n",
        "            # Convert results\n",
        "            weights_results = [\n",
        "                (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
        "                for _, fit_res in results\n",
        "            ]\n",
        "            if server_round == 0 or server_round % self.clustering_round != 0:\n",
        "              parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
        "\n",
        "            if server_round % self.clustering_round == 0:\n",
        "\n",
        "              for cid, fit_res in results:\n",
        "                self.client_params_history[cid] = parameters_to_ndarrays(fit_res.parameters)\n",
        "\n",
        "              #client_parameters = [parameters_to_ndarrays(result[1].parameters) for result in results]\n",
        "              #top_p_percent_parameters = np.argsort(np.abs(client_parameters))[-int(0.1 * len(client_parameters[0])):]\n",
        "\n",
        "              #parameter_ids = {param: idx for idx, param in enumerate(top_p_percent_parameters)}\n",
        "              #parameter_matrix = np.array(client_parameters)[:, top_p_percent_parameters]\n",
        "              #similarity_matrix = 1 - pairwise_distances(parameter_matrix, metric= 'cosine')\n",
        "\n",
        "              #common_ids = np.mean(similarity_matrix, axis=0)\n",
        "\n",
        "              client_params_flat = {cid: np.concatenate([param.flatten() for param in params]) for cid, params in self.client_params_history.items()}\n",
        "\n",
        "              top_10_percent_params_flat = {cid: self.compute_top_10_percent_params(params) for cid, params in client_params_flat.items()}\n",
        "              weight_map_id = assign_ids_to_weights(top_10_percent_params_flat)\n",
        "\n",
        "              #parameter_ids = {param: idx for idx, param in enumerate(top_10_percent_params_flat)}\n",
        "              #parameter_matrix = np.array(client_params_flat)[:, top_10_percent_params_flat]\n",
        "              #similarity_matrix = 1 - pairwise_distances(parameter_matrix, metric= 'cosine')\n",
        "\n",
        "              #common_ids = np.mean(similarity_matrix, axis=0)\n",
        "              client_vectors = self.create_client_vectors(client_params_flat, top_10_percent_params_flat)\n",
        "              kmeans = KMeans(n_clusters= self.num_clusters, random_state= 0)\n",
        "              cluster_assignments = kmeans.fit_predict(client_vectors)\n",
        "\n",
        "\n",
        "              self.client_clusters = {i: [] for i in range(self.num_clusters)}\n",
        "              for cid, cluster_id in zip(self.client_params_history.keys(), cluster_assignments):\n",
        "                self.client_clusters[cluster_id].append(top_10_percent_params_flat[cid])\n",
        "\n",
        "              cluster_updates = {i: [] for i in range(self.num_clusters)}\n",
        "              index = 0\n",
        "              for cluster in self.client_clusters.values():\n",
        "                if cluster:\n",
        "                  cluster_update = self.aggregate_cluster(cluster)\n",
        "                  cluster_updates[index] = cluster_update\n",
        "                  index += 1\n",
        "\n",
        "\n",
        "\n",
        "              start_fl_for_clusters(self.client_clusters)\n",
        "              print(\"finish\")\n",
        "\n",
        "              global_update = self.aggregate_cluster(cluster_updates)\n",
        "              parameters_aggregated = ndarrays_to_parameters(global_update)\n",
        "\n",
        "        # Aggregate custom metrics if aggregation fn was provided\n",
        "        metrics_aggregated = {}\n",
        "        if self.fit_metrics_aggregation_fn:\n",
        "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
        "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
        "        elif server_round == 1:  # Only log this warning once\n",
        "            log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
        "\n",
        "        return parameters_aggregated, metrics_aggregated\n",
        "\n",
        "\n",
        "    def aggregate_cluster(self, client_params):\n",
        "      num_clients = len(client_params)\n",
        "      averaged_params = []\n",
        "      for params in zip(*client_params):\n",
        "        averaged_param = sum(params) / num_clients\n",
        "        averaged_params.append(averaged_param)\n",
        "      return averaged_params\n",
        "\n",
        "    def aggregate_evaluate(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
        "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
        "        if not results:\n",
        "            return None, {}\n",
        "        # Do not aggregate if there are failures and failures are not accepted\n",
        "        if not self.accept_failures and failures:\n",
        "            return None, {}\n",
        "\n",
        "        # Aggregate loss\n",
        "        loss_aggregated = weighted_loss_avg(\n",
        "            [\n",
        "                (evaluate_res.num_examples, evaluate_res.loss)\n",
        "                for _, evaluate_res in results\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Aggregate custom metrics if aggregation fn was provided\n",
        "        metrics_aggregated = {}\n",
        "        if self.evaluate_metrics_aggregation_fn:\n",
        "            eval_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
        "            metrics_aggregated = self.evaluate_metrics_aggregation_fn(eval_metrics)\n",
        "        elif server_round == 1:  # Only log this warning once\n",
        "            log(WARNING, \"No evaluate_metrics_aggregation_fn provided\")\n",
        "\n",
        "        return loss_aggregated, metrics_aggregated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPT8nhByB37p",
        "outputId": "dc813bf0-9ab9-4376-a81f-c56de315757c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPLEMENTING 3 STRATEGIES FOR CLUSTERS**"
      ],
      "metadata": {
        "id": "A-5DIb6-JRJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def start_fl_for_clusters(cluster_models):\n",
        "  cluster_results = []\n",
        "  for cluster_id, client_parameters in cluster_models.items():\n",
        "    strategy = fl.server.strategy.FedAvg(initial_parameters= [fl.common.ndarrays_to_parameters(parameters) for parameters in client_parameters])\n",
        "    print(\"built strategy\")\n",
        "    server = fl.simulation.start_simulation(\n",
        "        client_fn= client_fn,\n",
        "        num_clients= 17,\n",
        "        config=fl.server.ServerConfig(num_rounds=1),\n",
        "        strategy=strategy,\n",
        "\n",
        "    )\n",
        "\n",
        "    print(\"id\", cluster_id)"
      ],
      "metadata": {
        "id": "ePmTnRg2JZxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "qm6rmufxTERO",
        "outputId": "1c3063b9-1753-4258-c117-458ad4117819"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DEVICE' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-941c731cc14f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclient_resources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"num_cpus\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"num_gpus\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# here we are assigning an entire GPU for each client.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mclient_resources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"num_cpus\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"num_gpus\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DEVICE' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "#strategy = SensitivityClustering(num_clusters= 3, num_clients=50, clustering_round=2, sensitivity_percentage=0.01)\n",
        "\n",
        "client_resources = {\"num_cpus\": 1, \"num_gpus\": 0.0}\n",
        "if DEVICE.type == \"cuda\":\n",
        "    # here we are assigning an entire GPU for each client.\n",
        "    client_resources = {\"num_cpus\": 1, \"num_gpus\": 1.0}\n",
        "    # Refer to our documentation for more details about Flower Simulations\n",
        "    # and how to setup these `client_resources`.\n",
        "# Start simulation\n",
        "print(client_fn)\n",
        "\n",
        "history = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=50,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=FedCluster(),\n",
        "    client_resources=client_resources,\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class FedCluster(fl.server.strategy.Strategy):\n",
        "    def __init__(\n",
        "        self,\n",
        "        fraction_fit: float = 1.0,\n",
        "        fraction_evaluate: float = 1.0,\n",
        "        min_fit_clients: int = 50,\n",
        "        min_evaluate_clients: int = 25,\n",
        "        min_available_clients: int = 50,\n",
        "        num_clusters: int = 3,\n",
        "        clustering_round: int = 1,\n",
        "        sensitivity_percentage: float = 0.01,\n",
        "\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.fraction_fit = fraction_fit\n",
        "        self.fraction_evaluate = fraction_evaluate\n",
        "        self.min_fit_clients = min_fit_clients\n",
        "        self.min_evaluate_clients = min_evaluate_clients\n",
        "        self.min_available_clients = min_available_clients\n",
        "        self.num_clusters = num_clusters\n",
        "        self.clustering_round = clustering_round\n",
        "        self. sensitivity_percentage = sensitivity_percentage\n",
        "\n",
        "        self.client_params_history = {}\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return \"FedCluster\"\n",
        "\n",
        "    def initialize_parameters(\n",
        "        self, client_manager: ClientManager\n",
        "    ) -> Optional[Parameters]:\n",
        "        \"\"\"Initialize global model parameters.\"\"\"\n",
        "        net = Net()\n",
        "        ndarrays = get_parameters(net)\n",
        "        return fl.common.ndarrays_to_parameters(ndarrays)\n",
        "\n",
        "\n",
        "    def configure_fit(\n",
        "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
        "        \"\"\"Configure the next round of training.\"\"\"\n",
        "\n",
        "        # Sample clients\n",
        "        sample_size, min_num_clients = self.num_fit_clients(\n",
        "            client_manager.num_available()\n",
        "        )\n",
        "        clients = client_manager.sample(\n",
        "            num_clients=sample_size, min_num_clients=min_num_clients\n",
        "        )\n",
        "\n",
        "        # Create custom configs\n",
        "        n_clients = len(clients)\n",
        "        half_clients = n_clients // 2\n",
        "        standard_config = {\"lr\": 0.001}\n",
        "        higher_lr_config = {\"lr\": 0.003}\n",
        "        fit_configurations = []\n",
        "        for idx, client in enumerate(clients):\n",
        "            if idx < half_clients:\n",
        "                fit_configurations.append((client, FitIns(parameters, standard_config)))\n",
        "            else:\n",
        "                fit_configurations.append(\n",
        "                    (client, FitIns(parameters, higher_lr_config))\n",
        "                )\n",
        "        return fit_configurations\n",
        "\n",
        "\n",
        "    def compute_top_10_percent_params(self, parameters: np.ndarray) -> List[int]:\n",
        "      param_magnitudes = np.abs(parameters)\n",
        "      num_params = len(param_magnitudes)\n",
        "      num_top_params = int(0.1 * num_params)\n",
        "\n",
        "      top_10_percent_params = np.argsort(param_magnitudes)[-num_top_params:]\n",
        "      return top_10_percent_params\n",
        "\n",
        "    def create_client_vectors(self, client_params_flat: Dict[str, np.ndarray], top_10_percent_params: Dict[str, List[int]]) -> np.ndarray:\n",
        "\n",
        "      param_set = set()\n",
        "      for ids in top_10_percent_params.values():\n",
        "        param_set.update(ids)\n",
        "      param_set = list(param_set)\n",
        "\n",
        "      client_vectors = []\n",
        "      for cid, params in client_params_flat.items():\n",
        "        binary_vector = np.zeros(len(param_set), dtype=int)\n",
        "        for idx in top_10_percent_params[cid]:\n",
        "          binary_vector[param_set.index(idx)] = 1\n",
        "        client_vectors.append(binary_vector)\n",
        "      return np.array(client_vectors)\n",
        "\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
        "        weights_results = [\n",
        "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
        "            for _, fit_res in results\n",
        "        ]\n",
        "        #client_params = [parameters_to_ndarrays(res.parameters) for _, res in results]\n",
        "        #client_params_flat = [np.concatenate([param.flatten() for param in client[0]]) for client in weights_results]\n",
        "\n",
        "        if server_round == 0 or server_round % self.clustering_round != 0:\n",
        "          parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
        "\n",
        "        if server_round % self.clustering_round == 0:\n",
        "\n",
        "          for cid, fit_res in results:\n",
        "            self.client_params_history[cid] = parameters_to_ndarrays(fit_res.parameters)\n",
        "\n",
        "\n",
        "          client_params_flat = {cid: np.concatenate([param.flatten() for param in params]) for cid, params in self.client_params_history.items()}\n",
        "\n",
        "\n",
        "          top_10_percent_params_flat = {cid: self.compute_top_10_percent_params(params) for cid, params in client_params_flat.items()}\n",
        "          weight_map_id = assign_ids_to_weights(top_10_percent_params_flat)\n",
        "\n",
        "\n",
        "          client_vectors = self.create_client_vectors(client_params_flat, top_10_percent_params_flat)\n",
        "\n",
        "          kmeans = KMeans(n_clusters= self.num_clusters, random_state= 0)\n",
        "          cluster_assignments = kmeans.fit_predict(client_vectors)\n",
        "\n",
        "\n",
        "\n",
        "          clustered_clients = {i: [] for i in range(self.num_clusters)}\n",
        "          for cid, cluster_id in zip(self.client_params_history.keys(), cluster_assignments):\n",
        "            clustered_clients[cluster_id].append(self.client_params_history[cid])\n",
        "          cluster_updates = []\n",
        "          for cluster in clustered_clients.values():\n",
        "            #cluster_clients = [params for params, assignment in zip(client_params, cluster_assignments) if assignment == cluster]\n",
        "            if cluster:\n",
        "              cluster_update = self.aggregate_cluster(cluster)\n",
        "              cluster_updates.append(cluster_update)\n",
        "\n",
        "          print(\"update\",cluster_updates )\n",
        "          global_update = self.aggregate_cluster(cluster_updates)\n",
        "        #parameters_aggregated = ndarrays_to_parameters(aggregate(weights_results))\n",
        "          parameters_aggregated = ndarrays_to_parameters(global_update)\n",
        "\n",
        "        metrics_aggregated = {}\n",
        "        return parameters_aggregated, metrics_aggregated\n",
        "\n",
        "    def aggregate_cluster(self, client_params):\n",
        "      num_clients = len(client_params)\n",
        "      averaged_params = []\n",
        "      for params in zip(*client_params):\n",
        "        averaged_param = sum(params) / num_clients\n",
        "        averaged_params.append(averaged_param)\n",
        "      return averaged_params\n",
        "\n",
        "    def configure_evaluate(\n",
        "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
        "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
        "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
        "        if self.fraction_evaluate == 0.0:\n",
        "            return []\n",
        "        config = {}\n",
        "        evaluate_ins = EvaluateIns(parameters, config)\n",
        "\n",
        "        # Sample clients\n",
        "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
        "            client_manager.num_available()\n",
        "        )\n",
        "        clients = client_manager.sample(\n",
        "            num_clients=sample_size, min_num_clients=min_num_clients\n",
        "        )\n",
        "\n",
        "        # Return client/config pairs\n",
        "        return [(client, evaluate_ins) for client in clients]\n",
        "\n",
        "    def aggregate_evaluate(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
        "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
        "\n",
        "        if not results:\n",
        "            return None, {}\n",
        "\n",
        "        loss_aggregated = weighted_loss_avg(\n",
        "            [\n",
        "                (evaluate_res.num_examples, evaluate_res.loss)\n",
        "                for _, evaluate_res in results\n",
        "            ]\n",
        "        )\n",
        "        metrics_aggregated = {}\n",
        "        return loss_aggregated, metrics_aggregated\n",
        "\n",
        "    def evaluate(\n",
        "        self, server_round: int, parameters: Parameters\n",
        "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "        \"\"\"Evaluate global model parameters using an evaluation function.\"\"\"\n",
        "\n",
        "        # Let's assume we won't perform the global model evaluation on the server side.\n",
        "        return None\n",
        "\n",
        "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
        "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
        "        num_clients = int(num_available_clients * self.fraction_fit)\n",
        "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
        "\n",
        "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
        "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
        "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
        "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients"
      ],
      "metadata": {
        "id": "eSiTOeD5kz8t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "flwr",
      "language": "python",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5412fcfd51b944a58cbffac601ed3b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_553eb205e7c748c791e3ee1095b947ea",
              "IPY_MODEL_d3efea749c7542b8ba5fb078bb67be8a",
              "IPY_MODEL_87be248dbc3d486283a561b0b1d1f3a7"
            ],
            "layout": "IPY_MODEL_2a6e1d07cb204bbf8ae42ef6427e4026"
          }
        },
        "553eb205e7c748c791e3ee1095b947ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d8d602d077c42e29bc15af6095bee73",
            "placeholder": "​",
            "style": "IPY_MODEL_a5b8cd68b90c46f485f71be1775b17cb",
            "value": "Downloading readme: 100%"
          }
        },
        "d3efea749c7542b8ba5fb078bb67be8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_604d2575082546d4950b88dde1b58918",
            "max": 5157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ad19bb025dd456ebda8dbb8977ad5d3",
            "value": 5157
          }
        },
        "87be248dbc3d486283a561b0b1d1f3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_237d678f3a304f31a5ff016ea0db4d6f",
            "placeholder": "​",
            "style": "IPY_MODEL_906c0a430a5047f2b750ecdc7844ae76",
            "value": " 5.16k/5.16k [00:00&lt;00:00, 119kB/s]"
          }
        },
        "2a6e1d07cb204bbf8ae42ef6427e4026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d8d602d077c42e29bc15af6095bee73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5b8cd68b90c46f485f71be1775b17cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "604d2575082546d4950b88dde1b58918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ad19bb025dd456ebda8dbb8977ad5d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "237d678f3a304f31a5ff016ea0db4d6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "906c0a430a5047f2b750ecdc7844ae76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3121b65f58af47e7a982bfa475a88b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53f8b87f16dd4e8494fabfca2737a2cd",
              "IPY_MODEL_9ca09450a12e4c05995ae3724779791c",
              "IPY_MODEL_f061875ce37f4b8a959385d0e1fc8573"
            ],
            "layout": "IPY_MODEL_b13a129aae0e4e3da404bf0ad28a2010"
          }
        },
        "53f8b87f16dd4e8494fabfca2737a2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ade872cb07ea40d1a3c69a5fa9758f57",
            "placeholder": "​",
            "style": "IPY_MODEL_e78fceb701c1403fb03884e1c314ae29",
            "value": "Downloading data:  61%"
          }
        },
        "9ca09450a12e4c05995ae3724779791c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ba88b6458e64c96bad2e44feafdd460",
            "max": 119705255,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_970d6a7bf93b40838da3341e89836332",
            "value": 73400320
          }
        },
        "f061875ce37f4b8a959385d0e1fc8573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17ac04a9bda143a69a8e9fee794b8d67",
            "placeholder": "​",
            "style": "IPY_MODEL_e1583090194b4ff29366df2497f46834",
            "value": " 73.4M/120M [17:01&lt;00:00, 90.9MB/s]"
          }
        },
        "b13a129aae0e4e3da404bf0ad28a2010": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade872cb07ea40d1a3c69a5fa9758f57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e78fceb701c1403fb03884e1c314ae29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ba88b6458e64c96bad2e44feafdd460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "970d6a7bf93b40838da3341e89836332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17ac04a9bda143a69a8e9fee794b8d67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1583090194b4ff29366df2497f46834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}